True cuda
args: None URLord URLord_2 /cs/casmip/nirm/embryo_project_version1/EXP_FOLDER/exp_fp2/203/exp2d_DF_3_2d True urlord2d_203exp2d_DF_3_2d DF_3_2d_TL DF_3_2d_TU DF_3_2d_VA DF_3_2d_TE False True /cs/labs/josko/nirm/embryo_project_version1/embyo_projects_codes/models_config/config_2d /cs/labs/josko/nirm/embryo_project_version1/embyo_projects_codes/models_config/config_2d
dividing....
(2016, 128, 128, 1) imaggggggeeeeeeeeeeeeeeee shape
[0.] unique claseesssssssssssssssssssssssssssssssssssssssssssssssss
False False load_model
arrive train
2 30 config['n_classes'], config['class_dim']
/cs/casmip/nirm/embryo_project_version1/venu-pytorch/lib/python3.7/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)
  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
/cs/labs/josko/nirm/embryo_project_version1/embyo_projects_codes/lord-pytorch-unet/model/modules_unet.py:356: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  tensor = torch.tensor(x, requires_grad = False)
here seg decay
here recon_loss
  0%|                                                                                                                                                                                                                                                                                        | 0/378 [00:00<?, ?it/s][W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)                                                                                                                                                                                             | 0/378 [00:00<?, ?it/s]
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)                                                                                                                                                                                              | 0/45 [00:00<?, ?it/s]
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)                                                                                                                                                                                             | 0/126 [00:00<?, ?it/s]
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
epoch #0:   1%|█▎                                                                                                                                                                                                                                                          | 2/378 [00:01<04:39,  1.35it/s, loss=119]
  1%|█▍                                                                                                                                                                                                                                                                              | 2/378 [00:01<04:39,  1.35it/s]
1 recon_decay
tensor(0., device='cuda:0') tensor(1., device='cuda:0') min max before 1
torch.Size([16]) sum mask size 1
torch.Size([16]) losssss
torch.Size([16]) losssss
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(11.2402, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(14.1952, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([661., 351., 219., 104., 685.,   1., 502., 172.,  66.,   1.,  96.,   1.,
        310., 372.,   1.,   1.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([339., 250., 156., 169., 354., 127., 309., 145., 145., 127., 131., 127.,
        235., 176., 127., 127.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([4.3817, 5.0384, 4.1382, 4.0395, 5.6181, 0.0000, 5.4468, 4.2876, 3.1491,
        0.0000, 4.1906, 0.0000, 6.1343, 3.8680, 0.0000, 0.0000],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([5.9176, 7.5617, 7.3569, 7.6617, 7.3940, 4.8255, 7.5177, 7.7011, 7.3727,
        4.8381, 8.1776, 4.8195, 8.7640, 5.4885, 4.8270, 4.8200],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(37.0124, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(37.4507, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([76., 37., 29., 25., 63.,  1., 47., 26., 13.,  1., 19.,  1., 51., 44.,
         1.,  1.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([100.,  35.,  24.,  21.,  54.,   1.,  47.,  25.,  12.,   1.,  21.,   1.,
         53.,  40.,   1.,   1.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([14.4840, 16.2880, 13.6057, 17.2480, 17.5611,  0.0000, 17.1381, 13.3741,
        12.1004,  0.0000, 16.8625,  0.0000, 19.2497, 14.9932,  0.0000,  0.0000],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([25.3663, 29.2662, 25.4519, 29.8957, 32.6060,  0.0000, 27.9156, 23.2650,
        21.7931,  0.0000, 30.9824,  0.0000, 32.5194, 26.2131,  0.0000,  0.0000],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(49.5618, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(49.0410, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([33., 41., 18., 34., 57.,  1., 29., 16., 13.,  1., 23.,  1., 35., 26.,
         1.,  1.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([39., 45., 20., 26., 48.,  1., 33., 22., 17.,  1., 19.,  1., 43., 33.,
         1.,  1.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([20.4755, 21.2600, 20.5626, 19.3933, 22.5173,  0.0000, 18.5052, 21.2513,
        17.2107,  0.0000, 21.8988,  0.0000, 24.3194, 18.8679,  0.0000,  0.0000],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([35.1044, 39.2170, 37.5110, 36.5285, 41.8333,  0.0000, 32.1889, 39.1507,
        30.6087,  0.0000, 42.9392,  0.0000, 41.8740, 33.6353,  0.0000,  0.0000],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(33.9507, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(37.9504, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([31.,  8.,  4., 12., 14.,  1.,  8.,  4., 10.,  1., 13.,  1., 11.,  9.,
         1.,  1.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([13., 13.,  7., 11.,  8.,  1.,  4.,  8.,  8.,  1.,  9.,  1., 12., 11.,
         1.,  1.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([15.4110, 12.7825,  9.9530, 17.1436, 15.6428,  0.0000, 14.9301, 13.4048,
        14.1890,  0.0000, 17.1471,  0.0000, 20.1576, 11.8138,  0.0000,  0.0000],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([30.7451, 21.9729, 21.2605, 33.6698, 29.4986,  0.0000, 25.8597, 24.4164,
        28.5576,  0.0000, 34.2311,  0.0000, 37.3621, 22.4486,  0.0000,  0.0000],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(10.1772, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(10.0418, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([28.,  5.,  1.,  5.,  6.,  1.,  8.,  6.,  1.,  1.,  7.,  1.,  4., 15.,
         1.,  1.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([19., 12.,  9., 10.,  7.,  1.,  6., 12.,  5.,  1.,  9.,  1.,  9., 39.,
         1.,  1.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([4.2625, 1.5122, 0.0000, 4.2843, 2.0120, 0.0000, 4.3516, 3.1586, 0.0000,
        0.0000, 3.7741, 0.0000, 4.0353, 4.2555, 0.0000, 0.0000],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([7.8413, 3.6290, 2.9719, 7.1781, 5.5824, 0.0000, 8.4188, 6.3696, 1.2989,
        0.0000, 7.2484, 0.0000, 7.9749, 7.5643, 0.0000, 0.0000],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
tensor(0.1146, device='cuda:0') tensor(0.9856, device='cuda:0') min max before 1
torch.Size([16]) sum mask size 1
torch.Size([16]) losssss
torch.Size([16]) losssss
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(10.4669, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(10.1967, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([192., 185., 220., 360.,  92., 229., 222., 134., 104., 192., 137., 210.,
        194., 247., 281., 206.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([248., 197., 231., 453., 148., 255., 300., 190., 122., 221., 191., 263.,
        242., 286., 373., 271.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([5.2875, 4.1953, 6.1479, 5.8405, 4.7158, 5.4939, 6.8837, 4.4015, 4.7366,
        6.4022, 3.4798, 5.7020, 5.9201, 5.9890, 6.8483, 7.0546],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([5.5348, 5.0898, 6.8430, 6.4080, 5.4338, 6.2000, 7.3807, 4.9974, 4.9748,
        7.1276, 4.3386, 6.2152, 6.0813, 6.3679, 7.4844, 7.4881],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(13.6738, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(13.4120, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([308., 327., 394., 544., 270., 381., 352., 353., 305., 339., 318., 401.,
        307., 432., 438., 370.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([318., 270., 353., 503., 270., 338., 358., 331., 271., 290., 261., 385.,
        258., 386., 423., 344.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([6.1557, 3.6472, 6.9368, 5.9110, 4.5464, 6.7363, 6.9520, 4.7289, 4.5312,
        5.7452, 3.7175, 6.3480, 4.7399, 6.2466, 6.9687, 6.6749],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([11.4857,  6.7396, 12.8776, 10.6169,  7.6884, 12.4908, 12.9440,  8.5108,
         8.0539, 10.8671,  6.4361, 11.9048,  8.5060, 11.2133, 12.4392, 12.3564],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(27.7739, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(27.1151, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([101., 116., 101., 163., 111., 127.,  75., 121., 102., 101., 136.,  84.,
        117., 122., 111., 139.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([105., 115.,  95., 153., 115., 130.,  74., 119., 110.,  88., 132.,  94.,
        118., 133., 117., 132.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 7.7103,  5.3908, 10.1697, 10.5634,  9.6155,  8.4867, 10.6991,  8.9897,
         8.2188,  7.1893,  7.8158,  8.8599,  9.7884, 11.4543, 11.2932, 10.5018],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([14.8433, 11.2083, 19.5224, 20.7007, 18.7288, 16.9423, 20.9573, 18.0346,
        15.9045, 14.8516, 15.6643, 17.8653, 19.3108, 22.1072, 22.4014, 20.3286],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(20.5742, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(23.1791, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([28., 23., 23., 25., 35., 17., 22., 36., 31., 27., 31., 31., 26., 29.,
        37., 24.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([10., 28.,  6., 16., 30., 12., 18., 33., 29., 15., 10., 19., 19., 19.,
        16., 20.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([4.0316, 4.5084, 4.7566, 6.9727, 4.3880, 3.8010, 4.5869, 4.4078, 3.6559,
        4.6029, 3.7363, 6.4068, 5.2451, 5.4757, 7.2736, 4.0917],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([ 7.2372,  7.2456,  8.3976, 10.2317,  7.9006,  5.6537,  8.9531,  7.9968,
         6.2678,  8.3249,  6.1355, 14.3993,  8.9066,  9.9831, 12.5985,  8.8139],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(6.2994, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(5.5458, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([13.,  8.,  8., 11., 19., 13.,  9., 15., 16.,  9.,  7., 11.,  8., 10.,
         9., 11.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([24., 21., 16., 18., 18., 20., 13., 22., 20., 15., 15., 30., 18., 20.,
        22., 29.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([3.1010, 2.3052, 2.4561, 3.0654, 2.2777, 2.0118, 1.6811, 2.3568, 1.6015,
        1.6085, 2.6410, 2.8234, 1.1673, 2.3944, 1.4121, 0.9774],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([5.7143, 3.8531, 4.9377, 5.1578, 4.3488, 3.5975, 3.3519, 4.8221, 3.0054,
        3.3336, 4.2006, 5.0290, 2.4417, 4.2796, 2.6564, 2.2096],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
------------ 0.2849280834197998 backwards -------------------------------
1 recon_decay
tensor(0., device='cuda:0') tensor(1., device='cuda:0') min max before 1
torch.Size([16]) sum mask size 1
torch.Size([16]) losssss
torch.Size([16]) losssss
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(14.1952, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(11.4966, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([ 99.,   1.,  67.,   1., 123., 132.,   1., 149., 207., 231.,  57.,   1.,
          1.,   1., 118., 167.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([527., 254., 403., 254., 501., 504., 254., 685., 742., 838., 440., 254.,
        254., 254., 546., 780.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([6.3138, 0.0000, 5.6322, 0.0000, 4.9378, 5.2772, 0.0000, 4.5403, 5.1252,
        5.0870, 5.9741, 0.0000, 0.0000, 0.0000, 5.2005, 5.3366],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([8.3457, 4.1408, 7.7835, 4.1423, 6.6144, 6.3919, 4.1697, 6.0946, 6.4346,
        6.2269, 8.3631, 4.1803, 4.1421, 4.1456, 7.1503, 6.7075],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(38.2164, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(32.1192, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([25.,  1., 27.,  1., 57., 26.,  1., 56., 42., 82.,  8.,  1.,  1.,  1.,
        22., 52.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 77.,   1.,  62.,   1., 120.,  78.,   1., 132., 108., 203.,  25.,   1.,
          1.,   1.,  70., 152.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([19.6663,  0.0000, 17.9537,  0.0000, 16.5182, 15.2435,  0.0000, 12.9725,
        17.6094, 15.7656, 14.0394,  0.0000,  0.0000,  0.0000, 14.6696, 15.2581],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([30.7400,  0.0000, 29.2690,  0.0000, 27.1849, 24.6329,  0.0000, 21.6512,
        27.3739, 25.5458, 21.9595,  0.0000,  0.0000,  0.0000, 23.6859, 24.8675],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(49.9243, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(49.0790, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([29.,  1., 29.,  1., 63., 38.,  1., 30., 25., 58., 19.,  1.,  1.,  1.,
        18., 23.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([29.,  1., 27.,  1., 53., 25.,  1., 41., 26., 55., 15.,  1.,  1.,  1.,
        26., 33.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([23.4959,  0.0000, 22.3209,  0.0000, 17.7892, 16.4990,  0.0000, 16.8169,
        22.9757, 21.9440, 16.2037,  0.0000,  0.0000,  0.0000, 20.4424, 18.9661],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([42.1721,  0.0000, 41.8419,  0.0000, 32.7407, 31.5129,  0.0000, 30.6754,
        38.9075, 40.2744, 31.8589,  0.0000,  0.0000,  0.0000, 34.7298, 32.4062],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(32.1284, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(35.2981, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([13.,  1., 23.,  1., 18., 27.,  1., 11.,  2., 36., 19.,  1.,  1.,  1.,
        17., 24.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([18.,  2., 11.,  2., 20., 17.,  2., 20.,  9., 25., 11.,  2.,  2.,  2.,
        10., 20.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([17.9878,  0.0000, 15.6908,  0.0000, 12.8723, 14.4886,  0.0000, 14.1625,
         7.4357, 16.2492, 16.0165,  0.0000,  0.0000,  0.0000, 15.5453, 14.6722],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([32.1090,  3.7946, 31.3372,  4.0415, 22.2106, 31.1555,  4.7957, 24.6124,
        19.6640, 30.3231, 30.3001,  5.0767,  3.4931,  3.2387, 28.7507, 30.5266],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(13.3679, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(12.8176, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([ 3.,  1.,  4.,  1.,  1.,  1.,  1.,  4.,  1.,  8.,  2.,  1.,  1.,  1.,
         1., 15.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([13.,  1.,  3.,  1.,  3.,  1.,  1., 13.,  8.,  5.,  1.,  1.,  1.,  1.,
         1., 19.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([4.3015, 0.0000, 4.7500, 0.0000, 0.0000, 0.0000, 0.0000, 5.2729, 0.0000,
        4.4121, 2.9980, 0.0000, 0.0000, 0.0000, 0.0000, 7.0431],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([ 9.2493,  0.0000,  8.9569,  0.0000,  3.2035,  0.0000,  0.0000,  7.4692,
         3.5860,  7.7356,  2.9980,  0.0000,  0.0000,  0.0000,  0.0000, 13.8675],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
tensor(0.1439, device='cuda:0') tensor(0.9778, device='cuda:0') min max before 1
torch.Size([16]) sum mask size 1
torch.Size([16]) losssss
torch.Size([16]) losssss
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(10.6118, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(10.6006, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([147., 131.,  77., 148., 239., 160., 260.,  79., 149., 129., 168., 127.,
        225.,  96., 203., 213.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([176., 168., 104., 157., 257., 196., 244., 100., 182., 154., 180., 178.,
        249.,  88., 260., 230.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([5.8072, 4.6393, 3.3047, 5.2324, 7.7199, 6.2374, 5.9792, 4.6055, 7.5548,
        5.8580, 6.6566, 4.6205, 7.3640, 5.3528, 6.4627, 7.4489],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([6.2819, 5.5639, 4.7909, 5.7853, 7.8788, 7.2431, 6.1825, 5.4805, 7.6556,
        6.6498, 7.3095, 5.1118, 7.9696, 6.8095, 7.0104, 7.6824],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(15.4175, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(12.9236, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([107., 177., 120., 147., 173., 184., 173., 110., 189., 221., 184., 172.,
        199., 180., 101., 129.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([330., 461., 357., 433., 419., 458., 416., 362., 376., 477., 440., 421.,
        466., 397., 389., 376.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([3.6248, 5.6936, 3.3524, 5.4469, 7.1529, 7.1085, 6.1492, 3.6744, 6.6245,
        7.2474, 6.4877, 5.4383, 6.6881, 4.3733, 6.5340, 6.7138],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([ 7.1378,  9.8931,  5.8875,  9.4215, 11.8657, 12.3266, 10.9314,  6.4553,
        11.7060, 12.4306, 11.0038,  9.4515, 11.6700,  7.6563, 10.7060, 12.3724],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(28.3444, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(29.1052, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([108., 114., 105., 128.,  96., 118., 132., 117.,  79., 137., 123.,  69.,
        100., 117.,  96.,  53.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 88.,  89.,  92., 111.,  70.,  91., 107.,  97.,  60., 118., 105.,  55.,
         67.,  88.,  82.,  45.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 8.7867,  9.3856,  5.7491,  9.8392,  8.5758,  7.2105, 11.2830,  9.4535,
         9.3868,  9.5149, 10.0376,  9.1196,  8.1179,  5.8194,  9.1800,  9.4073],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([18.3583, 18.4986, 11.7086, 19.8472, 16.8780, 14.5808, 22.5841, 19.7587,
        18.7878, 18.7089, 19.7943, 19.0923, 16.1017, 11.3589, 17.6754, 19.9309],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(19.6949, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(20.5744, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([38., 31., 27., 37., 40., 26., 42., 36., 45., 27., 38., 19., 36., 36.,
        32., 30.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([27., 28., 23., 51., 35., 16., 33., 46., 76., 34., 41., 28., 26., 50.,
        38., 39.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([3.9451, 4.2927, 5.2419, 4.5680, 5.4818, 3.9721, 4.9130, 3.6841, 3.6440,
        5.1346, 5.2614, 4.5278, 5.2233, 3.3505, 5.0676, 3.9698],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([6.4650, 8.0890, 8.6190, 8.0366, 6.8140, 7.5334, 8.6712, 6.1720, 5.9681,
        9.4455, 8.8800, 7.7309, 9.2976, 5.0907, 7.5980, 6.2430],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(5.9093, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(6.0332, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([ 9.,  8., 13., 16., 18., 12., 15., 16., 22., 14., 18., 13.,  7., 16.,
        12., 23.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([12., 13., 12., 13.,  9., 12., 12., 13., 21., 17., 20., 18., 13., 17.,
        11., 12.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([1.2976, 2.1609, 2.0986, 1.6884, 1.2944, 1.6841, 1.3700, 2.0285, 1.6532,
        1.8395, 1.2550, 1.8575, 1.5662, 1.3586, 2.1127, 1.3898],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([2.6104, 3.8421, 3.7353, 3.2800, 2.8518, 3.4536, 2.8113, 3.8410, 2.9963,
        3.4211, 2.4791, 3.0871, 3.1321, 3.2199, 3.9095, 3.3120],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
------------ 0.27480530738830566 backwards -------------------------------
1 recon_decay
tensor(0., device='cuda:0') tensor(1., device='cuda:0') min max before 1
torch.Size([16]) sum mask size 1
torch.Size([16]) losssss
torch.Size([16]) losssss
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(13.0496, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(15.5375, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([408.,   1.,   1., 222., 116.,   1., 159., 216.,   1.,  21.,   1., 275.,
        347., 263.,   1., 106.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([259., 126., 126., 190., 170., 126., 165., 202., 126., 132., 126., 213.,
        190., 201., 126., 162.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([4.7064, 0.0000, 0.0000, 4.2895, 5.7238, 0.0000, 6.6330, 5.9820, 0.0000,
        5.7551, 0.0000, 5.3837, 4.6132, 4.5347, 0.0000, 5.8757],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([ 6.9870,  4.6115,  4.6005,  7.4130,  9.1683,  4.6104, 10.1945,  8.8798,
         4.6096, 10.1744,  4.6151,  8.1310,  7.0300,  7.4513,  4.6195,  9.4882],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(36.0418, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(38.7343, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([91.,  1.,  1., 78., 34.,  1., 55., 67.,  1., 10.,  1., 38., 84., 72.,
         1., 45.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([56.,  1.,  1., 46., 18.,  1., 35., 43.,  1., 12.,  1., 22., 44., 37.,
         1., 28.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([14.7551,  0.0000,  0.0000, 13.5752, 15.9896,  0.0000, 18.7943, 17.6677,
         0.0000, 17.3907,  0.0000, 15.4283, 14.1203, 15.4232,  0.0000, 16.5650],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([27.2108,  0.0000,  0.0000, 26.0729, 29.1510,  0.0000, 31.4016, 32.2125,
         0.0000, 30.3607,  0.0000, 24.5954, 25.6570, 28.5085,  0.0000, 28.3096],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(48.7713, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(44.9393, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([45.,  1.,  1., 31., 24.,  1., 33., 58.,  1., 15.,  1., 23., 30., 43.,
         1., 29.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([65.,  1.,  1., 73., 33.,  1., 56., 72.,  1., 22.,  1., 37., 42., 54.,
         1., 44.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([18.3032,  0.0000,  0.0000, 15.5109, 21.3436,  0.0000, 27.1477, 23.4856,
         0.0000, 18.8316,  0.0000, 19.9494, 20.7396, 19.5719,  0.0000, 21.1374],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([32.8349,  0.0000,  0.0000, 26.0773, 40.0909,  0.0000, 45.2574, 42.0035,
         0.0000, 34.7083,  0.0000, 36.0976, 37.6475, 35.0638,  0.0000, 35.7650],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(32.1811, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(40.7231, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([33.,  1.,  1., 19., 21.,  1., 10., 22.,  1.,  3.,  1., 18., 20., 16.,
         1., 14.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([14.,  1.,  1.,  5., 10.,  1.,  7.,  7.,  1.,  3.,  1.,  6.,  8.,  7.,
         1., 10.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([14.7371,  0.0000,  0.0000,  8.4301, 15.8583,  0.0000, 16.5024, 15.2560,
         0.0000, 13.0161,  0.0000, 20.7741, 12.3856, 13.7497,  0.0000, 15.3103],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([30.4150,  0.0000,  0.0000, 18.1700, 29.6222,  0.0000, 30.5202, 27.6376,
         0.0000, 26.0322,  0.0000, 43.8891, 24.5424, 31.2145,  0.0000, 25.3761],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(12.3506, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(12.0472, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([12.,  1.,  1.,  1.,  9.,  1.,  1., 26.,  1.,  1.,  1., 19.,  3.,  1.,
         1., 11.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([17.,  1.,  1.,  1., 16.,  1.,  6., 15.,  1.,  1.,  1., 12.,  7.,  1.,
         1., 15.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([5.7580, 0.0000, 0.0000, 0.0000, 4.2559, 0.0000, 0.0000, 4.4854, 0.0000,
        0.0000, 0.0000, 6.2598, 1.8001, 0.0000, 0.0000, 5.2505],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([11.2952,  0.0000,  0.0000,  0.0000,  7.9547,  0.0000,  2.4952,  8.7367,
         0.0000,  0.0000,  0.0000, 12.1403,  7.1882,  0.0000,  0.0000,  8.5658],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
tensor(0.1604, device='cuda:0') tensor(0.9728, device='cuda:0') min max before 1
torch.Size([16]) sum mask size 1
torch.Size([16]) losssss
torch.Size([16]) losssss
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(10.8842, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(11.0534, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([ 50., 216., 193., 120.,  96., 173.,  98.,  90., 105.,  88.,  82., 142.,
         74., 210.,  90.,  39.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 47., 212., 179., 102., 100., 187., 136., 100.,  95.,  86.,  84., 131.,
         73., 166.,  94.,  57.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([3.7025, 6.4562, 6.8661, 5.6520, 6.7776, 8.1177, 5.5236, 5.0328, 5.4863,
        3.1273, 5.0193, 5.2897, 4.0212, 6.0514, 5.4784, 3.7662],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([4.7373, 6.7731, 7.0815, 5.9066, 6.9433, 8.6000, 6.4772, 6.1826, 5.8987,
        4.1653, 5.1105, 5.8302, 5.4879, 6.4979, 6.6688, 5.1396],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(13.9298, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(12.4478, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([232., 317., 357., 229., 283., 318., 351., 278., 246., 299., 260., 367.,
        264., 310., 259., 234.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([465., 531., 646., 435., 521., 561., 641., 508., 440., 500., 535., 624.,
        471., 597., 437., 430.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([3.2564, 5.9730, 6.2859, 4.4360, 5.8598, 6.8082, 5.0557, 4.3871, 4.6799,
        4.3763, 4.6855, 5.7701, 4.2481, 6.0309, 4.4514, 3.3097],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([ 5.6561, 10.3690, 10.7969,  7.6907, 10.3452, 11.9755,  8.4867,  7.6530,
         8.0981,  7.7120,  8.1281, 10.1123,  7.4278,  9.8908,  7.6190,  5.8601],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(26.0694, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(25.0286, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([153., 152., 146., 125., 148., 157., 182., 147., 157., 149., 152., 139.,
        164., 106., 158., 151.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([157., 152., 147., 132., 151., 133., 190., 152., 171., 167., 167., 152.,
        157., 135., 154., 151.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 5.2996,  9.6453, 10.7941,  7.1438, 11.5291,  7.7188,  9.6497,  5.5234,
         9.2201,  7.9306,  8.7802, 10.2875,  7.4012,  7.0600,  5.5211,  5.7158],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([10.6473, 19.2015, 21.0846, 13.9222, 22.3445, 14.6407, 18.7822, 10.4958,
        17.2326, 15.6782, 17.0849, 19.9491, 14.1608, 13.6467, 10.8844, 11.2932],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(18.5054, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(17.6824, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([46., 37., 35., 48., 59., 53., 35., 49., 55., 48., 62., 57., 27., 35.,
        40., 52.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 68.,  79.,  46.,  72.,  77., 115.,  51.,  71., 135., 109.,  78., 100.,
         49.,  71., 102.,  66.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([3.3962, 4.3972, 4.3871, 2.4666, 4.3251, 5.1785, 3.8148, 3.9862, 3.9399,
        5.1475, 5.7452, 4.6729, 5.2819, 3.5642, 4.2228, 4.7026],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([6.2957, 6.7402, 7.6976, 4.2725, 7.5516, 8.1961, 7.3004, 7.0625, 6.1260,
        8.4680, 8.9751, 7.9792, 8.9383, 6.7066, 7.2218, 7.4868],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(6.0009, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(6.1151, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([11.,  8., 22., 14., 19., 15., 12., 11., 16., 10., 16., 11., 16., 16.,
        10., 14.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([12.,  9., 20., 20., 15., 17., 10., 12., 15., 12.,  9., 16.,  9., 17.,
        13., 15.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([1.8548, 3.0175, 2.1910, 1.9641, 1.6852, 1.6847, 2.8858, 2.3811, 2.0362,
        1.8378, 1.3692, 1.6687, 1.7949, 2.5027, 2.1128, 1.9001],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([3.3009, 4.8469, 4.3869, 3.5397, 3.4464, 3.6018, 5.3754, 3.7993, 4.1899,
        3.0247, 2.5881, 2.9842, 2.9689, 5.4980, 3.6933, 3.3258],

  2%|████▎                                                                                                                                                                                                                                                                           | 6/378 [00:03<03:13,  1.92it/s]
------------ 0.27691054344177246 backwards -------------------------------
1 recon_decay
tensor(0., device='cuda:0') tensor(1., device='cuda:0') min max before 1
torch.Size([16]) sum mask size 1
torch.Size([16]) losssss
torch.Size([16]) losssss
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(11.7864, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(14.1952, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([157., 281., 142.,  66., 439.,  37., 370.,  97., 472., 420., 394., 367.,
         87.,   1.,   1.,   1.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([188., 215., 177., 159., 271., 143., 284., 172., 306., 244., 289., 259.,
        131., 127., 127., 127.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([5.4785, 3.5332, 3.5161, 4.1010, 5.1456, 4.4650, 5.4553, 3.9315, 4.6802,
        4.7064, 4.7439, 5.1259, 4.1975, 0.0000, 0.0000, 0.0000],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([8.5518, 6.2114, 6.7831, 7.6399, 6.9922, 8.3987, 7.5223, 7.2400, 6.5689,
        6.6511, 6.7585, 7.4087, 7.8601, 4.4023, 4.4676, 4.4683],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(37.2417, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(36.2564, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([24., 32., 14., 32., 42., 10., 39., 24., 77., 65., 37., 20., 19.,  1.,
         1.,  1.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([32., 31., 15., 38., 49., 10., 50., 27., 82., 68., 45., 21., 21.,  1.,
         1.,  1.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([17.0277, 13.0586, 10.9703, 15.8880, 16.9229, 13.8954, 16.7437, 13.6038,
        16.1828, 16.0024, 15.3422, 16.0476, 16.7599,  0.0000,  0.0000,  0.0000],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([27.9019, 23.0485, 18.7869, 27.7248, 27.5714, 25.6376, 28.7705, 24.5463,
        27.9154, 26.3520, 27.0744, 28.4289, 30.6763,  0.0000,  0.0000,  0.0000],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(48.6046, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(49.0410, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([24., 27., 25., 30., 29., 15., 46., 32., 41., 48., 40., 30., 25.,  1.,
         1.,  1.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([23., 24., 24., 22., 29., 16., 43., 32., 46., 60., 33., 22., 19.,  1.,
         1.,  1.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([23.0294, 17.0870, 12.2711, 15.4852, 21.0519, 18.1723, 22.0494, 14.6482,
        19.9408, 20.5944, 18.7909, 20.1196, 21.3797,  0.0000,  0.0000,  0.0000],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([42.8826, 29.7924, 23.0472, 27.2735, 39.4411, 32.6427, 40.8783, 28.2793,
        35.5052, 35.4538, 36.7406, 36.9505, 42.3930,  0.0000,  0.0000,  0.0000],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(34.0813, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(34.0686, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([19., 14.,  8., 21.,  8., 14., 13., 18., 19., 26., 10.,  6., 12.,  1.,
         1.,  1.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([31., 13., 22., 14., 16., 13., 18., 10., 18., 26., 11.,  8., 15.,  2.,
         2.,  2.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([16.1861, 12.4790, 19.5036, 17.2224, 13.4124, 16.0672, 15.8180, 13.6563,
        18.6638, 13.4830, 15.0332, 15.6422, 17.3397,  0.0000,  0.0000,  0.0000],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([28.1681, 25.6665, 35.1226, 33.1730, 27.9851, 30.4621, 26.5667, 24.6817,
        35.2435, 24.5332, 27.5360, 29.1083, 32.7835,  3.5274,  4.2750,  4.6567],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(11.4749, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(11.4480, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([13.,  1.,  3., 14.,  5.,  7.,  8., 12.,  6.,  2., 14.,  9.,  5.,  1.,
         1.,  1.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([10.,  2.,  7., 11., 12.,  5., 14.,  4.,  9.,  4.,  8., 20.,  7.,  1.,
         1.,  1.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([5.4654, 0.0000, 3.9528, 4.8118, 3.9913, 4.7022, 2.3634, 3.2231, 5.3420,
        0.9265, 3.5065, 3.6875, 4.1401, 0.0000, 0.0000, 0.0000],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([10.1145,  3.7054,  8.7686,  8.6922,  8.0396,  8.2372,  4.6059,  5.6288,
         9.6393,  3.3298,  6.8835,  6.9795,  8.0867,  0.0000,  0.0000,  0.0000],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
tensor(0.1653, device='cuda:0') tensor(0.9886, device='cuda:0') min max before 1
torch.Size([16]) sum mask size 1
torch.Size([16]) losssss
torch.Size([16]) losssss
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(11.0955, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(9.6778, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([126.,  73.,  40.,  74., 146.,  91.,  79.,  77.,  98.,  86.,  80.,  85.,
        105., 134., 149., 217.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([442., 234., 263., 298., 464., 361., 259., 279., 365., 330., 337., 346.,
        298., 425., 469., 556.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([6.2512, 3.5584, 3.7953, 4.6180, 5.9111, 4.7595, 4.4567, 3.7710, 5.0039,
        4.4754, 5.0071, 5.3611, 5.1938, 5.5698, 5.8446, 5.5946],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([7.3570, 4.9861, 5.7016, 6.1620, 7.0333, 6.0275, 5.7032, 5.4609, 6.3302,
        6.1051, 6.3503, 6.6274, 6.5704, 6.6007, 6.8073, 6.5124],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(13.3811, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(14.9663, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([326., 463., 366., 423., 469., 461., 457., 437., 372., 394., 488., 443.,
        454., 389., 475., 455.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([102., 188., 116., 123., 184., 142., 149., 123., 140., 143., 199., 164.,
        139., 114., 174., 255.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([5.5713, 3.5466, 3.6110, 3.7325, 5.9890, 3.8709, 3.7725, 3.1541, 4.2612,
        4.2229, 4.9112, 4.9586, 4.2830, 4.4281, 5.5708, 5.8298],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([10.0783,  6.6223,  5.9849,  6.7952, 10.6753,  6.6801,  7.0371,  6.3859,
         7.2814,  7.1931,  9.3994,  9.3448,  7.8268,  8.3472, 10.0051, 11.0269],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(29.9604, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(28.5218, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([ 43., 116., 101., 118.,  74., 120., 114.,  88.,  99.,  99.,  93.,  69.,
         99.,  97., 100.,  48.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 62., 130., 122., 104.,  87., 129., 118., 100., 117., 111.,  98.,  78.,
        112., 112., 112.,  55.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 8.6871,  7.0621,  6.9495,  8.4502, 10.5689,  8.0853,  8.3223,  7.5032,
         9.2145,  9.0209, 10.1161,  8.4238,  8.3909,  7.9008,  7.8818, 10.2348],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([15.9365, 13.3464, 14.0145, 16.7033, 20.5398, 16.0184, 16.7357, 14.7821,
        17.6167, 16.8913, 19.3845, 15.9439, 15.5874, 15.1090, 15.5168, 19.3710],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(19.1480, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(20.9460, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([38., 35., 34., 38., 39., 43., 34., 57., 34., 53., 48., 43., 30., 43.,
        30., 34.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([33., 38., 41., 52., 36., 41., 27., 81., 20., 56., 39., 33., 53., 39.,
        24., 23.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([4.5431, 4.3998, 4.3838, 4.3393, 5.2828, 3.5415, 4.2330, 3.2106, 4.7191,
        4.5105, 5.0224, 5.3318, 4.9214, 5.7073, 4.9661, 4.2681],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([7.5079, 6.8040, 8.1610, 7.2871, 9.7522, 6.7852, 7.3278, 5.7183, 8.0919,
        7.7879, 8.2789, 8.2164, 7.2237, 9.3110, 8.8014, 7.4962],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(6.7696, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(7.9771, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([ 7., 10., 10.,  7.,  6.,  6.,  8., 14.,  5.,  8., 13., 10.,  8.,  4.,
         6.,  8.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 5.,  8.,  7.,  7.,  6.,  5.,  6., 11.,  4.,  9.,  9.,  5.,  5.,  6.,
         7.,  5.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([2.4159, 1.3200, 1.3548, 2.1474, 2.7898, 1.5856, 2.6652, 2.0563, 1.3723,
        2.1771, 1.7703, 2.0122, 1.8711, 1.0949, 1.4740, 0.8235],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([3.8424, 2.8055, 2.3939, 4.6196, 5.4828, 3.1988, 4.7756, 4.3234, 2.7271,
        4.3782, 3.8213, 3.4125, 4.1886, 2.7595, 3.0232, 1.4823],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
------------ 0.27569055557250977 backwards -------------------------------
1 recon_decay
tensor(0., device='cuda:0') tensor(1., device='cuda:0') min max before 1
torch.Size([16]) sum mask size 1
torch.Size([16]) losssss
torch.Size([16]) losssss
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(14.4665, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(16.2594, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([ 38.,  15.,   1.,   1., 133.,   1., 102., 135., 191.,   1.,   1., 163.,
        130.,  64., 174.,   1.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([20., 19.,  1.,  1., 33.,  1., 29., 47., 28.,  1.,  1., 32., 28.,  1.,
        60.,  1.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([5.0296, 5.0881, 0.0000, 0.0000, 4.8533, 0.0000, 5.0255, 5.4120, 4.4367,
        0.0000, 0.0000, 5.2810, 6.1487, 4.8673, 4.9923, 0.0000],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([5.1112, 5.1893, 0.0000, 0.0000, 4.9360, 0.0000, 5.1517, 6.2053, 4.4796,
        0.0000, 0.0000, 5.3629, 6.7870, 4.8673, 5.2626, 0.0000],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(36.0418, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(38.3820, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([36., 35.,  1.,  1., 72.,  1., 61., 66., 95.,  1.,  1., 68., 21., 20.,
        62.,  1.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([24., 25.,  1.,  1., 39.,  1., 30., 42., 74.,  1.,  1., 47., 20., 12.,
        42.,  1.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([12.3990, 16.2680,  0.0000,  0.0000, 15.4466,  0.0000, 14.2973, 15.0122,
        13.9944,  0.0000,  0.0000, 16.7576, 15.7816, 15.1671, 15.1186,  0.0000],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([22.9650, 31.3268,  0.0000,  0.0000, 28.0639,  0.0000, 26.9041, 28.5381,
        24.3845,  0.0000,  0.0000, 28.9878, 27.2690, 25.6697, 28.5249,  0.0000],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(40.6466, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(51.6357, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([ 57.,  59.,   1.,   1., 109.,   1.,  91.,  99., 136.,   1.,   1.,  83.,
         62.,  40., 104.,   1.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([16., 18.,  1.,  1., 26.,  1., 27., 39., 38.,  1.,  1., 16., 10.,  7.,
        31.,  1.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([13.9939, 15.8803,  0.0000,  0.0000, 16.7859,  0.0000, 15.3713, 14.5967,
        17.4671,  0.0000,  0.0000, 16.8661, 15.2012, 14.5628, 16.0134,  0.0000],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([26.1494, 29.1436,  0.0000,  0.0000, 32.6773,  0.0000, 31.6059, 26.3128,
        34.5578,  0.0000,  0.0000, 29.6447, 27.2468, 30.5075, 31.1245,  0.0000],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(34.5222, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(36.0577, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([ 9., 22.,  1.,  1.,  9.,  1., 13., 11., 24.,  1.,  1., 11.,  9., 17.,
         8.,  1.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 7., 14.,  2.,  2., 12.,  2., 18., 11., 20.,  2.,  2., 15.,  5.,  4.,
        11.,  2.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([13.2760, 17.3077,  0.0000,  0.0000, 15.5937,  0.0000, 13.9572, 13.0924,
        17.7870,  0.0000,  0.0000, 16.4981, 11.6188, 17.3659, 13.2676,  0.0000],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([22.1165, 34.6724,  4.7460,  3.7583, 31.4006,  4.3620, 26.6390, 26.0778,
        36.0358,  4.3812,  3.5720, 32.5250, 21.9488, 35.8109, 25.5253,  4.0795],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(9.4144, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(15.6127, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([ 7., 21.,  1.,  1.,  3.,  1., 15., 17., 17.,  1.,  1., 21.,  8., 12.,
        18.,  1.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([2., 2., 1., 1., 1., 1., 3., 1., 1., 1., 1., 5., 1., 1., 2., 1.],
       device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([2.6264, 5.5210, 0.0000, 0.0000, 2.4172, 0.0000, 4.2942, 1.7870, 4.1095,
        0.0000, 0.0000, 5.0761, 2.9273, 3.9786, 4.1322, 0.0000],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([ 4.2725, 10.4740,  0.0000,  0.0000,  2.4172,  0.0000,  8.4938,  1.7870,
         4.1095,  0.0000,  0.0000, 11.0653,  2.9273,  3.9786,  7.0858,  0.0000],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
tensor(0.1985, device='cuda:0') tensor(0.9906, device='cuda:0') min max before 1
torch.Size([16]) sum mask size 1
torch.Size([16]) losssss
torch.Size([16]) losssss
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(10.8588, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(10.3706, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([133.,  74., 133.,  46.,  65., 105., 170., 100., 138., 105.,  85., 109.,
        153., 135., 117.,  62.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([240., 178., 207., 110., 108., 198., 232., 173., 203., 155., 145., 176.,
        201., 175., 171., 123.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([5.8036, 4.3971, 5.9334, 5.0689, 2.3741, 4.8012, 5.6018, 5.4353, 5.8454,
        4.5226, 4.0539, 5.4339, 5.3988, 4.4421, 5.7419, 3.1478],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([6.4510, 5.4489, 6.1640, 6.4131, 2.9843, 5.6915, 6.1064, 6.7963, 6.4616,
        5.5523, 5.0828, 5.7299, 5.9132, 5.2787, 6.5128, 5.1356],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(13.6696, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(12.4484, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([312., 367., 372., 352., 266., 390., 371., 282., 376., 304., 367., 378.,
        378., 391., 359., 314.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([525., 514., 586., 515., 468., 628., 510., 484., 515., 529., 548., 554.,
        577., 531., 567., 538.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([5.2553, 4.6444, 4.6718, 4.2944, 2.6038, 4.7174, 4.1180, 3.8997, 4.8977,
        4.2238, 3.2277, 4.7401, 5.2993, 4.3096, 5.2772, 2.3957],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([8.6304, 8.0084, 7.7625, 7.5477, 4.5194, 7.9341, 7.2984, 6.6554, 8.2381,
        6.7742, 5.5586, 7.8032, 8.9315, 7.5917, 9.2555, 4.1665],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(28.7497, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(26.4292, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([ 72.,  63., 106., 107., 117., 108., 121.,  90., 106., 104.,  94., 111.,
        106., 116.,  91., 109.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([103.,  92., 125., 139., 125., 143., 139., 129., 126., 150., 125., 139.,
        138., 128., 129., 137.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 8.3290,  9.5960,  9.2809,  7.9782,  5.4311,  8.3454,  8.6566,  6.5066,
        10.9063,  5.6883,  7.6854, 10.3946,  7.4607,  9.9354, 10.0040,  4.6741],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([16.0886, 17.6159, 17.5457, 15.6444, 10.6816, 15.6377, 16.6482, 12.3123,
        20.9596, 10.9141, 14.2435, 19.0086, 14.1171, 18.8465, 18.2405,  9.2638],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(18.8087, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(19.1848, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([51., 43., 43., 51., 49., 59., 35., 35., 40., 67., 47., 41., 48., 63.,
        47., 34.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 50.,  69.,  54.,  54.,  83., 106.,  68.,  56.,  48.,  72., 106.,  49.,
         70.,  93.,  78.,  33.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([4.1760, 5.3651, 3.4686, 3.9929, 2.7770, 4.3192, 3.6419, 3.2693, 4.8845,
        5.1323, 4.0279, 4.4453, 5.0952, 4.0828, 4.6111, 3.6096],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([7.9791, 8.6255, 5.8210, 7.2484, 4.7977, 7.3425, 6.4692, 6.6698, 8.3482,
        9.3508, 6.4304, 7.0734, 8.7355, 6.8054, 7.1828, 7.1556],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(6.7328, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(6.6055, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([ 5., 12., 13.,  6.,  8.,  6., 14.,  5.,  9.,  8., 13.,  9.,  6.,  9.,
         9.,  5.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 9., 15., 14., 12., 10., 12., 16., 11., 11., 12., 16.,  5., 14., 22.,
        12.,  8.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([1.2780, 2.2199, 1.8667, 1.6545, 1.6907, 2.4109, 2.0605, 2.0801, 1.4913,
        1.5589, 1.1567, 2.5032, 1.4137, 0.4438, 1.6299, 1.1044],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([2.6126, 3.6034, 3.4052, 2.9632, 3.5961, 3.9847, 3.3137, 3.4600, 2.6945,
        2.7410, 2.5184, 4.7723, 3.4604, 1.1934, 3.4329, 2.5974],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
------------ 0.2748832702636719 backwards -------------------------------
1 recon_decay
tensor(0., device='cuda:0') tensor(1., device='cuda:0') min max before 1
torch.Size([16]) sum mask size 1
torch.Size([16]) losssss
torch.Size([16]) losssss
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(14.2666, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(11.2580, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([ 10., 151.,   1.,   1.,  86.,   1.,   1.,   1., 101., 115.,   1.,  73.,
        150.,  33.,  21.,  90.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([292., 679., 254., 254., 331., 254., 254., 254., 520., 349., 254., 479.,
        719., 384., 281., 527.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([3.5856, 5.4980, 0.0000, 0.0000, 4.0992, 0.0000, 0.0000, 0.0000, 6.4685,
        3.1493, 0.0000, 5.8799, 5.4468, 4.1100, 3.6844, 6.1962],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([6.9885, 7.1047, 3.9367, 3.8913, 6.4981, 3.9613, 3.9124, 3.9412, 7.7194,
        5.4158, 3.9622, 8.0370, 6.8628, 6.7228, 7.1591, 8.0059],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(37.3691, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(34.8634, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([ 8., 42.,  1.,  1., 10.,  1.,  1.,  1., 60.,  8.,  1., 31., 43., 24.,
        13., 21.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([17., 54.,  1.,  1., 15.,  1.,  1.,  1., 61., 16.,  1., 38., 60., 32.,
        13., 24.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([13.6246, 17.6107,  0.0000,  0.0000, 16.6997,  0.0000,  0.0000,  0.0000,
        18.0777, 15.8044,  0.0000, 16.2204, 15.3586, 13.2710, 11.8911, 16.7750],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([22.6363, 31.1609,  0.0000,  0.0000, 28.8593,  0.0000,  0.0000,  0.0000,
        31.2776, 26.5584,  0.0000, 25.9120, 24.8785, 22.7678, 19.7160, 27.0451],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(45.0473, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(50.8610, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([19., 39.,  1.,  1., 22.,  1.,  1.,  1., 66., 19.,  1., 39., 55., 40.,
        21., 45.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([12., 12.,  1.,  1.,  8.,  1.,  1.,  1., 30.,  4.,  1., 17., 20., 28.,
        13., 20.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([16.1138, 19.7454,  0.0000,  0.0000, 19.0655,  0.0000,  0.0000,  0.0000,
        20.1501, 17.3697,  0.0000, 19.5432, 17.3173, 14.2410, 14.7147, 17.7988],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([29.9102, 41.0006,  0.0000,  0.0000, 33.8422,  0.0000,  0.0000,  0.0000,
        41.4788, 34.6079,  0.0000, 39.8093, 32.0382, 28.2522, 28.5020, 34.7280],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(33.8744, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(31.0195, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([10., 18.,  1.,  1.,  6.,  1.,  1.,  1., 17., 13.,  1., 17., 21., 18.,
         7., 13.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([15., 39.,  2.,  2.,  9.,  2.,  2.,  2., 26., 20.,  2., 42., 30., 19.,
        18., 12.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([13.1829, 15.4631,  0.0000,  0.0000, 12.6129,  0.0000,  0.0000,  0.0000,
        18.1877, 16.9904,  0.0000, 16.9686, 14.4690, 13.6866, 13.3743, 14.7227],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([24.6130, 28.0176,  4.1125,  3.5360, 20.5792,  3.7407,  2.8317,  2.0687,
        33.2642, 31.5252,  2.6898, 28.7696, 27.3735, 25.5567, 24.4153, 24.6836],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(8.7970, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(8.7518, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([ 2., 17.,  1.,  1.,  3.,  1.,  1.,  1., 22., 11.,  1., 29.,  9., 19.,
         3., 22.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 5., 10.,  1.,  1.,  6.,  1.,  1.,  1., 10., 14.,  1., 48.,  8., 11.,
         7., 13.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([1.5696, 3.1336, 0.0000, 0.0000, 2.9100, 0.0000, 0.0000, 0.0000, 2.7353,
        4.3646, 0.0000, 3.9017, 3.6431, 2.9750, 2.0454, 2.0987],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([3.3926, 5.9907, 0.0000, 0.0000, 4.0137, 0.0000, 0.0000, 0.0000, 5.7050,
        6.8194, 0.0000, 6.6417, 7.2688, 5.5109, 3.7054, 4.5484],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
tensor(0.1425, device='cuda:0') tensor(0.9885, device='cuda:0') min max before 1
torch.Size([16]) sum mask size 1
torch.Size([16]) losssss
torch.Size([16]) losssss
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(10.0477, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(9.8806, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([234., 205., 153., 247., 163., 136., 144., 198., 276., 130., 222., 199.,
        135., 230., 168., 222.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([359., 360., 228., 350., 323., 266., 278., 242., 386., 258., 313., 327.,
        164., 309., 217., 340.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([3.6664, 4.4532, 3.8533, 3.4649, 4.0909, 3.7417, 3.1148, 3.8208, 4.0880,
        3.2619, 3.1267, 3.4820, 3.1114, 3.9634, 3.6339, 3.6902],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([4.8923, 6.0385, 5.3149, 4.6793, 5.6416, 5.7264, 4.9940, 5.1095, 5.3734,
        5.2206, 4.3369, 5.3065, 4.7443, 4.9661, 5.1656, 5.2116],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(13.7372, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(15.1832, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([325., 443., 367., 365., 391., 333., 396., 410., 423., 362., 363., 349.,
        369., 359., 322., 378.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([132., 154., 140., 104., 197.,  96., 115., 180., 171., 161., 136., 102.,
        138., 144., 117.,  99.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([3.7811, 4.0101, 3.2589, 3.9747, 4.8540, 2.7270, 2.7612, 2.8512, 4.4223,
        2.4450, 3.7442, 3.6015, 3.6635, 4.1056, 3.3827, 4.0969],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([7.0301, 7.2417, 5.9588, 6.9687, 9.6281, 5.6034, 5.4194, 5.6519, 7.7954,
        5.0260, 6.5580, 7.2490, 6.4023, 7.2599, 6.8765, 7.9753],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(27.7136, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(26.6329, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([ 58., 112., 111., 136.,  86., 121., 140., 100., 130., 145., 132., 124.,
        110.,  99., 119., 127.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 81., 117., 119., 170.,  73., 106., 135., 111., 148., 139., 136., 119.,
        153., 102., 127., 137.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([7.7738, 7.4326, 6.7367, 7.1542, 9.8758, 6.2267, 5.1462, 5.9434, 9.6823,
        5.0957, 5.3990, 8.4984, 6.7633, 6.5466, 5.0000, 7.5004],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([14.0405, 13.6625, 13.2536, 13.7224, 19.0533, 12.4643, 10.0409, 11.7411,
        18.6027, 10.2137, 10.4439, 16.0622, 12.3722, 12.3749,  9.5984, 14.3445],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(18.1971, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(19.7279, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([36., 56., 58., 41., 64., 68., 91., 61., 51., 86., 73., 54., 61., 47.,
        63., 61.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 34.,  69.,  89.,  38.,  39., 137., 178.,  64.,  35., 115.,  62.,  85.,
         88.,  19.,  76.,  56.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([3.9969, 3.6864, 3.2176, 4.4823, 4.2509, 2.6738, 2.3618, 3.1015, 4.9352,
        3.9218, 4.8391, 4.1363, 4.2546, 3.3043, 2.6137, 6.0849],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([ 6.6923,  6.9846,  5.5337,  8.2549,  8.3613,  4.8253,  4.3514,  6.5215,
         9.3210,  6.5499,  8.3796,  6.2700,  6.9785,  7.2682,  4.9927, 10.0894],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(6.5451, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(6.7344, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([ 5., 13.,  5.,  7.,  8., 11.,  7.,  8., 10., 12.,  8., 17.,  5.,  8.,
         4., 14.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 5.,  9., 12.,  8., 10., 12., 15., 11., 11.,  9.,  9., 15., 11., 11.,
         8., 14.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([1.0681, 1.6683, 1.2342, 1.8173, 0.8476, 1.1915, 1.4446, 0.7592, 1.0458,
        0.8219, 2.2070, 0.8396, 1.1270, 0.7373, 1.4096, 1.9673],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([1.5854, 3.3006, 2.2935, 3.1166, 1.7223, 2.7244, 2.3637, 2.0807, 2.5006,
        1.2578, 3.8145, 1.9018, 2.4200, 1.6410, 2.8223, 4.0791],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
------------ 0.27424097061157227 backwards -------------------------------
1 recon_decay
tensor(0., device='cuda:0') tensor(1., device='cuda:0') min max before 1
torch.Size([16]) sum mask size 1
torch.Size([16]) losssss
torch.Size([16]) losssss
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(11.5228, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(15.5698, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([440., 104., 301.,   1., 330., 244., 289.,   1.,  69., 381.,   1., 107.,
          1., 400., 671., 418.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([185., 142., 176., 126., 195., 194., 177., 126., 138., 227., 126., 134.,
        126., 207., 266., 229.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([4.5449, 3.2635, 5.8183, 0.0000, 4.4514, 5.9450, 5.8523, 0.0000, 5.0722,
        4.5502, 0.0000, 2.8855, 0.0000, 5.1563, 5.4569, 4.4256],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([6.8793, 7.0123, 8.8225, 4.1814, 7.2234, 8.7767, 8.8619, 4.1008, 8.9096,
        7.0480, 4.1231, 6.6223, 4.0599, 7.8015, 7.4830, 6.7751],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(37.4205, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(39.0191, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([ 64.,  28.,  37.,   1., 114.,  50.,  21.,   1.,  14.,  46.,   1.,  19.,
          1.,  54.,  66.,  38.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([37., 22., 12.,  1., 81., 41., 17.,  1.,  9., 40.,  1., 12.,  1., 35.,
        58., 33.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([15.9638, 15.8496, 17.4260,  0.0000, 15.0712, 21.0213, 17.9686,  0.0000,
        19.2595, 16.2601,  0.0000, 13.0366,  0.0000, 16.0591, 17.0661, 15.0835],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([28.5757, 29.4473, 28.7723,  0.0000, 28.7877, 37.8110, 33.3715,  0.0000,
        32.6300, 30.2268,  0.0000, 22.0471,  0.0000, 28.0774, 27.9260, 26.6427],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(50.6231, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(53.2950, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([39., 36., 33.,  1., 54., 28., 27.,  1., 21., 34.,  1., 27.,  1., 39.,
        32., 42.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([39., 22., 19.,  1., 45., 19., 15.,  1., 14., 31.,  1., 20.,  1., 25.,
        31., 27.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([21.6567, 16.9927, 22.0717,  0.0000, 17.5793, 28.3466, 21.6723,  0.0000,
        19.9043, 23.5000,  0.0000, 15.3612,  0.0000, 19.5374, 18.8878, 17.9420],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([36.5974, 33.5598, 38.3554,  0.0000, 30.5596, 54.4191, 38.2235,  0.0000,
        37.7632, 46.1265,  0.0000, 30.3054,  0.0000, 37.1645, 35.1895, 34.5239],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(29.5113, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(30.6908, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([47., 33., 14.,  1., 20., 25., 26.,  1., 20., 23.,  1., 36.,  1., 37.,
        45., 38.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([53., 35., 42.,  2., 38., 26., 19.,  2., 14., 51.,  2., 28.,  2., 31.,
        41., 41.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([11.7177, 14.6852, 13.7380,  0.0000, 11.1414, 17.0282, 14.3468,  0.0000,
        15.4707, 14.7985,  0.0000, 12.3305,  0.0000, 12.9592, 11.6583, 11.4949],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([21.5740, 28.4719, 25.6130,  4.3467, 20.2525, 29.3997, 25.2316,  3.2323,
        30.2381, 25.3178,  3.7023, 25.3023,  3.1850, 25.9026, 23.4737, 21.9882],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(9.2579, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(10.1049, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([11., 15., 14.,  1.,  9., 30., 14.,  1.,  2.,  6.,  1.,  3.,  1.,  3.,
         6., 24.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 9.,  5., 29.,  1.,  8., 20., 13.,  1.,  1.,  9.,  1.,  1.,  1.,  3.,
         5., 16.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([1.8153, 4.5586, 4.6634, 0.0000, 5.3956, 5.3129, 3.3422, 0.0000, 1.7994,
        1.5722, 0.0000, 1.6999, 0.0000, 3.0637, 1.4602, 2.6189],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([ 3.9538,  9.8220,  7.7823,  0.0000, 10.6097, 10.0683,  5.8392,  0.0000,
         1.7994,  2.8037,  0.0000,  1.6999,  0.0000,  6.1275,  4.7884,  5.4569],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
tensor(0.2004, device='cuda:0') tensor(0.9879, device='cuda:0') min max before 1
torch.Size([16]) sum mask size 1
torch.Size([16]) losssss
torch.Size([16]) losssss
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(9.2346, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(8.6588, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([208., 226., 230., 182., 210., 201., 203., 451., 337., 439., 208., 277.,
        309., 213., 209., 322.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([431., 435., 408., 380., 422., 439., 445., 753., 575., 707., 355., 560.,
        538., 423., 467., 563.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([3.2871, 3.0226, 3.1126, 2.1279, 2.8359, 3.0003, 2.8301, 3.5076, 3.3048,
        3.3783, 2.5321, 3.1238, 3.2994, 2.8801, 3.0209, 2.7905],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([4.5884, 4.3762, 4.3772, 3.6480, 4.1636, 4.3731, 4.3353, 4.1645, 4.2773,
        4.2215, 3.7297, 4.2991, 4.4033, 4.3249, 4.3551, 3.9249],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(13.9521, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(13.5320, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([324., 324., 344., 337., 310., 306., 275., 337., 340., 369., 287., 316.,
        311., 246., 294., 325.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([337., 332., 317., 330., 301., 355., 284., 390., 382., 346., 270., 328.,
        301., 277., 300., 299.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([3.7259, 2.6893, 2.9032, 2.4159, 4.0286, 2.8009, 2.7288, 3.6992, 3.9998,
        3.7641, 3.0457, 3.5763, 3.3115, 2.6580, 3.3770, 3.4412],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([6.5306, 4.9417, 5.1921, 4.2442, 6.6538, 4.8221, 4.8192, 6.5401, 6.8231,
        6.6365, 5.9296, 6.4193, 6.0659, 4.8998, 6.1851, 6.2661],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(28.1243, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(28.1069, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([111., 110., 122., 112., 109., 114., 105.,  71.,  70., 144.,  83., 110.,
        129., 117., 113., 129.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([114., 105., 129., 104.,  97., 117., 108.,  84.,  67., 159.,  76., 114.,
        119., 116., 102., 126.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([7.3665, 4.6473, 6.1784, 4.3096, 6.7048, 4.9684, 6.9593, 7.1718, 7.4255,
        6.4327, 6.5314, 7.9363, 5.9861, 6.9134, 5.4880, 9.5352],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([14.1153,  8.9712, 12.3860,  8.1558, 12.0952, 10.0061, 13.3328, 14.3457,
        14.2368, 12.4576, 13.3137, 15.9802, 11.9008, 14.0882, 10.5728, 18.7998],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(19.7806, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(21.3009, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([40., 34., 29., 24., 26., 35., 28., 37., 42., 29., 38., 29., 50., 29.,
        26., 51.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([39., 56., 64., 24., 24., 33., 49., 22., 26., 27., 37., 27., 66., 62.,
        27., 39.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([3.6625, 3.9905, 3.3787, 3.0549, 5.7367, 3.5533, 3.4593, 3.8896, 4.8748,
        4.6636, 3.7983, 4.4966, 3.6171, 2.7849, 2.8870, 4.0640],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([6.8131, 5.9438, 5.2647, 6.3988, 8.1354, 6.6796, 5.8646, 5.4049, 8.0117,
        9.2920, 6.0600, 8.1300, 5.3990, 5.1475, 6.1417, 7.8352],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(6.5812, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(6.0169, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([ 9., 12.,  5.,  6.,  3.,  7., 12., 16.,  9.,  8.,  8., 11.,  7., 10.,
        13.,  7.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([19., 24., 17., 18., 13., 15., 16., 18., 18., 21., 14., 13., 18., 29.,
        20., 16.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([1.3329, 0.8919, 0.5428, 0.5887, 0.4807, 0.9273, 0.9078, 2.3168, 1.1335,
        1.7781, 2.1609, 1.2822, 0.5098, 0.6036, 0.6266, 0.9896],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([2.4387, 1.8278, 2.5827, 1.4017, 1.4622, 1.9729, 1.7702, 4.1711, 2.7332,
        4.3300, 4.4427, 2.2733, 1.1668, 0.9819, 1.2801, 2.6207],

  3%|███████▏                                                                                                                                                                                                                                                                       | 10/378 [00:05<03:05,  1.99it/s]
------------ 0.2846856117248535 backwards -------------------------------
1 recon_decay
tensor(0., device='cuda:0') tensor(1., device='cuda:0') min max before 1
torch.Size([16]) sum mask size 1
torch.Size([16]) losssss
torch.Size([16]) losssss
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(11.0721, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(15.3047, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([  1., 168.,   1.,   1., 701.,   1., 126., 502.,   1.,   1.,   1.,   1.,
          1., 166.,   1., 238.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([127., 158., 127., 127., 306., 127., 152., 247., 127., 127., 127., 127.,
        127., 176., 127., 190.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([0.0000, 4.3983, 0.0000, 0.0000, 5.3339, 0.0000, 3.7103, 4.2978, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 3.8408, 0.0000, 5.9394],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([3.6436, 7.3781, 3.8408, 3.6956, 7.1690, 3.7796, 6.8129, 6.3837, 3.8382,
        3.7120, 3.6870, 3.6981, 3.7981, 6.7212, 3.6754, 8.4620],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(37.5663, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(30.6117, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([ 1., 22.,  1.,  1., 69.,  1., 32., 49.,  1.,  1.,  1.,  1.,  1., 20.,
         1., 44.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([  1.,  64.,   1.,   1., 181.,   1.,  67., 134.,   1.,   1.,   1.,   1.,
          1.,  63.,   1., 100.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 0.0000, 18.9382,  0.0000,  0.0000, 17.2252,  0.0000, 18.0296, 15.4090,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000, 12.8817,  0.0000, 19.5575],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([ 0.0000, 31.2348,  0.0000,  0.0000, 28.4606,  0.0000, 30.3105, 25.2478,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000, 20.8476,  0.0000, 31.3819],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(46.3671, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(46.6214, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([ 1., 56.,  1.,  1., 74.,  1., 44., 58.,  1.,  1.,  1.,  1.,  1., 37.,
         1., 37.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 1., 35.,  1.,  1., 65.,  1., 37., 59.,  1.,  1.,  1.,  1.,  1., 30.,
         1., 40.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 0.0000, 18.0008,  0.0000,  0.0000, 19.6728,  0.0000, 17.8363, 16.9431,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000, 13.5195,  0.0000, 24.0507],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([ 0.0000, 36.1720,  0.0000,  0.0000, 36.1922,  0.0000, 34.5253, 31.0489,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000, 24.9822,  0.0000, 41.3354],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(32.6898, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(37.6614, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([ 1., 25.,  1.,  1., 18.,  1., 34., 14.,  1.,  1.,  1.,  1.,  1., 12.,
         1.,  7.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 2.,  8.,  2.,  2., 12.,  2., 25.,  7.,  2.,  2.,  2.,  2.,  2.,  6.,
         2.,  6.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 0.0000, 16.2641,  0.0000,  0.0000, 15.5713,  0.0000, 16.7359, 13.1521,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000, 16.6152,  0.0000, 15.6010],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([ 3.1686, 30.8503,  2.7443,  3.5618, 29.1992,  4.3970, 33.6272, 25.0553,
         3.5145,  3.7671,  4.1494,  3.6722,  2.2513, 31.0451,  4.0993, 27.9863],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(9.0972, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(9.5181, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([ 1.,  8.,  1.,  1., 10.,  1., 24., 24.,  1.,  1.,  1.,  1.,  1., 11.,
         1., 15.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 1.,  5.,  1.,  1., 18.,  1., 21., 13.,  1.,  1.,  1.,  1.,  1.,  7.,
         1., 17.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([0.0000, 5.1652, 0.0000, 0.0000, 4.1915, 0.0000, 4.6363, 2.2623, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 4.0457, 0.0000, 4.4720],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([ 0.0000, 10.3265,  0.0000,  0.0000,  7.5387,  0.0000,  8.9421,  4.7672,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  7.7806,  0.0000,  7.6950],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
tensor(0.2308, device='cuda:0') tensor(0.9931, device='cuda:0') min max before 1
torch.Size([16]) sum mask size 1
torch.Size([16]) losssss
torch.Size([16]) losssss
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(9.2633, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(9.7678, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([275., 229., 234., 165., 177., 176., 271., 223., 237., 364., 295., 220.,
        178., 163., 222., 196.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([332., 246., 302., 250., 209., 265., 279., 303., 267., 299., 321., 267.,
        221., 193., 278., 191.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([2.1573, 2.4458, 2.7445, 2.8050, 2.7578, 2.3444, 2.6928, 2.8009, 2.9843,
        2.4726, 2.8262, 2.3814, 2.7561, 2.6020, 2.0061, 1.9571],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([3.4954, 3.9724, 4.4552, 4.6633, 4.2411, 4.2690, 3.8657, 4.3323, 4.5500,
        3.5020, 4.1628, 4.1477, 4.6192, 4.5201, 3.8839, 3.5299],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(13.1501, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(13.1263, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([576., 618., 398., 419., 472., 463., 587., 431., 580., 530., 491., 549.,
        462., 467., 475., 404.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([474., 501., 369., 349., 424., 436., 552., 348., 448., 494., 467., 411.,
        402., 411., 384., 337.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([2.9574, 3.0160, 3.3717, 2.8660, 2.7904, 2.9846, 3.1190, 2.8757, 3.0797,
        3.1840, 3.5983, 2.7282, 2.6454, 2.7166, 2.7557, 2.9004],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([4.8517, 5.1716, 5.6097, 5.4309, 5.1793, 5.0280, 5.5939, 4.6739, 5.4809,
        5.3163, 6.3683, 4.9953, 4.5006, 4.8652, 5.1754, 5.0274],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(30.1674, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(28.4236, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([111.,  76.,  62.,  68.,  72.,  85.,  90.,  77., 104.,  69.,  74.,  93.,
         77.,  80., 102.,  70.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([130., 113.,  82.,  70.,  87., 102., 118., 100., 123., 108.,  88., 103.,
        100., 106., 106.,  97.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([6.7373, 6.7723, 6.9676, 6.9297, 5.5869, 5.7342, 6.2695, 5.6842, 6.5891,
        8.4442, 7.4436, 7.4261, 6.5457, 5.5759, 7.0339, 6.1465],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([13.0395, 12.8301, 13.1624, 14.0190, 12.2202, 10.6059, 11.9271, 10.7150,
        12.8294, 15.2495, 14.5129, 14.2499, 12.6271, 10.6268, 13.9075, 11.8489],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(21.8168, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(20.3975, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([32., 27.,  8., 20., 12., 20., 21., 15., 21., 25., 27., 26., 18., 11.,
        29., 23.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 52.,  61.,  45., 125.,  65.,  29.,  31.,  23.,  90.,  44.,  43., 102.,
         67.,  56.,  61.,  51.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([3.8900, 4.9053, 3.5661, 3.2626, 2.3112, 3.9870, 3.0297, 4.1121, 3.9562,
        4.6396, 4.4731, 2.7054, 5.0303, 2.8230, 5.5522, 3.8563],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([5.6696, 8.4800, 5.6231, 5.2110, 4.7902, 7.2788, 5.7940, 7.1355, 6.1769,
        7.7370, 7.6874, 4.9112, 8.0584, 5.1352, 9.3523, 6.6016],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(5.7354, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(6.2888, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([18.,  7., 10., 14., 12., 16., 12.,  6., 15., 16., 11., 10., 12., 12.,
        16., 17.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([12., 20., 10., 18., 12.,  9.,  7., 17.,  8., 18., 15., 11., 13., 12.,
        17., 12.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([1.2878, 0.9343, 1.3175, 1.1511, 0.9329, 0.5616, 1.0224, 1.6071, 1.0153,
        0.9634, 1.1966, 0.7865, 0.9995, 0.9722, 0.9196, 1.4995],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([2.3771, 2.0249, 2.5356, 1.7388, 1.7194, 1.0510, 2.3724, 2.6209, 1.9537,
        3.1045, 2.3712, 1.3952, 1.7047, 1.9553, 1.6425, 2.9175],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
------------ 0.27492332458496094 backwards -------------------------------
1 recon_decay
tensor(0., device='cuda:0') tensor(1., device='cuda:0') min max before 1
torch.Size([16]) sum mask size 1
torch.Size([16]) losssss
torch.Size([16]) losssss
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(12.2452, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(15.5768, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([ 97.,   1.,   1., 295., 690.,  59., 180., 204., 490.,  78., 343., 332.,
        245., 143., 329.,   1.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([144., 126., 126., 160., 285., 114., 129., 164., 247., 137., 194., 203.,
        185., 157., 221., 126.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([5.0837, 0.0000, 0.0000, 3.2843, 5.2579, 2.8504, 3.1887, 6.2175, 4.0848,
        2.9825, 5.6825, 5.3475, 4.9331, 4.6796, 4.7652, 0.0000],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([7.5655, 2.9586, 3.0339, 5.5672, 6.7016, 5.6589, 5.0310, 8.4037, 5.7398,
        5.7463, 7.5719, 7.2559, 7.0840, 7.0604, 6.4261, 2.7647],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(37.1109, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(35.1880, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([ 14.,   1.,   1.,  78.,  80.,  14.,  21.,  44., 137.,  27.,  59.,  48.,
         46.,  16.,  62.,   1.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 11.,   1.,   1., 101.,  96.,  22.,  29.,  55., 175.,  33.,  76.,  66.,
         70.,  20.,  71.,   1.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([15.7381,  0.0000,  0.0000, 13.8494, 16.8164, 15.4071, 13.6951, 19.0747,
        13.0445, 14.4679, 17.7490, 17.1889, 16.7911, 14.2988, 16.0953,  0.0000],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([24.5762,  0.0000,  0.0000, 24.2155, 27.1054, 26.1690, 22.7309, 30.7687,
        23.1959, 25.0109, 29.1665, 29.6048, 27.1115, 23.4336, 27.7429,  0.0000],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(51.5608, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(50.2344, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([ 7.,  1.,  1., 51., 23., 21., 10., 27., 37., 32., 33., 33., 30., 12.,
        38.,  1.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([20.,  1.,  1., 45., 43., 10., 10., 39., 69., 24., 37., 33., 37., 13.,
        45.,  1.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([18.0364,  0.0000,  0.0000, 17.3712, 23.3041, 15.5146, 16.1718, 27.4591,
        17.0118, 15.7870, 22.5729, 21.1280, 23.4563, 19.1324, 20.4761,  0.0000],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([31.5733,  0.0000,  0.0000, 30.3262, 41.9941, 28.9726, 27.9050, 47.4372,
        28.6000, 31.5388, 39.3705, 37.8366, 41.8332, 35.1110, 35.5450,  0.0000],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(37.9076, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(37.7226, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([ 6.,  1.,  1., 17.,  8., 12.,  2.,  2.,  9., 10.,  8.,  6., 15.,  5.,
         8.,  1.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([10.,  1.,  1., 22., 15.,  4.,  5.,  7., 18.,  7., 11.,  9., 23.,  3.,
        25.,  1.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([11.4730,  0.0000,  0.0000,  6.2801, 22.6851, 12.9436,  7.4594,  9.0556,
        12.1531, 16.8935, 12.8736, 15.8531, 20.2583, 14.4565, 13.7220,  0.0000],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([22.3275,  0.0000,  0.0000, 12.8359, 41.8118, 23.0118, 17.5745, 23.4915,
        23.2441, 32.5000, 29.3198, 29.0418, 35.2193, 26.3042, 24.6672,  0.0000],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(9.8037, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(10.6743, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([ 1.,  1.,  1.,  8., 27.,  4.,  9.,  1., 17., 11.,  6.,  3.,  3., 10.,
         1.,  1.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 4.,  1.,  1.,  7., 21.,  1., 20.,  3., 10.,  5.,  2.,  5., 14.,  5.,
         5.,  1.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([0.0000, 0.0000, 0.0000, 1.9057, 5.0835, 3.6949, 4.5961, 0.0000, 2.5418,
        3.8053, 3.3484, 1.9141, 3.2687, 3.7572, 0.0000, 0.0000],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([1.7887, 0.0000, 0.0000, 3.9225, 9.0911, 3.6949, 7.6845, 2.0097, 4.5538,
        7.6673, 5.5167, 3.4446, 3.9332, 6.9552, 0.9318, 0.0000],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
tensor(0.2506, device='cuda:0') tensor(0.9899, device='cuda:0') min max before 1
torch.Size([16]) sum mask size 1
torch.Size([16]) losssss
torch.Size([16]) losssss
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(8.7489, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(8.7886, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([296., 540., 440., 416., 351., 275., 358., 288., 340., 355., 250., 316.,
        303., 331., 472., 333.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([371., 576., 481., 506., 415., 291., 383., 350., 364., 385., 296., 348.,
        329., 403., 501., 353.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([2.2985, 2.8331, 2.3429, 2.9760, 2.1899, 2.3182, 2.3678, 2.7723, 2.6811,
        2.2170, 2.4334, 2.6905, 2.1981, 2.5789, 2.4439, 2.4665],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([3.4195, 3.7191, 3.2313, 3.8770, 3.1081, 3.7481, 3.4556, 3.7896, 3.7793,
        3.2622, 3.6605, 3.7327, 3.1837, 3.7366, 3.3276, 3.3996],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(14.8067, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(12.8970, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([196., 232., 280., 290., 194., 201., 244., 256., 201., 251., 182., 227.,
        211., 163., 248., 212.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([487., 604., 634., 580., 509., 430., 517., 453., 482., 481., 470., 473.,
        526., 462., 602., 452.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([2.2249, 3.4351, 3.6806, 3.6209, 2.7605, 2.5170, 2.8985, 2.8763, 4.0454,
        3.4843, 2.9846, 2.7558, 2.8050, 3.0165, 3.7939, 2.8906],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([3.7110, 5.6986, 6.0287, 6.1770, 4.5934, 4.3789, 5.0297, 4.8457, 6.6355,
        5.9672, 4.8917, 4.8581, 4.6920, 4.6898, 6.2336, 4.8810],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(25.4824, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(27.5808, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([162., 164., 171., 183., 194., 194., 160., 159., 180., 135., 152., 164.,
        150., 155., 187., 176.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([119., 130., 133., 134., 129., 126.,  98.,  92., 127.,  79., 127., 105.,
        106., 120., 136., 111.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([4.2456, 6.3458, 6.0376, 6.8866, 5.0371, 3.7160, 5.4670, 4.9520, 4.9557,
        6.2611, 5.5576, 5.7374, 5.0981, 4.5466, 5.9905, 4.5588],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([ 8.4662, 12.3420, 11.6073, 13.4878, 10.6744,  7.8024, 10.8043, 11.0565,
        10.1014, 13.2561, 11.1592, 12.0507, 10.6840,  8.9320, 12.0041,  9.3159],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(21.7095, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(24.1955, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([13., 15., 25., 19., 21., 41., 26., 13., 17., 18.,  8.,  8.,  9., 10.,
        20., 11.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([10., 13., 10., 16., 11., 46., 21., 19., 26., 24., 12., 24., 14., 31.,
        18., 24.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([4.6606, 4.3916, 2.6416, 6.3829, 3.9717, 2.7072, 5.3930, 3.1071, 1.9007,
        4.8009, 3.5118, 4.6603, 3.8384, 2.8054, 3.4677, 2.9166],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([ 9.0100,  8.2059,  5.7241, 11.7618,  7.7003,  4.0392,  9.0172,  4.5291,
         4.9258,  8.6133,  6.0277,  5.8359,  6.3223,  4.5183,  5.8354,  4.0353],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(5.8168, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(6.2828, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([12., 18., 13., 18.,  9., 23., 22., 11., 17., 19.,  7., 12., 11., 11.,
        22., 13.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([13., 19., 20., 10., 11., 28., 19., 14., 24., 20.,  9., 14., 19., 19.,
        29., 14.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([1.2517, 2.0515, 1.3238, 1.6122, 1.4018, 0.8141, 0.8773, 1.0272, 1.0252,
        1.1699, 1.1583, 1.1815, 0.7804, 1.2416, 0.9249, 0.7294],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([2.1042, 4.3603, 2.4465, 3.6604, 2.7085, 1.5801, 1.7626, 1.7705, 1.8991,
        2.3488, 2.4851, 2.3113, 1.6465, 2.3554, 1.9010, 1.4628],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
------------ 0.27422118186950684 backwards -------------------------------
1 recon_decay
tensor(0., device='cuda:0') tensor(1., device='cuda:0') min max before 1
torch.Size([16]) sum mask size 1
torch.Size([16]) losssss
torch.Size([16]) losssss
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(14.5375, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(15.3047, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([258., 131.,   1.,   1.,   1., 124., 132.,   1.,  78., 258.,  74., 139.,
        108.,  85., 240.,  83.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([247., 136., 127., 127., 127., 189., 221., 127., 190., 295., 163., 232.,
        202., 197., 219., 194.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([5.6064, 4.0250, 0.0000, 0.0000, 0.0000, 4.1305, 5.5182, 0.0000, 6.9240,
        5.0393, 5.1264, 5.2512, 7.2226, 6.7583, 5.3809, 6.3878],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([6.5345, 4.9827, 1.7976, 1.4349, 1.5832, 5.4531, 6.4057, 1.5096, 8.1400,
        6.0083, 6.4909, 6.2428, 8.4914, 8.0243, 6.2953, 7.5101],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(37.1537, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(37.8878, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([81., 38.,  1.,  1.,  1., 45., 62.,  1., 44., 81., 55., 46., 43., 19.,
        50., 38.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([73., 41.,  1.,  1.,  1., 49., 47.,  1., 46., 84., 37., 36., 34., 14.,
        42., 25.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([15.8421, 12.7429,  0.0000,  0.0000,  0.0000, 12.1829, 16.9614,  0.0000,
        19.2659, 15.1260, 13.6975, 14.8292, 18.3270, 17.2864, 16.4377, 17.1355],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([28.2292, 22.5977,  0.0000,  0.0000,  0.0000, 20.7260, 29.4511,  0.0000,
        33.2765, 25.2997, 23.7241, 25.3990, 31.8372, 31.2796, 29.1863, 30.4276],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(54.3568, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(51.6357, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([37., 16.,  1.,  1.,  1., 16., 25.,  1., 21., 42., 20., 16., 24., 15.,
        31., 28.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([39., 26.,  1.,  1.,  1., 31., 28.,  1., 24., 71., 26., 16., 20., 22.,
        38., 21.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([21.7223, 16.5058,  0.0000,  0.0000,  0.0000, 19.3177, 21.9006,  0.0000,
        25.5684, 22.2341, 18.5647, 18.1773, 23.4577, 20.6096, 17.9586, 19.2518],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([41.4322, 28.1722,  0.0000,  0.0000,  0.0000, 34.6348, 38.4845,  0.0000,
        43.8278, 38.4077, 31.8596, 33.1976, 45.0875, 38.0274, 29.6586, 35.4402],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(31.5212, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(41.7453, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([15.,  9.,  1.,  1.,  1., 23., 28.,  1., 11., 32., 19., 28., 15., 11.,
        20., 34.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 2.,  2.,  1.,  1.,  1.,  4., 17.,  1.,  3., 16.,  2., 11.,  3.,  1.,
         8.,  3.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([12.8162, 10.0471,  0.0000,  0.0000,  0.0000, 13.8533, 16.8214,  0.0000,
        15.5539, 17.5866, 11.5512, 13.1438, 12.8933, 14.1204, 13.7696, 16.7921],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([20.8212, 13.7680,  0.0000,  0.0000,  0.0000, 34.1500, 33.6048,  0.0000,
        28.2629, 35.3917, 18.9295, 27.9119, 24.6071, 14.1204, 27.0836, 31.1461],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(11.3715, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(10.4871, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([25.,  1.,  1.,  1.,  1.,  2., 17.,  1.,  5.,  8.,  3.,  4., 12., 18.,
         3., 10.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([20., 12.,  1.,  1.,  1.,  6., 26.,  1., 14., 19.,  1.,  3., 12., 14.,
        10.,  7.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([3.3215, 0.0000, 0.0000, 0.0000, 0.0000, 3.2099, 5.9860, 0.0000, 4.4929,
        3.8783, 3.9219, 5.2751, 2.2428, 4.4672, 3.4077, 5.2276],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([ 7.1612,  2.4020,  0.0000,  0.0000,  0.0000,  5.7122,  9.2482,  0.0000,
         7.9173,  7.5242,  3.9219,  8.6953,  3.1555,  8.3264,  6.8126, 10.7467],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
tensor(0.2482, device='cuda:0') tensor(0.9927, device='cuda:0') min max before 1
torch.Size([16]) sum mask size 1
torch.Size([16]) losssss
torch.Size([16]) losssss
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(9.4366, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(8.9577, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([153., 115., 213., 166., 178., 209.,  91., 177., 129., 186., 101.,  95.,
        143., 187., 179., 180.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([363., 278., 403., 392., 392., 426., 319., 417., 327., 354., 263., 267.,
        334., 427., 393., 378.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([2.3883, 2.5079, 2.2717, 2.3234, 2.3528, 2.3027, 2.2538, 2.5908, 2.4552,
        2.4720, 1.6999, 1.8420, 2.0837, 2.2690, 2.7148, 2.6753],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([3.1244, 3.2851, 3.0131, 3.0304, 3.1223, 3.1484, 3.2038, 3.3878, 3.3674,
        3.2638, 2.7156, 2.7497, 3.0309, 2.9612, 3.4865, 3.3938],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(14.8401, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(13.3238, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([241., 210., 273., 240., 189., 259., 214., 192., 156., 288., 228., 217.,
        223., 289., 226., 232.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([397., 363., 463., 438., 355., 389., 389., 402., 320., 533., 471., 372.,
        414., 466., 435., 414.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([2.9889, 2.2509, 2.7554, 3.1781, 3.6073, 2.8457, 2.4139, 3.2363, 2.5630,
        3.7715, 2.2525, 2.9455, 2.5328, 3.0788, 3.1361, 3.5587],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([5.0177, 3.9518, 4.6558, 5.4090, 5.5454, 4.9814, 4.0017, 5.4620, 4.1842,
        6.3384, 3.7393, 4.8915, 4.4709, 5.4220, 5.0703, 5.7955],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(27.9155, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(27.3459, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([102., 108., 157., 129., 107., 122., 114.,  92., 127., 147., 129., 136.,
        127., 118., 128., 119.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([101., 107., 171., 133., 119., 138., 123., 112., 132., 149., 139., 133.,
        142., 120., 144., 122.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([5.5191, 3.5047, 5.4564, 6.0581, 5.1306, 6.7301, 5.6277, 4.7507, 5.2562,
        6.0113, 3.9892, 3.6252, 5.7000, 6.5403, 3.9591, 5.3600],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([10.5300,  6.9331, 10.6190, 12.1780,  9.7289, 13.1113, 11.0100,  9.0694,
        10.0118, 11.5442,  7.8231,  6.7566, 11.0340, 12.7375,  7.4903, 10.0993],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(18.3194, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(19.7413, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([43., 58., 77., 68., 47., 49., 47., 44., 53., 68., 45., 60., 63., 45.,
        56., 38.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 65.,  88.,  64.,  75.,  60.,  67.,  66.,  53., 120.,  42.,  38., 102.,
        132.,  59.,  51.,  59.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([2.8807, 2.4455, 3.7750, 3.1233, 3.8085, 3.7952, 3.6388, 3.0807, 2.0181,
        4.7458, 3.0326, 2.7208, 2.8942, 3.7085, 3.1296, 2.6852],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([5.0758, 4.3130, 7.3629, 4.9831, 7.1164, 6.6915, 5.6089, 5.2309, 3.8755,
        8.0834, 5.7101, 4.8393, 4.7369, 6.5530, 6.0925, 5.3132],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(6.6510, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(7.1474, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([ 7.,  5.,  9.,  5.,  5., 18.,  6.,  9.,  5.,  8.,  4.,  9., 11., 10.,
         8.,  5.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([14.,  5., 10., 11.,  6., 17.,  5., 15.,  8.,  5.,  6., 10., 18.,  3.,
         7.,  6.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([1.1156, 1.4008, 1.8212, 1.6813, 1.8177, 1.3200, 1.3599, 1.0266, 1.1149,
        1.0302, 1.7923, 0.8248, 0.8178, 1.0904, 2.0628, 1.9405],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([2.1518, 2.4766, 3.3631, 3.7900, 3.6082, 2.0702, 2.6800, 2.5292, 2.5164,
        2.4667, 3.5602, 2.0964, 1.5674, 2.4375, 5.0366, 2.8658],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
------------ 0.27478766441345215 backwards -------------------------------
1 recon_decay
tensor(0., device='cuda:0') tensor(1., device='cuda:0') min max before 1
torch.Size([16]) sum mask size 1
torch.Size([16]) losssss
torch.Size([16]) losssss
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(11.9888, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(15.5698, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([837., 228.,  43., 346.,   1., 102., 276., 371.,  96., 146.,   1., 314.,
          1., 615., 677., 369.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([317., 196., 137., 157., 126., 115., 183., 195., 145., 162., 126., 204.,
        126., 276., 280., 210.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([5.0834, 5.7118, 3.3291, 3.4326, 0.0000, 4.7833, 4.9422, 5.9475, 3.5830,
        5.0181, 0.0000, 3.6589, 0.0000, 4.6509, 5.1862, 5.0738],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([5.5600, 6.2863, 3.9382, 3.9897, 0.3904, 5.3388, 5.6037, 6.5187, 4.3984,
        5.5074, 0.7376, 4.2616, 0.3144, 5.3134, 5.7248, 5.4813],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(38.3434, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(38.0213, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([69., 37.,  9., 47.,  1., 16., 30., 47., 29., 34.,  1., 56.,  1., 40.,
        68., 42.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([68., 43., 14., 52.,  1., 21., 33., 58., 24., 34.,  1., 46.,  1., 50.,
        71., 39.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([17.6627, 19.3830, 11.3946, 12.6394,  0.0000, 15.0711, 17.9751, 17.8236,
        16.9453, 16.9306,  0.0000, 16.3657,  0.0000, 19.5704, 17.1791, 15.0875],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([29.4275, 33.7839, 18.3669, 22.7636,  0.0000, 27.1831, 27.0923, 30.2108,
        30.5790, 27.9033,  0.0000, 29.8763,  0.0000, 33.6646, 27.8065, 25.4476],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(51.8815, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(48.9200, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([45., 36.,  2., 44.,  1., 11., 19., 48., 26., 19.,  1., 53.,  1., 58.,
        28., 25.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([69., 38.,  9., 43.,  1., 18., 32., 65., 28., 24.,  1., 53.,  1., 69.,
        42., 35.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([23.6267, 23.1521, 10.7793, 16.9015,  0.0000, 20.8563, 25.9440, 24.9099,
        16.2309, 24.6816,  0.0000, 15.3970,  0.0000, 18.7745, 21.1011, 20.6817],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([41.3090, 40.4073, 18.3325, 28.6634,  0.0000, 36.4248, 44.8868, 43.6637,
        31.5672, 42.3047,  0.0000, 27.5691,  0.0000, 32.8853, 38.1729, 37.2429],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(36.0802, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(41.5603, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([ 2.,  9.,  4., 19.,  1.,  9., 17., 10., 18.,  7.,  1., 11.,  1., 16.,
         7.,  2.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 3.,  5.,  7.,  6.,  1.,  6., 14., 10.,  5.,  2.,  1.,  8.,  1.,  9.,
         5.,  1.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 7.4116, 17.6262, 11.0338,  9.1867,  0.0000, 18.0658, 21.2782, 18.6388,
        17.1925, 13.4827,  0.0000, 13.3729,  0.0000, 15.0341, 18.1634,  4.9977],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([14.0352, 30.8977, 22.7769, 16.1390,  0.0000, 35.8873, 40.8460, 34.6407,
        32.7002, 20.4692,  0.0000, 22.5364,  0.0000, 29.2150, 34.9634,  4.9977],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(10.4684, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(10.8781, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([14., 15.,  1.,  2.,  1.,  7., 12.,  3., 12., 12.,  1.,  2.,  1., 15.,
        25., 14.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 9.,  8.,  6.,  3.,  1., 10., 18.,  8.,  9., 14.,  1.,  8.,  1.,  4.,
        19.,  8.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([4.0893, 4.4806, 0.0000, 0.6285, 0.0000, 3.3656, 4.7067, 2.5452, 4.4606,
        4.1174, 0.0000, 3.5149, 0.0000, 3.8698, 4.8649, 2.5343],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([6.9321, 9.3187, 1.2086, 1.6172, 0.0000, 6.2488, 8.0544, 6.4075, 8.5111,
        7.8485, 0.0000, 6.4331, 0.0000, 7.4230, 9.9570, 4.6731],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
tensor(0.2640, device='cuda:0') tensor(0.9957, device='cuda:0') min max before 1
torch.Size([16]) sum mask size 1
torch.Size([16]) losssss
torch.Size([16]) losssss
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(8.6470, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(8.6936, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([293., 312., 265., 245., 391., 383., 348., 304., 227., 211., 376., 352.,
        326., 349., 250., 293.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([365., 368., 311., 312., 480., 391., 370., 413., 306., 264., 427., 450.,
        390., 394., 349., 333.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([2.2118, 1.7481, 1.6206, 1.4678, 2.2831, 2.0169, 2.4014, 2.1999, 1.0426,
        1.4309, 2.3704, 2.0560, 1.6465, 1.9078, 1.4321, 1.5289],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([2.7951, 2.3292, 2.1665, 2.0981, 2.8914, 2.7155, 3.1434, 2.7408, 1.7423,
        2.0432, 3.1632, 2.6568, 2.2147, 2.3480, 2.0551, 2.0455],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(13.6989, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(12.2392, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([441., 341., 355., 375., 441., 303., 401., 454., 378., 444., 466., 439.,
        459., 335., 356., 359.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([844., 686., 701., 770., 777., 642., 820., 765., 765., 767., 893., 858.,
        713., 639., 793., 705.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([2.9909, 2.6769, 2.7130, 2.4673, 3.4888, 2.8990, 3.1039, 3.3454, 2.3793,
        2.4529, 3.2505, 3.4128, 2.7550, 2.9033, 2.4667, 2.6420],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([4.8921, 4.2972, 4.4676, 3.9635, 5.6592, 5.0655, 5.1092, 5.6102, 4.0423,
        4.2574, 5.1511, 5.5150, 4.8118, 4.7277, 3.8675, 4.6449],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(26.6185, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(27.1827, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([165., 135., 120., 150., 138.,  90., 153., 155., 154., 127., 143., 150.,
        146.,  87., 130., 138.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([136., 125., 115., 129., 144.,  78., 151., 137., 138., 131., 129., 156.,
        132.,  98., 136., 123.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([5.4651, 5.2551, 5.2167, 4.6910, 6.0390, 5.7758, 5.4627, 6.0743, 3.7668,
        6.2736, 6.0830, 7.0589, 7.0243, 4.7143, 3.4825, 5.0033],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([10.4927, 10.2073, 10.1510,  9.6398, 11.9362, 12.0300, 10.2625, 12.2692,
         7.4363, 12.5088, 11.6606, 13.2898, 14.5997,  8.9679,  6.7676,  9.7617],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(19.3919, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(22.3822, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([19., 29., 51., 33., 29., 19., 33., 24., 25., 30., 30., 32., 42., 41.,
        29., 42.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([17., 15., 44., 29., 20., 19., 33., 17., 28., 25., 20., 19., 36., 34.,
        27., 23.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([5.7663, 2.8770, 3.0977, 2.2147, 2.5241, 3.5307, 3.6434, 3.5130, 3.2313,
        4.0402, 3.2486, 3.1621, 3.3016, 3.7520, 3.0221, 4.1727],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([10.2614,  5.9204,  5.1238,  4.2123,  4.7759,  7.4493,  6.4670,  6.2067,
         5.8558,  6.0496,  6.5264,  5.9514,  6.2662,  6.3003,  5.5019,  7.1771],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(6.4737, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(7.8114, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([10.,  7., 17.,  7.,  6., 12.,  4., 12.,  5.,  5.,  5.,  3., 10.,  8.,
         4.,  9.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 4.,  5.,  6.,  5.,  6.,  6.,  7.,  6.,  4.,  6.,  8.,  7., 10.,  5.,
         5.,  4.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([1.1510, 1.2583, 1.2529, 1.6387, 0.9398, 1.5224, 0.4519, 0.8095, 0.7660,
        1.7539, 0.7241, 1.9799, 1.1495, 1.6929, 1.0576, 1.5449],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([2.7512, 2.3881, 2.6815, 4.1518, 1.8031, 2.2963, 1.5009, 1.7616, 1.7094,
        3.2228, 1.9018, 3.5882, 1.8630, 2.3467, 2.1802, 2.8718],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
------------ 0.27497410774230957 backwards -------------------------------
1 recon_decay

  4%|██████████                                                                                                                                                                                                                                                                     | 14/378 [00:07<03:03,  1.99it/s]
torch.Size([16]) sum mask size 1
torch.Size([16]) losssss
torch.Size([16]) losssss
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(11.8289, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(14.1952, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([169., 751., 538., 404., 760.,   1., 783.,   1., 441., 637., 150.,  86.,
          1.,  19.,  31.,   1.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([197., 444., 295., 253., 418., 127., 414., 127., 251., 369., 184., 131.,
        127., 135., 141., 127.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([4.1052, 4.9756, 4.4858, 4.9486, 5.1484, 0.0000, 5.3810, 0.0000, 4.6702,
        5.5940, 3.6946, 4.7406, 0.0000, 3.2086, 5.0213, 0.0000],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([4.3077, 5.5127, 4.8496, 5.1752, 5.4910, 0.0229, 5.7163, 0.1764, 4.9075,
        5.8583, 3.9309, 4.9184, 0.0779, 3.3016, 5.1703, 0.0231],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(36.5298, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(34.8021, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([ 33.,  53.,  84.,  63.,  78.,   1.,  79.,   1.,  58., 111.,  23.,  21.,
          1.,   4.,   9.,   1.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 48.,  93., 120.,  83., 103.,   1., 121.,   1.,  86., 133.,  25.,  21.,
          1.,   3.,  13.,   1.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([13.7028, 16.5971, 15.4439, 16.1573, 15.6139,  0.0000, 15.4860,  0.0000,
        16.2187, 16.4558, 13.0436, 16.1867,  0.0000,  9.8933, 12.2289,  0.0000],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([23.2384, 26.1999, 26.0884, 25.3275, 24.9036,  0.0000, 26.0400,  0.0000,
        25.4390, 27.7154, 22.6445, 29.4734,  0.0000, 15.0567, 19.4517,  0.0000],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(48.7713, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(49.0410, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([21., 48., 42., 36., 62.,  1., 61.,  1., 38., 57., 16., 24.,  1.,  7.,
         5.,  1.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([28., 48., 45., 45., 54.,  1., 66.,  1., 34., 61., 16., 19.,  1.,  9.,
         9.,  1.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([14.5456, 17.1705, 21.8080, 19.9235, 20.4551,  0.0000, 19.3825,  0.0000,
        21.7501, 20.6927, 14.4596, 21.1889,  0.0000,  5.1995, 14.5449,  0.0000],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([27.0719, 30.7056, 38.7824, 34.5224, 38.6619,  0.0000, 33.8281,  0.0000,
        37.3292, 39.0219, 25.8924, 40.9991,  0.0000, 10.6976, 24.0346,  0.0000],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(33.9507, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(32.7947, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([12., 17., 10., 22., 11.,  1.,  9.,  1., 11., 13., 10., 13.,  1.,  3.,
         8.,  1.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([23., 29., 13., 37., 18.,  2., 24.,  2., 18., 21.,  8., 16.,  2.,  5.,
        12.,  2.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([15.1780, 15.6181, 16.0556, 12.3067, 15.6945,  0.0000, 14.6914,  0.0000,
        15.6421, 14.5193, 10.4890, 16.9965,  0.0000,  9.5105, 15.3225,  0.0000],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([28.1703, 29.4705, 29.6941, 22.1489, 29.0270,  2.9326, 27.3767,  3.9599,
        28.8262, 26.2769, 18.1979, 31.7117,  4.2831, 17.5358, 28.6882,  3.9346],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(12.1912, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(11.4454, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([ 9.,  9.,  2., 11.,  8.,  1.,  3.,  1.,  4.,  4.,  4.,  3.,  1.,  1.,
         1.,  1.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([14.,  9.,  4., 21., 22.,  1., 10.,  1.,  6.,  1.,  2.,  7.,  1.,  1.,
         1.,  1.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([4.9797, 5.4449, 2.7584, 4.0900, 6.3363, 0.0000, 3.7195, 0.0000, 2.5794,
        3.4083, 3.0601, 3.2540, 0.0000, 0.0000, 0.0000, 0.0000],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([ 8.6149, 10.5417,  6.8335,  7.5422, 10.6384,  0.0000,  7.4450,  0.0000,
         7.7931,  3.4083,  5.5077,  6.8963,  0.0000,  0.0000,  0.0000,  0.0000],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
tensor(0.2973, device='cuda:0') tensor(0.9962, device='cuda:0') min max before 1
torch.Size([16]) sum mask size 1
torch.Size([16]) losssss
torch.Size([16]) losssss
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(9.0769, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(8.5755, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([221., 125., 262., 200., 197., 117., 229., 146., 160.,  79., 133., 175.,
        151., 182., 176., 121.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([426., 326., 473., 339., 387., 237., 487., 270., 280., 285., 360., 351.,
        223., 391., 388., 296.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([1.8405, 2.1552, 2.2748, 2.0458, 2.0970, 1.1882, 1.7216, 2.0429, 3.0477,
        1.2942, 1.4789, 1.4126, 2.9890, 1.6079, 1.7949, 1.5896],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([2.3489, 2.3311, 2.9177, 2.8531, 2.8205, 2.0385, 2.4824, 2.9203, 4.0834,
        2.2068, 1.9366, 1.8479, 4.0013, 2.2765, 2.3850, 1.8538],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(13.0571, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(14.1236, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([743., 518., 732., 467., 429., 561., 816., 465., 547., 547., 430., 687.,
        434., 715., 664., 634.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([332., 284., 383., 263., 189., 268., 389., 232., 281., 289., 209., 406.,
        230., 385., 337., 295.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([2.6186, 3.1153, 3.1393, 2.5575, 2.1244, 2.8384, 2.4240, 2.5277, 2.5627,
        2.2338, 2.3659, 2.8532, 2.6411, 2.1870, 2.8215, 2.7015],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([4.2822, 5.2357, 5.2302, 4.6162, 3.9994, 4.9912, 4.0680, 4.4247, 4.5615,
        3.7699, 3.7371, 4.5817, 4.8060, 3.7131, 4.5044, 4.3778],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(30.2886, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(29.3225, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([103.,  51.,  83.,  85.,  86.,  90., 119.,  56.,  72., 104.,  89.,  93.,
         61., 112., 108.,  92.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([144.,  56.,  98.,  85.,  98.,  93., 134.,  71.,  89., 117.,  98., 105.,
         71., 127., 120., 104.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([4.8971, 5.6225, 5.0929, 5.5581, 4.6733, 7.6309, 4.5190, 5.5460, 6.0757,
        2.9001, 2.8639, 5.2509, 6.5261, 3.6764, 4.8402, 5.1983],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([ 9.3438, 11.5313, 10.4682, 10.9259,  9.4633, 15.3901,  8.9539, 11.8113,
        11.8748,  5.5327,  5.4610,  9.8298, 12.6846,  7.1198,  9.5281, 10.4349],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(18.2494, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(19.0798, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([86., 59., 56., 27., 53., 82., 75., 68., 58., 41., 39., 70., 66., 41.,
        54., 69.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 60.,  86.,  39.,  60.,  74., 203.,  79., 111.,  79.,  41.,  87.,  69.,
         96.,  46.,  41., 109.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([3.5752, 2.6504, 3.3348, 4.4358, 3.2032, 3.6642, 3.4144, 3.3138, 2.6784,
        2.6409, 3.0069, 3.6857, 3.0691, 2.7465, 3.2005, 3.0452],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([5.9052, 5.1494, 5.9438, 7.7942, 5.9347, 5.5753, 6.1061, 5.4393, 4.9635,
        4.8310, 5.1883, 7.2025, 5.6318, 5.0356, 6.1774, 5.2321],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(6.5198, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(6.9264, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([27., 12.,  9.,  4.,  6.,  6., 15.,  3.,  5.,  4., 10.,  7.,  4.,  8.,
         7., 15.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([17., 10., 13., 11., 12., 11., 14., 11.,  5.,  7., 15.,  6., 12., 11.,
         7.,  8.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([1.2221, 1.3801, 1.1335, 0.3643, 1.2571, 1.1416, 1.8917, 0.1207, 0.8222,
        1.0397, 1.6065, 1.3808, 1.2997, 1.0294, 0.9625, 1.3654],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([2.2081, 2.2805, 2.5193, 1.4986, 1.8803, 2.1585, 3.2501, 0.7784, 1.5008,
        1.9986, 2.5425, 2.5801, 1.9741, 2.1960, 1.7952, 1.8917],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
------------ 0.27501702308654785 backwards -------------------------------
1 recon_decay
tensor(0., device='cuda:0') tensor(1., device='cuda:0') min max before 1
torch.Size([16]) sum mask size 1
torch.Size([16]) losssss
torch.Size([16]) losssss
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(11.5921, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(15.5698, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([422.,   1., 371., 184.,   1., 227., 386.,   1., 107.,   1., 320., 102.,
        407., 380., 838.,   1.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([220., 126., 215., 165., 126., 169., 209., 126., 108., 126., 205., 153.,
        231., 185., 322., 126.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([5.4475, 0.0000, 4.8041, 5.3536, 0.0000, 5.7950, 5.0084, 0.0000, 4.2576,
        0.0000, 4.1770, 4.4090, 4.4475, 4.6654, 5.2674, 0.0000],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([5.6272, 0.0099, 5.1599, 5.5064, 0.0810, 5.9658, 5.5245, 0.0112, 4.3803,
        0.0080, 4.3755, 4.5425, 4.7287, 4.8599, 5.6882, 0.0093],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(36.9231, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(37.0409, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([46.,  1., 62., 16.,  1., 50., 31.,  1., 28.,  1., 68., 35., 65., 37.,
        56.,  1.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([69.,  1., 70., 12.,  1., 51., 36.,  1., 29.,  1., 66., 32., 52., 19.,
        68.,  1.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([14.8800,  0.0000, 17.8244, 14.6357,  0.0000, 18.2533, 17.4023,  0.0000,
        14.6996,  0.0000, 13.4881, 16.8523, 15.8358, 14.0073, 17.1947,  0.0000],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([25.1006,  0.0000, 31.9600, 20.2726,  0.0000, 30.0059, 31.8473,  0.0000,
        27.4287,  0.0000, 23.7913, 30.9442, 28.3156, 22.0374, 28.0093,  0.0000],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(52.2800, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(47.4344, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([26.,  1., 33.,  4.,  1., 22., 25.,  1., 18.,  1., 27., 18., 33.,  8.,
        42.,  1.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([58.,  1., 61., 16.,  1., 41., 48.,  1., 19.,  1., 47., 45., 52., 28.,
        80.,  1.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([15.8601,  0.0000, 20.6136, 18.0048,  0.0000, 27.4090, 19.8146,  0.0000,
        18.7487,  0.0000, 19.3609, 19.2298, 20.7741, 18.3046, 22.1946,  0.0000],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([27.1613,  0.0000, 35.6849, 30.1624,  0.0000, 44.0789, 34.0388,  0.0000,
        36.2060,  0.0000, 34.7543, 33.8541, 36.5415, 32.4461, 37.5527,  0.0000],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(35.3515, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(32.4376, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([28.,  1., 15.,  4.,  1.,  6.,  8.,  1., 17.,  1., 14., 22., 11.,  1.,
         8.,  1.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([59.,  2., 45., 12.,  2., 21., 27.,  2., 21.,  2., 21., 27., 31.,  8.,
        17.,  2.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([13.1190,  0.0000, 15.7150, 16.0879,  0.0000, 17.5946, 12.9740,  0.0000,
        15.8839,  0.0000, 13.6808, 18.5966, 15.1313,  0.0000,  9.5738,  0.0000],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([24.7859,  3.2655, 27.6660, 29.9485,  3.8552, 32.0616, 23.7868,  2.7491,
        28.6386,  3.8293, 26.6938, 35.2251, 25.8450, 13.7300, 18.8294,  2.8680],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(9.2405, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(11.2059, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([34.,  1.,  3.,  9.,  1.,  9., 15.,  1., 12.,  1.,  5., 21.,  4.,  9.,
        11.,  1.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([25.,  1.,  3., 11.,  1., 13., 10.,  1., 12.,  1.,  7., 18.,  6.,  8.,
         6.,  1.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([3.6542, 0.0000, 2.2682, 4.0202, 0.0000, 4.2374, 5.5328, 0.0000, 4.0846,
        0.0000, 2.3113, 5.3781, 3.0989, 4.4212, 2.6772, 0.0000],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([ 7.9797,  0.0000,  3.9936,  7.4418,  0.0000,  7.7499, 10.7958,  0.0000,
         7.7141,  0.0000,  5.6282, 10.8759,  5.5062,  9.5616,  5.7580,  0.0000],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
tensor(0.2780, device='cuda:0') tensor(0.9975, device='cuda:0') min max before 1
torch.Size([16]) sum mask size 1
torch.Size([16]) losssss
torch.Size([16]) losssss
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(8.4522, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(8.1930, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([264., 325., 275., 298., 280., 228., 318., 295., 235., 284., 244., 340.,
        216., 228., 360., 241.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([399., 553., 427., 517., 496., 427., 471., 499., 367., 441., 362., 470.,
        357., 405., 530., 378.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([2.0429, 1.4972, 1.1369, 2.0055, 2.1023, 2.3110, 1.0972, 1.7762, 1.8885,
        1.3407, 1.0092, 1.5187, 1.0874, 1.1851, 2.0136, 1.2071],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([3.5048, 2.1939, 1.8509, 2.7637, 3.2136, 3.9008, 1.8486, 2.9487, 3.1210,
        2.1054, 1.6448, 2.1311, 1.7450, 2.2940, 2.6615, 2.1129],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(15.3577, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(13.8660, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([162., 176., 197., 152., 169., 165., 166., 150., 168., 176., 168., 224.,
        149., 126., 197., 108.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([260., 341., 350., 324., 255., 231., 313., 255., 258., 358., 328., 333.,
        313., 173., 318., 177.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([2.7073, 3.3019, 2.3093, 3.3323, 2.4997, 2.5786, 3.1055, 2.9289, 2.7411,
        2.8896, 2.8813, 2.8229, 2.4692, 3.1991, 3.7162, 2.3210],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([4.5143, 5.1543, 3.7514, 4.9536, 4.1435, 4.8973, 5.0342, 5.0478, 4.7988,
        4.6355, 4.8630, 4.8676, 3.9450, 5.4483, 6.2058, 3.9367],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(29.0148, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(28.3730, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([ 80.,  89., 117.,  89.,  42.,  55., 107.,  48.,  80.,  98., 105., 102.,
        101.,  43., 109., 105.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 94., 107., 127., 110.,  60.,  63., 117.,  55.,  95., 109., 131., 120.,
        111.,  51., 121., 103.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([5.9876, 3.9587, 2.6552, 4.1174, 4.3192, 6.5510, 3.7443, 4.4022, 6.5526,
        4.9274, 5.1723, 6.1736, 3.1251, 4.9953, 6.0503, 4.0043],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([11.8180,  7.5055,  5.1792,  8.0673,  8.8769, 13.3771,  7.2232,  8.8691,
        12.7666,  9.8383, 10.1147, 12.1927,  6.1908, 10.6339, 11.5896,  7.7726],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(18.7953, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(19.4560, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([43., 44., 39., 39., 43., 27., 50., 25., 43., 61., 52., 49., 18., 31.,
        38., 31.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 52.,  63.,  66.,  52.,  56.,  49.,  77.,  51., 104.,  69.,  67.,  82.,
         53.,  52.,  63.,  54.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([3.2140, 2.7101, 3.6773, 3.2775, 3.6127, 2.8977, 2.8849, 3.7422, 2.8079,
        3.5758, 3.0288, 3.4055, 2.9220, 3.7138, 2.5344, 2.7191],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([5.4056, 4.8154, 5.9909, 6.5929, 5.7160, 4.5285, 5.8607, 6.2113, 5.0475,
        6.8345, 5.8043, 5.8978, 5.4566, 7.0861, 4.8511, 4.6051],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(6.0010, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(6.3867, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([ 7.,  7., 12., 13.,  9.,  7., 11.,  5.,  9., 11.,  5., 13.,  7., 16.,
        11.,  8.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 8.,  9., 10., 14.,  8.,  9., 11., 11., 15., 11.,  7., 11., 10., 21.,
        17.,  8.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([0.5491, 0.8848, 1.3412, 1.6188, 1.1632, 1.6262, 0.7571, 0.4232, 1.0732,
        0.5732, 1.1436, 1.4989, 0.9070, 0.9230, 1.2814, 0.9148],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([1.7002, 2.2252, 2.4585, 3.2703, 2.3024, 2.6472, 1.5190, 1.5651, 2.0396,
        1.2475, 2.1842, 2.9060, 1.9099, 1.4270, 2.5145, 1.7306],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
------------ 0.27525758743286133 backwards -------------------------------
1 recon_decay
tensor(0., device='cuda:0') tensor(1., device='cuda:0') min max before 1
torch.Size([16]) sum mask size 1
torch.Size([16]) losssss
torch.Size([16]) losssss
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(11.2402, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(11.2580, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([208., 506., 475.,   1.,   1., 907.,   1., 655., 569., 154., 175.,  89.,
          1., 523., 257., 294.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 360.,  730.,  710.,  254.,  254., 1178.,  254.,  840.,  818.,  364.,
         460.,  351.,  254.,  759.,  516.,  584.], device='cuda:0',
       grad_fn=<AddBackward0>) sum_m_f size
tensor([4.7249, 4.8852, 4.3690, 0.0000, 0.0000, 4.0981, 0.0000, 4.5969, 4.6553,
        5.9806, 5.0438, 3.8412, 0.0000, 4.4161, 5.0840, 3.4185],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([5.6662, 5.6706, 5.1392, 1.6136, 1.5787, 4.6393, 1.6104, 5.4661, 5.3781,
        7.1984, 6.0802, 5.2812, 1.5849, 5.1075, 6.0354, 4.1724],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(37.7004, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(35.0252, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([ 13.,  71.,  47.,   1.,   1., 158.,   1.,  76.,  53.,  14.,  23.,  28.,
          1.,  70.,  39.,  88.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 27., 111.,  72.,   1.,   1., 222.,   1.,  99.,  82.,  31.,  23.,  43.,
          1.,  95.,  65.,  94.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([15.2233, 16.4654, 15.7452,  0.0000,  0.0000, 14.3670,  0.0000, 15.0543,
        17.0077, 17.6838, 14.6066, 16.3590,  0.0000, 16.0689, 16.6642, 13.0259],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([24.9571, 27.0693, 25.9860,  0.0000,  0.0000, 24.6026,  0.0000, 25.1758,
        27.4444, 30.8252, 20.7835, 28.7618,  0.0000, 26.5070, 27.4191, 22.7578],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(44.4269, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(49.1213, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([ 30., 104.,  75.,   1.,   1., 163.,   1.,  64.,  55.,  32.,  20.,  40.,
          1.,  74.,  57.,  89.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 14.,  62.,  41.,   1.,   1., 103.,   1.,  49.,  30.,  20.,  12.,  28.,
          1.,  60.,  27.,  61.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([14.5329, 19.3983, 17.2716,  0.0000,  0.0000, 17.3203,  0.0000, 18.5892,
        16.4222, 20.6288, 16.8352, 15.9038,  0.0000, 17.2581, 20.3720, 11.9238],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([25.1330, 37.3156, 31.4363,  0.0000,  0.0000, 33.3107,  0.0000, 33.3328,
        29.2743, 40.8867, 31.2083, 29.4459,  0.0000, 29.4404, 40.1683, 21.4201],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(33.2680, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(30.5330, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([14., 10., 13.,  1.,  1., 34.,  1., 16., 14.,  7., 11., 25.,  1., 25.,
        25., 11.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([19., 40., 56.,  2.,  2., 68.,  2., 35., 37., 19., 30., 33.,  2., 36.,
        40., 24.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([13.9550, 12.5940, 13.3843,  0.0000,  0.0000,  9.6598,  0.0000, 17.2472,
        15.6856, 10.7300, 15.6398, 16.8801,  0.0000, 17.1195, 15.1850,  8.7212],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([28.3123, 23.4317, 21.9406,  2.3325,  4.4923, 18.7741,  2.9578, 28.2728,
        29.6438, 22.6641, 28.4567, 30.9770,  1.1021, 31.0305, 25.8691, 13.6656],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(9.4144, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(15.6127, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([ 8.,  7.,  1.,  1.,  1., 37.,  1., 21., 21.,  2.,  9., 30.,  1., 18.,
         8.,  2.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([1., 1., 1., 1., 1., 3., 1., 3., 5., 1., 4., 3., 1., 1., 3., 1.],
       device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([2.0964, 4.0943, 0.0000, 0.0000, 0.0000, 2.3652, 0.0000, 4.1375, 5.0460,
        0.3303, 5.5759, 4.2179, 0.0000, 4.1518, 2.0839, 0.0000],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([ 2.0964,  4.0943,  0.0000,  0.0000,  0.0000,  5.4500,  0.0000,  5.3014,
        11.0567,  0.3303, 11.0745,  9.0203,  0.0000,  4.1518,  4.7132,  0.0000],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
tensor(0.2984, device='cuda:0') tensor(0.9961, device='cuda:0') min max before 1
torch.Size([16]) sum mask size 1
torch.Size([16]) losssss
torch.Size([16]) losssss
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(8.5702, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(7.8738, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([206., 261., 278., 239., 385., 262., 291., 277., 266., 219., 211., 180.,
        266., 196., 168., 341.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([438., 500., 542., 490., 760., 472., 567., 472., 558., 442., 463., 351.,
        556., 418., 323., 727.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([1.4112, 0.8711, 0.9700, 0.9433, 1.8662, 0.9294, 0.9802, 0.9824, 0.9912,
        0.8153, 1.3957, 1.4239, 1.3535, 1.9373, 1.4219, 1.8513],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([2.6641, 1.7764, 1.7292, 1.8962, 2.6975, 1.7014, 1.6972, 1.5341, 1.8963,
        1.8593, 2.2594, 2.5532, 2.3649, 3.1063, 2.7620, 2.7084],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(13.2970, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(13.0302, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([405., 417., 540., 436., 771., 569., 452., 476., 493., 524., 531., 351.,
        475., 469., 440., 622.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([401., 422., 554., 446., 740., 523., 486., 465., 514., 511., 577., 312.,
        525., 431., 394., 610.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([2.8660, 2.3408, 2.7289, 2.5885, 2.6817, 2.4229, 2.3465, 2.5561, 2.9642,
        2.8721, 3.0341, 2.0622, 2.7457, 2.5983, 2.5247, 2.9502],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([4.7422, 3.9938, 4.4129, 4.2223, 4.2840, 4.0695, 3.7597, 4.1419, 4.6953,
        4.7096, 4.9015, 3.4685, 4.4895, 4.3343, 4.2472, 4.6673],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(26.7485, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(29.6541, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([111.,  87., 123., 127., 165., 132., 125., 135.,  86.,  98., 131., 105.,
        103., 141., 142., 164.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 70.,  65.,  83.,  64., 136.,  97.,  85., 104.,  58.,  57.,  95.,  79.,
         81.,  98.,  98., 112.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([4.3566, 4.1257, 4.5510, 4.2247, 5.6978, 5.9594, 3.5680, 4.4513, 5.2697,
        4.2741, 4.1485, 4.0676, 5.4466, 4.5259, 4.2766, 4.4044],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([ 8.4322,  8.0538,  8.9469,  8.7271, 11.4827, 11.8961,  6.5790,  8.8039,
        11.2100,  9.1746,  8.2506,  7.9515,  9.7211,  8.8053,  8.3699,  7.5780],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(19.3939, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(18.7818, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([37., 27., 40., 44., 36., 39., 25., 40., 45., 45., 31., 29., 24., 36.,
        42., 42.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 80.,  91., 103.,  97.,  68., 135.,  85.,  98.,  61.,  49.,  71.,  90.,
         66.,  88., 119.,  85.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([2.7088, 2.9314, 2.2134, 2.6102, 3.4686, 3.1205, 2.4192, 3.3744, 3.3867,
        3.4102, 3.2583, 2.6517, 4.8887, 3.2569, 4.1150, 3.7071],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([4.6307, 5.0401, 4.5150, 4.9904, 6.5722, 5.3342, 4.7895, 5.9836, 6.6764,
        6.1386, 5.3558, 5.0492, 8.2808, 5.5730, 6.6862, 6.6680],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(7.3536, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(6.3742, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([ 6.,  4.,  5.,  6., 13.,  4.,  2.,  5.,  4.,  2.,  5.,  2.,  1.,  5.,
         3.,  5.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([10., 18.,  6.,  7., 20., 18., 10.,  9.,  8.,  4., 14., 11., 11.,  9.,
        13., 15.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([0.3987, 1.4606, 0.4128, 1.2446, 1.3201, 0.9971, 0.2149, 0.9803, 1.0981,
        0.1226, 1.6506, 0.5172, 0.0000, 1.1585, 1.0053, 1.5402],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([0.9010, 3.2390, 1.1185, 2.6496, 2.6960, 1.9705, 0.8665, 1.8497, 2.1838,
        0.4435, 2.8745, 1.5718, 0.8018, 1.9774, 1.9564, 3.7389],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
------------ 0.2751929759979248 backwards -------------------------------
1 recon_decay
tensor(0., device='cuda:0') tensor(1., device='cuda:0') min max before 1
torch.Size([16]) sum mask size 1
torch.Size([16]) losssss
torch.Size([16]) losssss
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(13.9537, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(15.5768, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([  1.,   1., 224., 183.,   9., 260.,  71., 193., 228.,   1., 216., 210.,
        164.,   1., 349., 235.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([126., 126., 228., 196., 128., 204., 171., 200., 196., 126., 243., 242.,
        194., 126., 293., 184.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([0.0000, 0.0000, 5.1372, 5.6185, 5.8289, 5.0478, 5.3395, 5.0888, 4.1429,
        0.0000, 4.9969, 4.7371, 6.0670, 0.0000, 4.9156, 5.2916],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([0.0189, 0.0135, 5.3007, 5.8881, 5.9063, 5.3676, 5.6181, 5.3573, 4.4268,
        0.0321, 5.4284, 5.0672, 6.2304, 0.0309, 5.3142, 5.4404],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(37.7004, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(37.2597, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([ 1.,  1., 59., 71.,  4., 76., 16., 49., 97.,  1., 49., 63., 57.,  1.,
        86., 40.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([  1.,   1.,  60.,  86.,   6.,  81.,  10.,  59., 101.,   1.,  51.,  63.,
         49.,   1.,  86.,  55.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 0.0000,  0.0000, 14.6380, 16.3644, 16.5475, 15.2581, 17.2817, 15.0016,
        11.9404,  0.0000, 14.9450, 16.5303, 17.4014,  0.0000, 16.7100, 14.6087],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([ 0.0000,  0.0000, 26.3366, 27.8320, 19.9953, 26.5615, 30.7283, 25.5390,
        21.5068,  0.0000, 26.3899, 30.2557, 28.0699,  0.0000, 29.7842, 25.2889],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(52.0932, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(44.7429, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([ 1.,  1., 20., 49.,  2., 30., 19., 24., 44.,  1., 32., 39., 30.,  1.,
        48., 25.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([  1.,   1.,  61., 101.,   8.,  74.,  40.,  68.,  88.,   1.,  60., 103.,
         74.,   1., 107.,  48.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 0.0000,  0.0000, 17.1622, 21.8960, 21.8097, 21.5037, 15.3842, 20.6128,
        15.5764,  0.0000, 16.6612, 23.7007, 21.6206,  0.0000, 21.0026, 20.5368],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([ 0.0000,  0.0000, 29.1898, 38.9093, 33.9736, 35.3154, 27.5090, 34.1270,
        26.1032,  0.0000, 30.3334, 40.5885, 36.7599,  0.0000, 32.8474, 36.0588],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(29.3356, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(37.2971, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([ 1.,  1., 28., 27.,  3., 31., 16., 14., 32.,  1., 15., 20., 35.,  1.,
        29., 24.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 2.,  2., 13.,  8.,  3., 13.,  6.,  6., 10.,  2.,  5., 24., 15.,  2.,
        16.,  7.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 0.0000,  0.0000, 13.4049, 11.9702,  8.0210, 14.4338, 13.1707,  9.7024,
         8.8573,  0.0000, 14.0351, 14.2829, 15.1407,  0.0000, 14.2282, 10.3213],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([ 4.7342,  0.4408, 28.5009, 21.7403, 13.1289, 30.4752, 22.7807, 17.5263,
        19.4518,  1.0787, 24.2696, 25.6676, 30.7912,  1.7424, 26.5159, 21.6923],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(8.9753, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(9.6819, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([ 1.,  1., 15.,  7.,  1., 26., 11., 25.,  7.,  1., 19., 11.,  5.,  1.,
         7., 13.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 1.,  1., 35.,  8.,  1., 31., 11., 17.,  5.,  1.,  5., 26.,  3.,  1.,
        16., 14.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([0.0000, 0.0000, 3.0737, 4.0943, 0.0000, 3.7745, 3.7142, 1.9938, 1.3352,
        0.0000, 2.3241, 2.2892, 3.1005, 0.0000, 4.3341, 3.8725],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([0.0000, 0.0000, 5.3951, 8.0174, 0.0000, 6.5442, 7.1723, 4.3262, 2.5245,
        0.0000, 4.8341, 4.8842, 6.1684, 0.0000, 6.9275, 8.2726],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
tensor(0.2843, device='cuda:0') tensor(0.9965, device='cuda:0') min max before 1
torch.Size([16]) sum mask size 1
torch.Size([16]) losssss
torch.Size([16]) losssss
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(8.0047, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(8.9314, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([302., 274., 376., 364., 374., 378., 401., 389., 444., 359., 374., 268.,
        229., 314., 306., 267.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([250., 195., 214., 287., 268., 287., 278., 260., 338., 267., 309., 250.,
        177., 238., 253., 186.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([0.9647, 1.6884, 2.5705, 1.7147, 1.6895, 1.6975, 1.9534, 1.1824, 1.5640,
        1.2885, 1.5559, 1.1061, 1.6185, 1.4134, 1.2706, 1.8423],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([1.4467, 2.3879, 4.3186, 2.4104, 2.4692, 2.2092, 2.6473, 1.5959, 2.1746,
        1.7307, 2.3618, 1.8683, 2.3391, 2.4013, 1.6999, 3.0116],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(13.3509, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(13.1542, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([399., 379., 566., 616., 647., 626., 571., 523., 572., 434., 567., 461.,
        417., 331., 521., 404.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([385., 358., 521., 533., 652., 598., 581., 512., 626., 415., 497., 495.,
        437., 286., 533., 408.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([2.3937, 2.0522, 2.9915, 2.9069, 3.1768, 3.1022, 3.3523, 2.9506, 3.6132,
        2.3539, 2.6162, 2.1687, 2.7068, 2.7444, 2.4889, 2.2194],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([3.9252, 3.4991, 4.7646, 4.6289, 4.9114, 4.3538, 5.3735, 4.6711, 5.6360,
        3.7556, 4.2944, 3.4445, 4.3891, 4.3138, 3.9589, 3.7789],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(28.8784, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(28.4166, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([110.,  90.,  96., 134., 132., 124.,  88.,  98., 122., 101., 110., 122.,
         97.,  89., 100., 110.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([108.,  92., 104., 130., 136., 130., 103., 116., 125.,  94., 116., 120.,
        108.,  96., 123., 114.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([3.9103, 4.4942, 4.6178, 6.5596, 5.0015, 6.0324, 5.8317, 4.5403, 6.0747,
        5.2191, 7.0288, 2.9071, 3.6344, 4.5671, 3.8567, 4.6104],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([ 8.0036,  8.9786,  8.8934, 12.9899,  9.6737, 11.4792, 11.2896,  8.7145,
        11.8981, 10.5793, 13.8344,  6.0517,  7.0818,  9.0458,  7.5838,  9.7004],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(18.9526, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(18.6924, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([36., 32., 58., 23., 65., 45., 40., 41., 37., 41., 37., 35., 35., 33.,
        40., 39.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([111.,  69.,  74.,  60.,  74.,  64.,  36.,  77.,  98.,  94.,  60.,  75.,
        107.,  61.,  96.,  77.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([1.7959, 3.6770, 3.8288, 4.5529, 4.2418, 3.2323, 3.0732, 3.5084, 3.0854,
        3.1574, 4.6731, 3.1394, 3.9808, 2.9637, 3.1433, 3.5878],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([3.3890, 6.7341, 7.0282, 7.8589, 7.5821, 5.6926, 7.6353, 6.3533, 5.4360,
        5.7957, 8.6870, 6.0309, 7.2487, 5.3548, 5.8214, 5.7277],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(6.1298, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(7.3696, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([ 9.,  9., 19., 11.,  8., 12., 10., 14., 10.,  5., 29.,  9.,  6.,  4.,
        10.,  5.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 9.,  3.,  6., 11.,  6.,  6., 11.,  7.,  7.,  5., 19.,  5.,  7.,  3.,
         5.,  7.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([0.9191, 1.6060, 2.0732, 1.5855, 1.0008, 1.0787, 0.9420, 0.8770, 0.4674,
        0.9426, 2.5829, 1.0952, 1.3416, 0.2474, 1.4524, 0.9402],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([1.9051, 3.3520, 3.0361, 2.9119, 1.3435, 1.5164, 3.8325, 1.7608, 1.4706,
        1.9897, 5.7940, 2.2600, 2.6761, 0.3902, 2.3827, 1.5999],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
------------ 0.2751450538635254 backwards -------------------------------
1 recon_decay
tensor(0., device='cuda:0') tensor(1., device='cuda:0') min max before 1
torch.Size([16]) sum mask size 1
torch.Size([16]) losssss
torch.Size([16]) losssss
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(11.2402, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(11.7864, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([122., 448.,  64., 446.,   1.,  86.,   1.,   1.,   1., 232.,   1.,   1.,
        151.,   1., 129., 579.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([305., 646., 310., 678., 253., 298., 253., 253., 253., 371., 253., 253.,
        387., 253., 311., 677.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([3.5765, 4.9045, 3.7101, 4.7597, 0.0000, 4.3913, 0.0000, 0.0000, 0.0000,
        4.4082, 0.0000, 0.0000, 4.5401, 0.0000, 3.2729, 4.1257],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([4.6067, 5.6170, 5.0064, 5.5234, 1.4393, 5.5037, 1.5723, 1.4402, 1.5774,
        5.2385, 1.5754, 1.4692, 5.7666, 1.4679, 4.2500, 4.9471],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(37.1309, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(30.9471, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([31., 62.,  9., 44.,  1., 18.,  1.,  1.,  1.,  8.,  1.,  1., 31.,  1.,
        12., 48.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 62., 150.,  26., 124.,   1.,  35.,   1.,   1.,   1.,  44.,   1.,   1.,
         72.,   1.,  38., 122.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([18.3041, 15.9566, 13.7128, 17.3773,  0.0000, 17.6112,  0.0000,  0.0000,
         0.0000, 13.9858,  0.0000,  0.0000, 15.2349,  0.0000, 12.5440, 14.5731],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([29.3490, 25.0406, 21.8174, 26.8214,  0.0000, 28.6293,  0.0000,  0.0000,
         0.0000, 23.7915,  0.0000,  0.0000, 24.3734,  0.0000, 19.8932, 22.1491],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(59.9828, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after

  5%|████████████▉                                                                                                                                                                                                                                                                  | 18/378 [00:09<03:04,  1.95it/s]
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(59.3215, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([15.,  8.,  4.,  9.,  1., 13.,  1.,  1.,  1., 10.,  1.,  1.,  2.,  1.,
        12., 11.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 9.,  9.,  2., 17.,  1.,  9.,  1.,  1.,  1.,  5.,  1.,  1.,  5.,  1.,
        11., 15.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([15.6866, 22.7904, 19.2128, 23.6554,  0.0000, 16.6943,  0.0000,  0.0000,
         0.0000, 17.5647,  0.0000,  0.0000, 13.3035,  0.0000, 13.2753, 12.0925],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([29.5265, 39.4166, 27.3186, 39.7537,  0.0000, 33.4184,  0.0000,  0.0000,
         0.0000, 33.5671,  0.0000,  0.0000, 26.6411,  0.0000, 24.2883, 18.8754],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(39.7900, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(33.8801, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([ 8.,  7.,  4.,  3.,  1.,  7.,  1.,  1.,  1.,  9.,  1.,  1., 10.,  1.,
         4.,  5.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([27., 35.,  6., 18.,  2.,  8.,  2.,  2.,  2., 10.,  2.,  2., 16.,  2.,
        12., 21.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([18.0558, 19.4344, 16.0406, 16.9329,  0.0000, 17.6762,  0.0000,  0.0000,
         0.0000, 18.0973,  0.0000,  0.0000, 16.4340,  0.0000, 11.2954, 11.7761],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([32.0129, 33.0701, 29.8163, 32.1234,  3.0356, 34.3648,  2.2020,  2.8202,
         1.8418, 35.7281,  1.5328,  2.3822, 29.9050,  2.9843, 23.5691, 19.8381],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(11.1168, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(8.9076, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([14., 17.,  2., 11.,  1.,  1.,  1.,  1.,  1.,  9.,  1.,  1.,  9.,  1.,
         3.,  6.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([28., 47.,  4., 25.,  1.,  5.,  1.,  1.,  1., 13.,  1.,  1.,  9.,  1.,
         2., 23.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([5.8975, 6.1590, 1.7540, 3.5309, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        4.7859, 0.0000, 0.0000, 4.5249, 0.0000, 2.6363, 3.0074],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([10.6158,  8.9769,  2.9957,  6.0252,  0.0000,  2.1719,  0.0000,  0.0000,
         0.0000, 10.1292,  0.0000,  0.0000,  8.6125,  0.0000,  4.5157,  6.0374],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
tensor(0.2661, device='cuda:0') tensor(0.9978, device='cuda:0') min max before 1
torch.Size([16]) sum mask size 1
torch.Size([16]) losssss
torch.Size([16]) losssss
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(8.6806, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(8.1570, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([192., 167., 193., 122., 190., 153., 175.,  92., 165., 185., 189., 157.,
        140., 250., 135.,  92.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([480., 362., 484., 367., 416., 443., 430., 342., 381., 414., 403., 355.,
        401., 516., 412., 344.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([2.1282, 1.3221, 1.7726, 2.2939, 2.2189, 2.3330, 1.5784, 2.1864, 1.6748,
        2.2684, 2.9182, 2.0427, 1.4890, 1.9597, 1.6769, 1.6774],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([2.9407, 1.9781, 2.5127, 3.8231, 3.3736, 2.9500, 2.2472, 2.9399, 2.4059,
        3.7783, 4.3114, 3.3689, 2.2716, 2.6254, 2.2769, 2.4967],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(13.7687, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(13.9580, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([470., 407., 600., 310., 393., 516., 432., 411., 510., 403., 353., 394.,
        449., 642., 400., 309.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([357., 325., 469., 227., 287., 415., 345., 326., 427., 328., 276., 292.,
        317., 471., 298., 201.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([3.1296, 2.5251, 3.0177, 2.7363, 3.1693, 3.6722, 2.3892, 3.6962, 2.2946,
        2.9205, 3.1837, 2.5766, 2.9458, 2.9726, 2.5067, 2.9815],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([4.8224, 3.9076, 4.5424, 4.4078, 5.0581, 5.5037, 3.9163, 6.0109, 3.8006,
        4.6861, 5.1241, 4.1929, 4.7676, 4.5726, 3.7250, 5.0858],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(27.7466, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(28.4099, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([117., 111., 126.,  82., 120., 127., 138., 108., 133.,  99.,  94., 109.,
         97., 146., 122., 103.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([107., 111., 136.,  75., 117., 111., 137., 105., 137.,  86.,  82., 105.,
         94., 155., 109.,  96.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([4.5852, 4.5091, 4.7185, 5.1737, 5.5223, 4.9269, 3.3163, 4.0733, 3.4314,
        5.2892, 5.0894, 6.1067, 4.0439, 5.0058, 3.2991, 4.4740],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([ 8.4168,  8.5824,  9.1075, 10.1526, 10.2642,  9.4899,  6.4483,  8.0988,
         6.8132, 10.6646, 10.0557, 12.4941,  8.2004,  9.8015,  6.3130,  8.5079],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(17.7091, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(19.4896, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([55., 62., 86., 60., 49., 88., 55., 64., 78., 64., 54., 53., 50., 79.,
        52., 37.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([87., 67., 85., 62., 55., 58., 60., 75., 38., 41., 72., 90., 72., 60.,
        68., 57.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([3.1096, 2.9507, 6.3564, 3.8948, 4.6120, 3.8142, 2.9183, 3.2630, 2.8175,
        2.8599, 3.5218, 2.0627, 3.2147, 5.3804, 3.5698, 3.5239],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([ 6.3043,  5.7452, 11.6613,  6.6323,  8.2999,  7.2616,  5.5084,  5.8098,
         5.1949,  5.0188,  5.9361,  4.2556,  5.3560,  9.1204,  6.2490,  6.6933],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(5.6215, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(7.1822, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([10.,  7., 18.,  1., 33., 14., 13., 10.,  9.,  6.,  9.,  7., 18., 20.,
        12., 16.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([10.,  2., 11.,  5., 24.,  8.,  7.,  5.,  5.,  6.,  3.,  6.,  5.,  8.,
        12., 13.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([0.7810, 0.8320, 1.9153, 0.0000, 2.3823, 1.1539, 0.9930, 0.9427, 1.1502,
        1.1803, 0.5920, 1.0361, 0.7565, 0.8258, 1.0491, 0.5188],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([1.3539, 1.2551, 2.9163, 1.0509, 4.2205, 2.1008, 2.4497, 1.9817, 1.9139,
        2.1698, 0.9590, 2.3047, 1.8418, 1.6444, 2.0676, 1.1561],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
------------ 0.27617406845092773 backwards -------------------------------
1 recon_decay
tensor(0., device='cuda:0') tensor(1., device='cuda:0') min max before 1
torch.Size([16]) sum mask size 1
torch.Size([16]) losssss
torch.Size([16]) losssss
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(11.2402, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(15.5768, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([  1.,   1., 267.,   1.,   1.,   1.,   1., 328., 636., 358.,   1., 913.,
         77., 401., 188.,   1.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([126., 126., 170., 126., 126., 126., 126., 165., 196., 223., 126., 314.,
        134., 202., 161., 126.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([0.0000, 0.0000, 5.0012, 0.0000, 0.0000, 0.0000, 0.0000, 5.5390, 3.5273,
        4.3523, 0.0000, 5.0162, 2.8022, 4.7438, 5.0220, 0.0000],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([0.1344, 0.1745, 5.2150, 0.1296, 0.0371, 0.2357, 0.3231, 5.8174, 3.9111,
        5.0075, 0.0858, 5.3829, 2.9893, 5.2252, 5.1162, 0.1053],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(36.5298, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(37.8878, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([  1.,   1.,  52.,   1.,   1.,   1.,   1.,  34., 118.,  25.,   1.,  64.,
         15.,  28.,  34.,   1.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 1.,  1., 39.,  1.,  1.,  1.,  1., 31., 95., 16.,  1., 51.,  8., 21.,
        21.,  1.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 0.0000,  0.0000, 15.5303,  0.0000,  0.0000,  0.0000,  0.0000, 17.1621,
        11.7450, 14.5705,  0.0000, 16.2000, 14.6154, 16.1866, 19.4638,  0.0000],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([ 0.0000,  0.0000, 28.4844,  0.0000,  0.0000,  0.0000,  0.0000, 30.6821,
        21.4019, 26.7345,  0.0000, 27.2515, 24.1763, 28.0810, 34.9494,  0.0000],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(47.7416, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(50.6475, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([ 1.,  1., 36.,  1.,  1.,  1.,  1., 52., 78., 26.,  1., 60., 23., 34.,
        42.,  1.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 1.,  1., 34.,  1.,  1.,  1.,  1., 30., 45., 22.,  1., 38., 18., 18.,
        22.,  1.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 0.0000,  0.0000, 21.7911,  0.0000,  0.0000,  0.0000,  0.0000, 21.4858,
        15.4945, 16.8911,  0.0000, 19.8152, 12.8175, 18.9942, 18.3289,  0.0000],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([ 0.0000,  0.0000, 39.3179,  0.0000,  0.0000,  0.0000,  0.0000, 41.7921,
        26.5844, 32.9808,  0.0000, 36.7631, 24.0552, 32.5741, 37.3353,  0.0000],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(34.2576, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(27.4907, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([ 1.,  1., 19.,  1.,  1.,  1.,  1.,  7., 14.,  6.,  1., 15., 11.,  7.,
        13.,  1.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 6.,  6., 67.,  6.,  6.,  6.,  6., 38., 73., 23.,  6., 58., 35., 37.,
        28.,  6.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 0.0000,  0.0000, 17.5321,  0.0000,  0.0000,  0.0000,  0.0000, 12.6427,
         9.1550, 13.3917,  0.0000, 13.9189, 14.8812, 18.4404, 16.4840,  0.0000],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([ 2.6332,  3.7872, 28.7010,  2.3059,  1.7007,  3.8312,  2.2574, 22.4212,
        16.6491, 23.4056,  2.2090, 23.5291, 25.1839, 29.7063, 27.5876,  2.0157],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(9.2840, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(10.1747, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([ 1.,  1.,  3.,  1.,  1.,  1.,  1., 25.,  4.,  9.,  1., 36.,  3.,  7.,
        14.,  1.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 1.,  1.,  8.,  1.,  1.,  1.,  1., 14.,  4., 11.,  1., 13.,  4., 14.,
         4.,  1.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([0.0000, 0.0000, 0.6858, 0.0000, 0.0000, 0.0000, 0.0000, 2.7471, 2.0226,
        3.6700, 0.0000, 3.5223, 2.7284, 3.8946, 2.7268, 0.0000],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([0.0000, 0.0000, 1.7317, 0.0000, 0.0000, 0.0000, 0.0000, 5.9315, 3.3553,
        5.1364, 0.0000, 6.8764, 5.1782, 5.8266, 6.5658, 0.0000],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
tensor(0.2856, device='cuda:0') tensor(0.9967, device='cuda:0') min max before 1
torch.Size([16]) sum mask size 1
torch.Size([16]) losssss
torch.Size([16]) losssss
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(8.7031, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(7.9648, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([114., 110., 177., 121., 128., 120., 113., 139., 107., 142., 142., 153.,
        125., 155., 106., 173.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([476., 415., 504., 442., 414., 427., 407., 466., 381., 453., 417., 464.,
        378., 482., 377., 468.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([2.1394, 1.9223, 1.9591, 2.4302, 2.2653, 2.0122, 1.7452, 1.9598, 2.0966,
        1.7185, 2.0871, 2.2710, 2.1568, 2.4118, 1.8558, 2.8731],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([3.2065, 3.0928, 3.1328, 3.3446, 3.4482, 3.1322, 2.9100, 2.8023, 2.8137,
        2.5299, 3.2651, 2.8996, 3.5800, 3.5366, 2.8921, 3.7168],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(13.7129, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(14.4943, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([317., 264., 542., 360., 393., 327., 356., 543., 390., 504., 440., 527.,
        318., 492., 288., 632.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([224., 154., 313., 220., 199., 187., 166., 289., 242., 310., 260., 289.,
        170., 290., 169., 394.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([3.1962, 2.9542, 3.0632, 3.5792, 3.2322, 3.1879, 3.3309, 2.9643, 3.0403,
        2.9738, 2.3020, 3.4085, 2.9646, 3.6050, 3.8185, 3.5148],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([5.7322, 5.1796, 5.2034, 6.2158, 4.8880, 5.5275, 5.4011, 4.7104, 4.4697,
        4.7532, 3.7471, 5.1546, 4.7125, 5.2965, 6.5690, 5.3537],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(27.4793, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(27.0541, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([ 77.,  73., 122.,  66., 126.,  63., 106., 113., 112., 149., 115., 126.,
        100.,  84., 100., 137.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 81.,  58., 121.,  90., 125.,  68., 105., 128., 121., 145., 134., 130.,
        106., 109., 106., 148.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([5.9051, 4.5202, 4.9037, 4.9655, 4.2424, 5.1311, 5.2006, 4.6884, 3.2729,
        3.6983, 4.1274, 5.6512, 4.8301, 5.0513, 4.0870, 6.0339],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([11.4757,  9.0833,  9.5787,  9.8908,  7.8678, 10.3202, 10.1955,  8.1985,
         6.2441,  6.9327,  8.0263, 10.9021,  9.5241,  8.9237,  8.1448, 11.5385],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(19.5660, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(19.5346, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([21., 21., 55., 46., 30., 17., 24., 40., 37., 41., 31., 26., 25., 40.,
        23., 21.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([37., 51., 59., 70., 46., 43., 72., 43., 81., 60., 39., 35., 73., 53.,
        57., 29.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([5.0984, 3.3844, 3.5262, 2.8880, 1.8808, 2.0269, 2.5512, 2.9624, 3.4779,
        3.2035, 2.7606, 3.0276, 3.1210, 3.3074, 4.0984, 2.7422],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([8.6137, 5.5119, 6.5007, 5.2347, 4.7088, 3.9938, 4.5345, 4.9958, 6.3686,
        6.7752, 5.3279, 5.1498, 5.9836, 6.0134, 7.1041, 6.4292],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(6.8969, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(7.6680, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([4., 7., 8., 4., 6., 7., 3., 8., 6., 3., 3., 1., 5., 3., 7., 3.],
       device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([6., 3., 5., 5., 6., 2., 2., 3., 5., 9., 3., 4., 1., 3., 5., 4.],
       device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([0.4429, 0.4958, 1.3063, 1.0890, 0.5333, 0.7972, 0.5903, 0.3250, 1.5981,
        1.0023, 0.2070, 0.0000, 0.2516, 0.4413, 0.8346, 0.4695],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([1.6484, 1.9429, 2.4387, 2.1109, 1.0666, 1.2741, 2.3567, 0.3629, 3.5031,
        1.9375, 0.7904, 0.5490, 0.2516, 1.1332, 1.5315, 0.9030],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
------------ 0.27436184883117676 backwards -------------------------------
1 recon_decay
tensor(0., device='cuda:0') tensor(1., device='cuda:0') min max before 1
torch.Size([16]) sum mask size 1
torch.Size([16]) losssss
torch.Size([16]) losssss
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(14.1502, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(14.1952, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([  1., 171., 222.,  21., 206.,   1., 101.,   1., 226., 133.,   1., 280.,
          1.,  87., 198., 149.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([127., 176., 335., 152., 269., 127., 211., 127., 367., 277., 127., 404.,
        127., 190., 320., 280.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([0.0000, 4.8152, 4.7547, 5.2155, 5.1606, 0.0000, 4.9153, 0.0000, 5.2512,
        5.8569, 0.0000, 5.8112, 0.0000, 3.9961, 4.6817, 5.4798],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([0.0835, 5.1888, 5.1347, 5.4824, 5.6323, 0.3121, 5.2410, 0.2379, 5.9728,
        6.2455, 0.2143, 6.1308, 0.0623, 4.3157, 5.0806, 5.7893],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(37.7004, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(38.3820, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([ 1., 40., 75.,  5., 67.,  1., 42.,  1., 75., 29.,  1., 76.,  1., 43.,
        70., 69.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 1., 35., 64.,  3., 48.,  1., 39.,  1., 65., 30.,  1., 59.,  1., 20.,
        63., 61.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 0.0000, 14.9172, 14.7942, 14.3714, 14.1847,  0.0000, 13.3651,  0.0000,
        15.7812, 16.1734,  0.0000, 17.0103,  0.0000, 11.4907, 13.1774, 17.3062],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([ 0.0000, 27.1389, 26.8319, 22.4113, 26.3754,  0.0000, 24.1371,  0.0000,
        28.7720, 26.8945,  0.0000, 28.7496,  0.0000, 18.3521, 24.3357, 29.5813],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(48.2064, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(51.2978, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([ 1., 31., 53., 16., 45.,  1., 22.,  1., 75., 45.,  1., 40.,  1., 43.,
        33., 71.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 1., 20., 40., 14., 27.,  1., 22.,  1., 50., 39.,  1., 34.,  1., 24.,
        24., 58.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 0.0000, 16.7563, 17.4317, 12.4559, 18.4794,  0.0000, 16.9493,  0.0000,
        18.0440, 14.8318,  0.0000, 21.2534,  0.0000, 14.4844, 16.9134, 20.3228],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([ 0.0000, 32.7064, 32.4862, 22.7841, 34.7595,  0.0000, 28.1812,  0.0000,
        34.3291, 25.8091,  0.0000, 40.4882,  0.0000, 24.2633, 27.9156, 36.6054],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(30.8247, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(37.1751, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([ 1., 16., 17., 16., 24.,  1., 15.,  1., 23., 19.,  1., 29.,  1., 28.,
        22., 25.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 2., 11., 11.,  7.,  8.,  2.,  7.,  2., 10.,  8.,  2., 22.,  2.,  8.,
        10., 11.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 0.0000, 11.6186, 14.6034, 16.2769, 11.0606,  0.0000, 10.8940,  0.0000,
        14.4993,  8.6306,  0.0000, 18.2898,  0.0000,  9.5298, 12.5186, 13.4936],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([ 1.4127, 21.3967, 27.3616, 30.0138, 22.8275,  0.3786, 19.1682,  1.1245,
        26.6238, 14.8958,  1.5928, 36.3465,  1.5535, 22.4697, 26.8969, 29.0274],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(10.1092, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(10.0418, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([ 1., 17.,  9.,  1., 11.,  1.,  2.,  1., 11., 10.,  1., 14.,  1.,  2.,
        28.,  8.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 1., 39.,  8.,  2., 12.,  1.,  7.,  1., 14., 13.,  1., 20.,  1.,  1.,
        28.,  4.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([0.0000, 4.4544, 3.8558, 0.0000, 3.9203, 0.0000, 4.7040, 0.0000, 2.6229,
        2.9359, 0.0000, 5.2840, 0.0000, 0.0000, 5.1438, 2.5226],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([0.0000, 7.8355, 6.2844, 1.7763, 8.9012, 0.0000, 9.2867, 0.0000, 5.2123,
        5.2645, 0.0000, 9.4327, 0.0000, 0.0000, 9.4070, 3.9591],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
tensor(0.2932, device='cuda:0') tensor(0.9967, device='cuda:0') min max before 1
torch.Size([16]) sum mask size 1
torch.Size([16]) losssss
torch.Size([16]) losssss
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(7.9439, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(8.1882, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([289., 303., 373., 256., 254., 326., 332., 309., 364., 340., 304., 357.,
        270., 306., 333., 229.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([369., 360., 428., 367., 343., 430., 389., 367., 422., 491., 397., 463.,
        394., 357., 441., 366.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([1.6691, 1.5681, 1.9197, 2.0221, 1.7004, 2.0851, 1.9763, 1.3644, 1.3658,
        1.9244, 1.5074, 1.7703, 1.7396, 2.3350, 1.9457, 2.2295],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([2.5825, 2.3569, 2.6668, 2.8777, 2.7679, 2.8572, 2.6960, 2.0937, 2.2288,
        2.6432, 2.3523, 2.6501, 2.8817, 3.7372, 3.2115, 3.8455],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(14.2618, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(17.0048, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([398., 423., 400., 315., 315., 299., 541., 273., 464., 452., 322., 430.,
        364., 268., 396., 214.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 76.,  75.,  76.,  72.,  49.,  62., 121.,  63.,  93., 100.,  51., 112.,
         77.,  46.,  94.,  47.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([3.6642, 3.4600, 3.3496, 4.1985, 3.4878, 2.9549, 3.5700, 3.4155, 3.5200,
        3.4567, 3.4374, 3.1832, 2.9363, 2.5760, 3.2442, 3.2156],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([6.1145, 5.7405, 4.6514, 5.9544, 5.1318, 4.3327, 5.3305, 5.2687, 4.6288,
        5.5628, 5.4797, 4.9242, 4.0557, 3.7378, 5.0789, 5.6535],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(25.8089, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(28.3902, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([131., 161., 158., 148., 132., 157., 191., 141., 157., 173., 136., 158.,
        160., 125., 181., 125.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 95., 126., 117., 115.,  86., 126., 146., 104., 123., 128., 105.,  95.,
        105.,  98., 110.,  83.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([5.1999, 5.8751, 4.3155, 5.2834, 5.6029, 4.4890, 5.5853, 4.2509, 4.9517,
        5.4278, 4.9281, 5.0477, 4.4014, 4.6025, 5.6548, 6.3585],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([ 9.2822, 11.5788,  8.2814, 10.1673, 11.2105,  8.5748, 10.2026,  8.0826,
         8.5526,  9.8375,  8.9381, 10.4529,  8.4230,  9.1841, 11.0791, 13.2438],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(19.7022, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(19.1153, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([27., 28., 23., 33., 25., 24., 34., 22., 56., 25., 33., 47., 30., 23.,
        46., 10.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([74., 57., 77., 67., 81., 62., 44., 49., 84., 52., 55., 80., 87., 70.,
        76., 47.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([4.1079, 6.4804, 3.1463, 3.2657, 2.1128, 3.1924, 3.6229, 3.1093, 6.3218,
        4.1648, 3.1174, 3.3387, 2.4639, 2.8402, 4.7044, 3.4359],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([ 6.9378, 11.2304,  6.5656,  6.4022,  4.5330,  6.1549,  6.0737,  5.5519,
         9.7150,  8.3162,  5.8992,  5.6332,  4.7797,  6.0260,  8.6320,  5.5077],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(6.7706, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(7.6302, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([ 3.,  9.,  6., 10.,  4.,  3.,  5.,  7., 16.,  8.,  6.,  4.,  6.,  6.,
         2.,  3.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 4., 21.,  4.,  5.,  3.,  4.,  4.,  8.,  6.,  5.,  6.,  4.,  4.,  3.,
         3.,  3.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([1.1864, 1.4864, 1.1410, 0.7340, 1.6746, 0.4483, 0.9687, 0.4645, 1.7313,
        0.9774, 0.7345, 0.1193, 1.0539, 0.8667, 0.0972, 1.1880],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([1.8826, 2.6765, 2.3128, 1.2182, 2.6930, 1.3640, 1.5507, 0.9685, 3.7476,
        2.0571, 1.3830, 0.6890, 1.9929, 2.1581, 0.6512, 1.8516],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
------------ 0.2748148441314697 backwards -------------------------------
1 recon_decay
tensor(0., device='cuda:0') tensor(1., device='cuda:0') min max before 1
torch.Size([16]) sum mask size 1
torch.Size([16]) losssss
torch.Size([16]) losssss
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(14.2898, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(15.5698, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([  1., 191., 165., 156.,   1.,  20., 209.,   1.,  69.,   1.,  37.,  64.,
          1., 265.,   1., 117.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([126., 211., 236., 243., 126., 138., 194., 126., 166., 126., 139., 175.,
        126., 335., 126., 197.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([0.0000, 4.6901, 4.3586, 4.9348, 0.0000, 6.7511, 4.9363, 0.0000, 5.3041,
        0.0000, 4.1740, 4.4386, 0.0000, 5.1334, 0.0000, 6.9005],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([0.1805, 5.2765, 4.7509, 5.4614, 0.0861, 6.7880, 5.3093, 0.0138, 5.3832,
        0.0221, 4.3070, 4.6892, 0.0162, 5.8377, 0.0158, 7.0832],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(37.6084, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(36.6936, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([ 1., 44., 46., 49.,  1., 14., 53.,  1., 33.,  1.,  7., 49.,  1., 48.,
         1., 40.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 1., 55., 51., 55.,  1., 12., 59.,  1., 27.,  1.,  5., 53.,  1., 47.,
         1., 42.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 0.0000, 15.6787, 16.1192, 14.9417,  0.0000, 18.3835, 15.8497,  0.0000,
        16.2098,  0.0000, 13.4857, 12.7987,  0.0000, 16.9278,  0.0000, 18.3286],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([ 0.0000, 28.0833, 28.1476, 26.4351,  0.0000, 30.5331, 25.2799,  0.0000,
        28.3549,  0.0000, 16.9724, 24.0689,  0.0000, 29.7590,  0.0000, 31.2626],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(46.1265, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(52.6526, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([ 1., 57., 53., 55.,  1., 24., 53.,  1., 39.,  1., 27., 40.,  1., 86.,
         1., 42.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 1., 29., 26., 26.,  1., 16., 24.,  1., 17.,  1., 19., 21.,  1., 40.,
         1., 16.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 0.0000, 14.2306, 16.9323, 15.8710,  0.0000, 17.7153, 19.3019,  0.0000,
        21.1077,  0.0000, 11.3387, 15.0755,  0.0000, 16.0747,  0.0000, 20.5765],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([ 0.0000, 28.8699, 32.3354, 30.1494,  0.0000, 33.3956, 32.0064,  0.0000,
        40.2985,  0.0000, 19.9202, 24.9588,  0.0000, 29.1470,  0.0000, 41.0834],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(30.8879, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(33.5938, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([ 1., 18., 28., 13.,  1., 16., 10.,  1., 14.,  1., 13., 21.,  1., 10.,
         1., 15.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 2., 22., 24., 13.,  2., 11.,  9.,  2., 26.,  2., 12., 15.,  2., 16.,
         2., 14.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 0.0000, 11.3920, 11.9902, 13.9628,  0.0000, 15.0407,  9.9041,  0.0000,
        16.5621,  0.0000, 12.9104, 12.6057,  0.0000, 10.0864,  0.0000, 12.7592],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([ 0.1580, 20.9099, 22.1824, 24.6450,  0.8056, 29.1640, 21.9970,  2.6767,
        27.7385,  1.6484, 24.0546, 24.5889,  1.3123, 17.8750,  0.2971, 22.7998],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(10.7502, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(8.5916, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([ 1., 15., 14., 12.,  1.,  2.,  8.,  1.,  5.,  1.,  1.,  8.,  1.,  3.,
         1., 15.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 1., 18., 18., 12.,  1.,  2., 20.,  1., 34.,  1.,  5., 17.,  1.,  5.,
         1., 19.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([0.0000, 3.8753, 2.5344, 2.4742, 0.0000, 2.0931, 1.5478, 0.0000, 2.3891,
        0.0000, 0.0000, 4.3166, 0.0000, 2.2549, 0.0000, 2.2416],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([0.0000, 7.7156, 4.8209, 4.7296, 0.0000, 3.4436, 3.9631, 0.0000, 4.0043,
        0.0000, 1.6984, 7.3202, 0.0000, 3.8762, 0.0000, 3.5204],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
tensor(0.2595, device='cuda:0') tensor(0.9979, device='cuda:0') min max before 1
torch.Size([16]) sum mask size 1
torch.Size([16]) losssss
torch.Size([16]) losssss
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(7.7999, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(8.3412, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([372., 331., 284., 342., 251., 276., 395., 345., 306., 327., 296., 300.,
        314., 412., 339., 378.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([368., 346., 277., 331., 279., 293., 380., 393., 360., 313., 361., 367.,
        339., 371., 324., 387.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([1.1498, 1.6346, 1.6408, 1.2283, 0.8348, 0.9940, 1.4421, 1.4271, 1.1373,
        1.4995, 1.1757, 1.5929, 1.6929, 2.0864, 1.0847, 1.2991],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([1.6977, 2.7088, 2.8209, 1.9284, 1.5816, 1.6555, 2.0686, 2.3362, 1.8156,
        2.4776, 2.0453, 2.8075, 2.7046, 3.4027, 1.6189, 2.0011],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(13.9518, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(14.4262, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([585., 552., 367., 573., 316., 311., 532., 402., 490., 404., 299., 438.,
        598., 642., 474., 486.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([416., 313., 239., 400., 222., 193., 345., 249., 338., 251., 201., 318.,
        376., 447., 296., 320.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([2.6155, 3.2442, 3.5028, 3.3922, 3.4379, 2.9884, 3.0062, 2.7215, 2.5883,
        2.9911, 3.5106, 3.4053, 2.7547, 3.2124, 3.6439, 2.2645],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([3.8575, 4.8387, 5.4130, 4.7645, 5.4270, 4.8375, 4.3357, 4.0692, 3.9631,
        4.8699, 5.3499, 5.3596, 4.2007, 4.8393, 5.4682, 3.7001],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(29.8108, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(31.1902, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([110.,  95.,  88.,  84.,  96.,  99., 113., 124., 103.,  73.,  59.,  70.,
        119., 100.,  95., 115.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 97.,  80.,  75.,  85.,  86.,  89., 104., 110.,  99.,  60.,  52.,  45.,
        102.,  90.,  85., 108.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([3.5504, 5.9438, 4.8170, 3.4729, 4.9640, 4.8265, 4.8646, 3.0758, 3.6562,
        5.0800, 5.3782, 4.6455, 4.6739, 4.7823, 4.0613, 3.9822],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([ 6.7443, 10.7908,  9.7423,  6.7744,  9.2984,  8.9981,  9.2998,  5.9098,
         7.0068, 10.0511, 10.5920,  8.8516,  9.0977,  8.8172,  8.3700,  7.9037],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(20.4767, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(23.9665, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([29., 44., 38., 37., 19., 38., 24., 16., 24., 39., 46., 31., 55., 26.,
        29., 22.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([18., 15., 33., 27., 32., 18., 12., 11.,  5., 22., 24., 17., 43., 20.,
        19., 14.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([1.9978, 3.8144, 4.4100, 4.4643, 3.5047, 4.4378, 3.2149, 1.8404, 2.2168,
        4.6027, 4.9797, 4.7076, 3.7510, 4.0044, 2.9099, 3.4533],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([ 3.9490,  6.2706,  7.7943,  8.8636,  6.0652, 10.2263,  6.8760,  3.8274,
         2.8184,  7.7026,  8.3860,  8.8711,  8.2174,  7.5239,  6.4421,  6.8195],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(6.8320, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(6.4361, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([ 3., 11., 11., 11.,  6., 13.,  1.,  4.,  4.,  7.,  8.,  4.,  7.,  7.,
         1.,  6.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 7.,  7., 36., 17., 12., 18., 10., 10.,  9.,  8., 10., 20., 17.,  9.,
         1.,  6.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([0.6718, 0.8327, 1.5154, 1.2483, 0.8533, 0.6892, 0.0000, 1.8040, 0.3051,
        0.7620, 0.5859, 1.2511, 2.2996, 2.0900, 0.0000, 1.0074],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([1.5821, 1.6821, 3.8178, 2.1547, 1.3437, 1.8636, 0.7543, 2.8666, 1.5818,
        1.9290, 1.8203, 3.8079, 4.2953, 3.7285, 0.0000, 1.9777],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
------------ 0.27518248558044434 backwards -------------------------------
1 recon_decay
tensor(0., device='cuda:0') tensor(1., device='cuda:0') min max before 1
torch.Size([16]) sum mask size 1
torch.Size([16]) losssss
torch.Size([16]) losssss
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(15.5698, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(15.5698, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([  1.,   1.,   1., 153.,  90.,   1.,  85.,   1., 120.,   9.,  42.,  23.,
         90.,   1.,  56., 126.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([126., 126., 126., 218., 224., 126., 240., 126., 171., 139., 166., 147.,
        165., 126., 179., 209.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([0.0000, 0.0000, 0.0000, 5.8872, 5.4832, 0.0000, 4.9257, 0.0000, 5.0640,
        4.3624, 6.3937, 6.0387, 4.4249, 0.0000, 6.0649, 5.2250],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([0.0342, 0.0778, 0.1353, 6.1483, 5.7100, 0.0182, 5.2581, 0.0222, 5.1950,
        4.4198, 6.6449, 6.1658, 4.6253, 0.0192, 6.2692, 5.7114],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(34.7874, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(36.5687, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([  1.,   1.,   1., 157.,  89.,   1.,  88.,   1.,  85.,  31.,  67.,  42.,
         27.,   1.,  71.,  44.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([  1.,   1.,   1., 109.,  65.,   1.,  51.,   1.,  65.,  19.,  37.,  27.,
         23.,   1.,  43.,  36.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 0.0000,  0.0000,  0.0000, 14.2546, 13.5291,  0.0000, 13.4386,  0.0000,
        12.1291, 12.1241, 15.2560, 14.5085,  9.3688,  0.0000, 15.6064, 16.6394],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([ 0.0000,  0.0000,  0.0000, 24.6913, 22.6525,  0.0000, 24.0045,  0.0000,
        21.6138, 20.5517, 25.0921, 26.7848, 16.4081,  0.0000, 26.3601, 31.2473],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(43.7614, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(47.6729, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([  1.,   1.,   1., 120.,  61.,   1.,  59.,   1.,  49.,  27.,  65.,  46.,
         72.,   1.,  61.,  60.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 1.,  1.,  1., 91., 44.,  1., 49.,  1., 31., 19., 43., 18., 46.,  1.,
        43., 47.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 0.0000,  0.0000,  0.0000, 18.9019, 16.6573,  0.0000, 14.9012,  0.0000,
        17.1226, 14.5232, 20.3930, 13.2885, 12.0050,  0.0000, 20.6571, 17.1281],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([ 0.0000,  0.0000,  0.0000, 35.5696, 31.0753,  0.0000, 24.5978,  0.0000,
        33.1662, 27.2405, 37.9682, 23.6570, 22.7447,  0.0000, 37.6072, 30.5783],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(39.7900, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(36.2264, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([ 1.,  1.,  1.,  5.,  8.,  1.,  3.,  1.,  6.,  5., 10., 10., 11.,  1.,
        11.,  2.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 2.,  2.,  2., 14., 11.,  2., 11.,  2.,  7., 19., 16., 10., 18.,  2.,
        17., 16.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 0.0000,  0.0000,  0.0000, 13.6086, 15.6022,  0.0000, 12.3852,  0.0000,
        10.4474, 11.5546, 18.9292, 16.4340, 19.8896,  0.0000, 17.3673,  9.4928],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([ 1.2428,  0.9336,  2.7238, 24.3804, 27.7883,  1.4116, 23.3006,  0.5962,
        20.7999, 22.6425, 33.4346, 30.8213, 35.7230,  0.5466, 31.4931, 20.1936],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(11.1168, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(9.5975, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([ 1.,  1.,  1., 11., 15.,  1.,  1.,  1.,  4.,  5.,  3.,  9.,  3.,  1.,
         3.,  5.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 1.,  1.,  1., 11., 18.,  1.,  9.,  1., 13., 11., 19.,  8., 11.,  1.,
        18., 21.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([0.0000, 0.0000, 0.0000, 2.7887, 2.3031, 0.0000, 0.0000, 0.0000, 3.3260,
        3.4399, 0.7358, 4.4489, 4.0978, 0.0000, 0.3801, 6.3633],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([ 0.0000,  0.0000,  0.0000,  6.1282,  4.3807,  0.0000,  2.1836,  0.0000,
         6.8122,  6.2656,  1.9077,  8.5122,  7.7490,  0.0000,  1.4570, 10.9826],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
tensor(0.2913, device='cuda:0') tensor(0.9987, device='cuda:0') min max before 1
torch.Size([16]) sum mask size 1
torch.Size([16]) losssss
torch.Size([16]) losssss
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(7.9840, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(8.7088, device='cuda:0', grad_fn=<MaxBackward1>) min max before

  6%|███████████████▊                                                                                                                                                                                                                                                               | 22/378 [00:11<03:01,  1.96it/s]
tensor([343., 295., 291., 307., 261., 208., 319., 358., 266., 443., 199., 264.,
        244., 191., 328., 255.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([288., 277., 245., 278., 232., 234., 313., 291., 258., 359., 200., 244.,
        220., 195., 278., 282.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([1.6566, 1.0795, 1.5944, 1.3049, 1.2987, 1.2243, 1.4812, 1.7702, 0.8537,
        1.8004, 0.9584, 0.8479, 1.7229, 0.5728, 1.2378, 1.3000],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([2.3334, 1.5881, 2.1106, 1.7367, 1.6781, 1.8464, 2.1912, 2.7616, 1.3586,
        2.4777, 1.2842, 1.3026, 2.3090, 0.9136, 1.7917, 2.0299],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(14.2277, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(15.0657, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([527., 462., 357., 424., 324., 401., 461., 836., 448., 620., 228., 551.,
        455., 354., 497., 390.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([279., 280., 182., 249., 211., 232., 254., 436., 271., 333., 110., 313.,
        270., 177., 280., 211.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([3.2091, 3.1816, 2.9716, 3.4837, 3.4917, 2.6353, 2.6554, 2.7366, 3.2813,
        3.2073, 3.1478, 2.5912, 2.9377, 3.0461, 2.8267, 2.5553],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([4.5190, 4.8990, 4.2275, 5.3078, 6.1790, 3.7934, 3.5215, 3.8802, 5.2047,
        4.7667, 4.9237, 3.7074, 4.5853, 4.3328, 4.1957, 3.5516],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(27.9960, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(28.5940, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([131., 126., 100., 107.,  71., 122., 142., 193., 121., 147.,  69., 127.,
        114., 104., 142., 123.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([120., 116.,  97., 104.,  70., 123., 130., 187., 120., 146.,  55., 119.,
        101., 116., 140., 122.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([4.2156, 4.9753, 4.5244, 4.6163, 4.5158, 4.0059, 3.8252, 4.2518, 5.3484,
        5.5296, 5.8578, 4.4830, 4.3484, 5.1337, 4.7743, 3.9776],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([ 8.4405,  9.3540,  8.1950,  8.6443,  8.0363,  8.1596,  7.4745,  8.0364,
        10.5458, 10.5693, 11.6879,  8.7016,  8.2631,  9.9760,  8.7077,  7.1957],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(17.2880, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(19.5543, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([ 85., 111.,  55.,  99., 155.,  56.,  56., 125., 107.,  91.,  53.,  98.,
        108.,  82.,  72.,  55.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 75., 108.,  54.,  76.,  77.,  81.,  55.,  87.,  84.,  56.,  86.,  72.,
         50., 113.,  55.,  66.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([2.9008, 3.1519, 2.7802, 3.6095, 4.3641, 3.3552, 2.6185, 3.5734, 3.8197,
        3.2013, 3.0930, 3.2486, 3.7832, 3.2855, 2.8393, 2.5387],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([5.7542, 6.3785, 5.8295, 5.8181, 8.5209, 6.3558, 5.5155, 6.6812, 6.5768,
        7.3832, 5.2677, 5.9456, 7.1646, 6.1872, 5.7963, 6.1133],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(7.6295, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(8.0719, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([ 4.,  5.,  9.,  2., 13.,  4.,  3.,  5.,  2.,  7.,  2.,  2.,  2.,  3.,
         4.,  4.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([4., 4., 5., 3., 5., 6., 4., 7., 7., 8., 5., 1., 3., 5., 4., 5.],
       device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([0.3441, 1.0597, 0.6253, 0.1239, 0.8628, 0.6129, 1.5765, 0.9660, 0.0581,
        2.5921, 0.5424, 0.0293, 0.1868, 0.6499, 1.1782, 0.7314],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([0.6236, 1.5480, 1.4562, 1.7877, 1.9244, 1.2956, 2.8515, 2.1041, 0.3461,
        5.5403, 1.4036, 0.0293, 0.7363, 1.0860, 1.3668, 1.5152],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
------------ 0.2754232883453369 backwards -------------------------------
1 recon_decay
tensor(0., device='cuda:0') tensor(1., device='cuda:0') min max before 1
torch.Size([16]) sum mask size 1
torch.Size([16]) losssss
torch.Size([16]) losssss
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(11.3865, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(11.7864, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([  1., 298.,   1.,   1.,   1., 352.,   1., 581.,   1.,   1.,   1.,   1.,
          1.,  22.,   1., 386.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([253., 519., 253., 253., 253., 553., 253., 672., 253., 253., 253., 253.,
        253., 277., 253., 596.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([0.0000, 4.7354, 0.0000, 0.0000, 0.0000, 5.1517, 0.0000, 3.7507, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 4.2321, 0.0000, 4.0922],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([1.0782, 5.7449, 1.0639, 1.1113, 1.0530, 5.8300, 1.1048, 4.4702, 1.2360,
        1.0814, 1.0595, 1.0550, 1.0931, 5.2585, 1.1153, 4.9464],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(35.1663, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(34.0710, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([ 1., 47.,  1.,  1.,  1., 44.,  1., 71.,  1.,  1.,  1.,  1.,  1.,  2.,
         1., 88.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([  1.,  56.,   1.,   1.,   1.,  68.,   1.,  78.,   1.,   1.,   1.,   1.,
          1.,   4.,   1., 104.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 0.0000, 16.2534,  0.0000,  0.0000,  0.0000, 15.7440,  0.0000, 13.1616,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  8.5208,  0.0000, 14.2564],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([ 0.0000, 27.9370,  0.0000,  0.0000,  0.0000, 25.5131,  0.0000, 23.0502,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  8.9336,  0.0000, 24.6569],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(43.8156, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(42.4161, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([ 1., 57.,  1.,  1.,  1., 56.,  1., 85.,  1.,  1.,  1.,  1.,  1.,  3.,
         1., 56.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([  2.,  62.,   2.,   2.,   2.,  70.,   2., 113.,   2.,   2.,   2.,   2.,
          2.,  11.,   2.,  78.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 0.0000, 19.2576,  0.0000,  0.0000,  0.0000, 15.3850,  0.0000, 11.8820,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  8.3426,  0.0000, 18.5469],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([ 6.8631, 34.8899,  4.4380,  9.5633,  6.0480, 27.3091,  8.1886, 21.1675,
         4.2682,  7.9139,  3.8984,  8.5504,  4.0164, 15.7429,  9.6091, 32.1408],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(30.9338, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(31.0631, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([ 1., 31.,  1.,  1.,  1., 25.,  1., 46.,  1.,  1.,  1.,  1.,  1.,  1.,
         1., 19.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 2., 39.,  2.,  2.,  2., 21.,  2., 62.,  2.,  2.,  2.,  2.,  2.,  5.,
         2., 36.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 0.0000, 14.8509,  0.0000,  0.0000,  0.0000, 12.7474,  0.0000,  9.9809,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, 14.2321],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([ 0.6836, 27.4956,  3.5004,  0.8214,  1.5020, 25.7458,  1.0842, 19.3461,
         1.9666,  0.0898,  2.9800,  2.2245,  0.0800,  5.9452,  0.7913, 26.0472],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(12.2510, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(11.5521, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([ 1.,  9.,  1.,  1.,  1.,  3.,  1., 13.,  1.,  1.,  1.,  1.,  1.,  1.,
         1., 12.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 1., 10.,  1.,  1.,  1.,  1.,  1., 14.,  1.,  1.,  1.,  1.,  1.,  1.,
         1., 11.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([0.0000, 3.0715, 0.0000, 0.0000, 0.0000, 1.6905, 0.0000, 6.6344, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 2.5324],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([ 0.0000,  5.5363,  0.0000,  0.0000,  0.0000,  1.6905,  0.0000, 13.1983,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  4.9445],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
tensor(0.2915, device='cuda:0') tensor(0.9976, device='cuda:0') min max before 1
torch.Size([16]) sum mask size 1
torch.Size([16]) losssss
torch.Size([16]) losssss
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(8.2268, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(7.8893, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([225., 215., 279., 168., 276., 275., 267., 214., 250., 243., 199., 192.,
        257., 247., 206., 212.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([445., 456., 475., 318., 524., 469., 491., 395., 418., 431., 391., 372.,
        441., 464., 372., 385.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([1.3106, 1.5639, 2.0159, 0.9378, 1.5475, 1.5183, 1.5312, 1.1326, 2.2036,
        1.4562, 0.8048, 2.3581, 1.9572, 1.4538, 1.0406, 1.3972],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([2.1629, 2.3495, 2.9979, 1.7542, 2.2763, 2.3260, 2.2320, 1.6614, 3.4216,
        2.3003, 1.5351, 3.6304, 3.1447, 2.2046, 1.7278, 2.1331],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(13.7404, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(15.2552, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([431., 737., 387., 331., 881., 605., 614., 526., 376., 499., 459., 536.,
        387., 639., 408., 565.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([181., 337., 164., 130., 367., 226., 294., 196., 171., 214., 171., 239.,
        170., 256., 184., 224.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([3.3339, 3.4740, 3.0445, 3.3239, 3.4713, 3.0876, 3.2757, 3.0956, 3.0040,
        3.8458, 3.2382, 3.2993, 3.8507, 3.1725, 3.0369, 3.1460],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([5.0818, 5.1404, 4.5999, 5.4591, 5.1162, 4.5553, 4.9968, 4.3070, 4.8146,
        5.9757, 4.7156, 4.8896, 6.5548, 4.4374, 4.0566, 4.7163],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(29.0115, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(30.0000, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([ 57., 133.,  55.,  86., 162., 115., 121., 105.,  74., 119.,  57.,  88.,
         50., 121.,  86., 139.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 63., 126.,  41.,  70., 126., 102., 110., 106.,  68., 127.,  63.,  81.,
         49., 105.,  96., 117.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([4.5562, 5.2917, 5.4915, 4.9411, 5.7241, 4.4775, 5.4162, 6.5985, 4.7871,
        5.0711, 6.3108, 4.8329, 6.2234, 4.0660, 5.0057, 4.2621],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([ 8.3945,  9.9017, 10.5464,  9.6405, 10.5248,  8.9143, 10.2560, 12.4973,
         9.4448,  9.7542, 11.4789,  8.9975, 11.9453,  8.1395,  9.3092,  8.2844],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(19.0267, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(21.7914, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([32., 39., 29., 37., 75., 53., 46., 48., 40., 44., 15., 47., 19., 56.,
        37., 40.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([27., 29., 23., 41., 22., 45., 25., 34., 27., 24., 24., 29., 13., 60.,
        47., 36.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([3.9599, 3.8308, 3.4559, 4.0945, 4.0087, 3.8012, 2.5910, 3.6202, 3.0444,
        2.5671, 3.7737, 2.4715, 4.3758, 3.8375, 3.3023, 4.1607],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([ 6.0475,  6.6817,  5.4934,  6.4383,  7.9833,  8.2877,  4.6461,  8.4949,
         6.9463,  6.2811,  5.8484,  6.1741,  9.2779, 10.1554,  7.5292,  7.2238],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(8.2001, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(7.6964, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([ 4.,  3.,  1.,  2.,  3., 12.,  4.,  2.,  4.,  2.,  2.,  2.,  6.,  2.,
         1.,  1.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 6.,  6.,  4.,  5.,  5., 18.,  7.,  4.,  1.,  3.,  3.,  5.,  3.,  4.,
         9.,  8.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([0.7684, 0.0657, 0.0000, 0.8060, 0.5174, 2.5398, 1.7068, 0.6703, 0.8632,
        0.1369, 0.2368, 1.6546, 0.5865, 0.1777, 0.0000, 0.0000],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([2.1678, 0.9436, 1.1739, 1.9250, 1.5263, 4.2047, 4.1307, 1.5337, 0.8632,
        0.5898, 0.6543, 3.4788, 2.1353, 0.4032, 1.3663, 0.6439],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
------------ 0.27654409408569336 backwards -------------------------------
1 recon_decay
tensor(0., device='cuda:0') tensor(1., device='cuda:0') min max before 1
torch.Size([16]) sum mask size 1
torch.Size([16]) losssss
torch.Size([16]) losssss
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(14.2666, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(15.5768, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([ 91.,  87.,   1., 123.,  78., 115., 217.,   1.,  55., 329., 268.,   1.,
        198.,   1., 162.,  82.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([183., 177., 126., 167., 166., 122., 268., 126., 122., 297., 236., 126.,
        196., 126., 237., 182.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([6.2661, 6.7950, 0.0000, 6.6581, 5.6458, 4.6813, 4.8550, 0.0000, 3.9387,
        6.1113, 6.0782, 0.0000, 4.0469, 0.0000, 4.6629, 6.5226],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([6.4503, 7.2754, 0.0126, 6.9468, 5.7571, 5.0969, 5.2736, 0.0209, 4.1813,
        6.4799, 6.3220, 0.0468, 4.3223, 0.0385, 5.0319, 6.7926],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(35.6329, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(38.3820, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([ 50.,  32.,   1.,  40.,  57.,  10.,  99.,   1.,  21.,  99.,  85.,   1.,
        134.,   1.,  71.,  36.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([29., 19.,  1., 29., 26.,  9., 64.,  1., 17., 40., 55.,  1., 87.,  1.,
        42., 25.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([16.7080, 16.1698,  0.0000, 17.9656, 16.3496, 15.9042, 14.1653,  0.0000,
        11.7333, 14.9344, 16.1031,  0.0000, 11.4258,  0.0000, 13.5177, 16.9586],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([30.6075, 29.6819,  0.0000, 32.6834, 26.7670, 29.8433, 26.3806,  0.0000,
        21.2411, 24.4857, 28.4336,  0.0000, 21.2083,  0.0000, 24.9501, 29.3324],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(48.7423, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(51.2978, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([31., 32.,  1., 32., 32.,  8., 51.,  1., 16., 53., 59.,  1., 70.,  1.,
        32., 40.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([27., 21.,  1., 25., 20.,  4., 40.,  1., 12., 37., 40.,  1., 40.,  1.,
        41., 21.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([23.1158, 19.8249,  0.0000, 21.3489, 21.3266, 15.7792, 17.7848,  0.0000,
        18.7458, 18.9387, 21.2888,  0.0000, 14.8202,  0.0000, 13.8744, 18.2885],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([40.6956, 34.9400,  0.0000, 38.0603, 40.0165, 30.7394, 33.4008,  0.0000,
        32.5595, 35.5390, 40.7532,  0.0000, 25.7008,  0.0000, 24.4329, 32.1506],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(33.0319, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(31.8017, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([14., 20.,  1.,  4., 16., 17., 15.,  1., 18., 15., 15.,  1., 14.,  1.,
        14., 12.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([32., 15.,  2.,  9., 33., 20., 21.,  2., 12., 32., 21.,  2., 29.,  2.,
        24., 33.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([14.3427, 14.8681,  0.0000,  9.1995, 18.1705, 15.6989, 15.0686,  0.0000,
        10.1792, 14.4989, 11.8186,  0.0000,  9.2514,  0.0000, 12.0823, 15.8506],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([26.3354, 26.9142,  0.4330, 21.2031, 29.8285, 29.2310, 26.6317,  1.6490,
        21.3502, 26.8624, 22.3984,  1.7148, 18.3532,  2.1649, 22.9633, 27.7804],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(8.3997, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(10.7083, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([ 4., 27.,  1., 27.,  8., 12., 13.,  1.,  7., 40., 24.,  1.,  9.,  1.,
        23., 22.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 9., 13.,  1., 13., 12.,  6.,  7.,  1.,  7., 27., 12.,  1.,  3.,  1.,
        11., 19.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([0.3957, 2.4093, 0.0000, 1.9925, 0.4322, 4.6970, 3.7860, 0.0000, 3.0978,
        3.3006, 3.2901, 0.0000, 1.4446, 0.0000, 1.3889, 4.4273],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([1.3150, 4.7471, 0.0000, 5.0809, 1.2037, 7.5485, 6.5617, 0.0000, 5.2200,
        6.9723, 6.8786, 0.0000, 2.7212, 0.0000, 4.2269, 7.0166],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
tensor(0.3027, device='cuda:0') tensor(0.9985, device='cuda:0') min max before 1
torch.Size([16]) sum mask size 1
torch.Size([16]) losssss
torch.Size([16]) losssss
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(7.4560, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(8.8705, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([230., 517., 284., 359., 378., 551., 521., 370., 485., 433., 392., 379.,
        552., 462., 393., 372.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([166., 264., 148., 188., 241., 251., 224., 212., 235., 246., 237., 222.,
        273., 240., 191., 201.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([1.1525, 1.2026, 1.8367, 1.1941, 1.2302, 1.8154, 1.4612, 1.3418, 2.1053,
        1.1263, 1.1043, 1.1177, 1.5866, 1.2238, 1.8061, 1.3522],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([1.5191, 1.5187, 2.7843, 1.6842, 1.4867, 2.5203, 2.1958, 1.6003, 2.8851,
        1.4464, 1.4420, 1.3208, 1.9823, 1.5093, 2.7065, 2.1327],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(15.6111, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(16.7621, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([230., 368., 129., 221., 233., 276., 429., 275., 283., 303., 295., 243.,
        283., 234., 206., 209.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 84., 176.,  52., 121., 108., 121., 211., 106., 107., 141., 125., 113.,
        119., 107.,  82., 100.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([4.0997, 2.9613, 2.4107, 3.5185, 2.8215, 3.5821, 2.8050, 2.5266, 3.4710,
        2.8503, 3.0075, 2.7037, 3.0504, 3.0280, 2.7687, 2.8785],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([5.3333, 4.1407, 3.7768, 5.2446, 3.9916, 5.5337, 4.0671, 3.8163, 5.1253,
        4.0215, 5.1053, 3.7200, 4.4836, 4.2513, 4.0488, 4.9361],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(30.4053, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(29.7515, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([ 83., 123.,  65.,  65.,  85., 107., 139.,  81.,  80.,  85., 106.,  73.,
        113.,  85.,  45.,  69.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 98., 137.,  68.,  76.,  96., 110., 156.,  88.,  88.,  91., 115.,  90.,
        123.,  95.,  45.,  79.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([7.6413, 4.3670, 3.9374, 7.0586, 3.6992, 4.7494, 4.6008, 4.1420, 5.0402,
        3.8497, 3.9655, 4.0266, 4.2926, 2.7335, 4.8718, 3.9664],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([14.8106,  8.0623,  7.5306, 12.8860,  7.1025,  8.5125,  8.7589,  8.2727,
         9.5356,  7.1549,  7.5149,  7.7783,  8.1295,  5.6887,  9.3613,  7.9433],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(19.4742, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(21.5135, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([43., 55., 40., 30., 37., 58., 92., 51., 52., 53., 67., 44., 70., 33.,
        25., 39.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([73., 53., 35., 35., 41., 35., 55., 18., 26., 55., 57., 42., 34., 27.,
        31., 42.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([4.7055, 4.4677, 3.7881, 3.0187, 3.7160, 3.6420, 3.9502, 2.8547, 3.3754,
        2.9727, 3.5513, 3.3202, 3.4781, 3.0118, 3.3842, 4.3839],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([7.4034, 7.8602, 8.3121, 6.6062, 6.2981, 7.2974, 7.6431, 5.2721, 6.3406,
        5.9974, 6.0833, 6.0793, 7.3980, 5.9466, 6.6541, 7.5017],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(6.5018, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(7.5482, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([ 6.,  7.,  8.,  3.,  6.,  7., 11.,  4.,  6.,  4.,  4.,  5., 28.,  7.,
         4.,  5.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([10.,  5., 13.,  5.,  1.,  4.,  5.,  1.,  3.,  3.,  5.,  2., 15.,  1.,
         1.,  6.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([1.1135, 0.6672, 0.2363, 1.1936, 0.6347, 1.6450, 1.1017, 0.7078, 1.6178,
        1.4459, 0.6713, 0.6554, 1.6864, 0.9604, 0.9598, 0.6213],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([1.7595, 1.1854, 1.7791, 2.0029, 0.6347, 3.4807, 2.2006, 0.7078, 3.6748,
        1.8952, 1.7028, 1.0759, 2.9198, 0.9604, 0.9598, 1.7051],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
------------ 0.27547788619995117 backwards -------------------------------
1 recon_decay
tensor(0., device='cuda:0') tensor(1., device='cuda:0') min max before 1
torch.Size([16]) sum mask size 1
torch.Size([16]) losssss
torch.Size([16]) losssss
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(11.7306, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(15.5021, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([520., 312., 433., 360.,   1., 853., 362., 360., 388.,   1.,   1.,   1.,
        274.,   1.,   1., 434.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([240., 221., 241., 189., 126., 316., 209., 189., 220., 127., 127., 127.,
        185., 127., 127., 245.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([4.4059, 5.0226, 4.3124, 5.6198, 0.0000, 4.9629, 4.4410, 5.7513, 5.0345,
        0.0000, 0.0000, 0.0000, 4.4056, 0.0000, 0.0000, 4.2677],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([4.6915, 5.5650, 5.0008, 5.7869, 0.0949, 5.2050, 4.6684, 5.8985, 5.3755,
        0.0463, 0.1664, 0.0665, 4.7862, 0.0567, 0.1209, 4.7749],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(36.7976, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(37.2597, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([61., 58., 55., 63.,  1., 84., 20., 63., 17.,  1.,  1.,  1., 32.,  1.,
         1., 67.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([77., 55., 47., 65.,  1., 71., 37., 65., 25.,  1.,  1.,  1., 32.,  1.,
         1., 63.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([14.1404, 17.7957, 15.6141, 16.2675,  0.0000, 16.2151, 13.7624, 16.7636,
        15.3468,  0.0000,  0.0000,  0.0000, 13.7041,  0.0000,  0.0000, 16.0543],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([23.9318, 31.5112, 28.4076, 27.7360,  0.0000, 27.3630, 21.0998, 28.5343,
        25.9620,  0.0000,  0.0000,  0.0000, 23.5812,  0.0000,  0.0000, 29.6064],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(51.8815, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(48.0753, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([20., 27., 29., 44.,  1., 42., 17., 44., 14.,  1.,  1.,  1., 16.,  1.,
         1., 42.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([39., 45., 53., 64.,  1., 64., 25., 64., 20.,  1.,  1.,  1., 29.,  1.,
         1., 76.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([17.6695, 24.4092, 18.4874, 22.4279,  0.0000, 19.5766, 16.9898, 23.0322,
        15.0325,  0.0000,  0.0000,  0.0000, 19.1916,  0.0000,  0.0000, 22.6326],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([29.7530, 43.7832, 32.2460, 39.4330,  0.0000, 35.8721, 28.0533, 40.4216,
        25.0041,  0.0000,  0.0000,  0.0000, 32.0829,  0.0000,  0.0000, 40.2967],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(29.3610, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(37.1494, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([36., 28., 31., 32.,  1., 28., 31., 32., 21.,  1.,  1.,  1., 39.,  1.,
         1., 23.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([15., 17., 16.,  7.,  2., 12., 19.,  7.,  5.,  2.,  2.,  2.,  9.,  2.,
         2., 35.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([13.6811, 15.6891, 14.3021, 15.2554,  0.0000, 13.9644, 15.9076, 15.4248,
        11.6439,  0.0000,  0.0000,  0.0000, 13.7052,  0.0000,  0.0000, 13.1842],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([29.0112, 29.6219, 25.1336, 28.6429,  3.1523, 27.0293, 32.1554, 28.5748,
        21.2987,  0.5645,  0.9558,  1.4941, 24.4577,  0.7367,  2.1033, 23.6679],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(13.5823, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(11.7016, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([14.,  1.,  2.,  1.,  1.,  4., 16.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,
         1.,  1.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([25.,  1.,  2.,  1.,  1.,  3., 45.,  1.,  4.,  1.,  1.,  1.,  1.,  1.,
         1.,  8.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([6.6626, 0.0000, 2.1352, 0.0000, 0.0000, 3.6427, 5.8299, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([12.5072,  0.0000,  3.6056,  0.0000,  0.0000,  5.5078, 10.2531,  0.0000,
         2.4743,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.6383],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
tensor(0.2735, device='cuda:0') tensor(0.9992, device='cuda:0') min max before 1
torch.Size([16]) sum mask size 1
torch.Size([16]) losssss
torch.Size([16]) losssss
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(7.7235, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(8.4637, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([374., 417., 324., 341., 314., 287., 221., 286., 288., 220., 227., 400.,
        366., 310., 255., 308.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([354., 422., 292., 360., 299., 266., 262., 261., 298., 234., 288., 338.,
        367., 329., 300., 293.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([1.4868, 1.9110, 1.1315, 1.4655, 1.6704, 1.7192, 1.2318, 1.5014, 1.1639,
        1.5448, 1.4080, 2.2403, 1.4362, 1.3510, 1.0549, 2.1899],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([2.0471, 2.7108, 1.5810, 2.2548, 2.3478, 2.3946, 2.0118, 2.2001, 1.5888,
        2.5925, 2.4333, 3.5020, 1.8798, 1.9068, 1.5730, 3.7872],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(15.2036, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(16.5758, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([360., 466., 295., 367., 388., 283., 171., 218., 277., 200., 211., 500.,
        273., 292., 264., 393.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([158., 132., 129., 163., 139., 123.,  76.,  87.,  97.,  77.,  75., 204.,
        160., 122.,  93., 165.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([3.3850, 3.3157, 2.7708, 3.1736, 3.2278, 3.3400, 2.6782, 2.8689, 3.1265,
        2.8550, 2.9703, 3.6233, 2.5879, 3.1431, 3.0953, 3.0005],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([4.9179, 4.5820, 4.1470, 5.0747, 4.1454, 5.0367, 3.7498, 4.5446, 3.8174,
        4.0934, 4.8576, 5.1678, 3.8576, 4.6981, 3.9185, 4.5340],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(27.5430, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(30.7882, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([158., 144., 122., 112., 150., 149., 109., 124., 123.,  97.,  95., 165.,
        137., 100., 146., 131.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([114.,  85.,  89.,  77., 106., 113.,  76.,  86.,  87.,  69.,  54., 108.,
        105.,  53., 100.,  83.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([4.1332, 4.7097, 4.7401, 4.4405, 4.5712, 4.7186, 4.2883, 4.1860, 4.8694,
        4.3083, 5.9065, 5.0161, 3.8373, 4.5310, 4.1964, 5.0962],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([ 7.7727,  8.3352,  9.5665,  7.8893,  8.2432,  8.5148,  8.2414,  8.2376,
         8.9701,  8.5269, 11.4579,  9.2777,  7.0197,  8.1416,  7.9302,  8.7686],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(18.2972, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(19.5885, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([ 58.,  53.,  65.,  62., 100.,  65.,  35.,  40.,  57.,  53.,  33.,  71.,
         28.,  52.,  50.,  95.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 53.,  65., 111.,  41.,  68.,  57.,  55.,  37.,  68.,  97.,  82.,  74.,
         68.,  45.,  57.,  70.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([3.3875, 3.1957, 3.2424, 2.7341, 4.0801, 3.8396, 3.1181, 3.8817, 5.9814,
        4.4838, 3.5484, 4.1954, 2.0978, 2.9059, 3.9686, 3.9536],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([ 6.6535,  5.1053,  6.5557,  5.7133,  7.3230,  7.7118,  5.2407,  7.5904,
        11.6728,  7.0199,  5.6250,  6.6740,  4.8649,  5.3554,  7.8021,  6.8741],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(5.6075, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(6.3323, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([13., 33.,  9., 15., 20.,  9.,  9., 10., 13.,  9., 11., 12., 10., 12.,
        21., 16.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 6., 13.,  4., 12., 19., 10.,  7.,  8., 16., 17., 11.,  9., 10., 10.,
        23., 12.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([1.0827, 2.1056, 1.3590, 1.4303, 1.0429, 1.5795, 1.5564, 1.2922, 1.4969,
        1.7559, 1.2541, 1.2283, 0.6641, 0.6548, 1.7208, 1.0437],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([2.1719, 3.9326, 1.6520, 3.0617, 2.3562, 2.6484, 2.8800, 2.0536, 2.6819,
        2.1647, 2.0629, 2.2314, 1.3457, 1.5629, 4.0291, 2.1812],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
------------ 0.27150607109069824 backwards -------------------------------
1 recon_decay
tensor(0., device='cuda:0') tensor(1., device='cuda:0') min max before 1
torch.Size([16]) sum mask size 1
torch.Size([16]) losssss
torch.Size([16]) losssss
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(12.1947, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(11.9888, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([447., 397., 672., 340.,  33.,   1., 278., 206., 262.,   1.,   1., 121.,
        475.,   1., 291., 301.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([682., 436., 912., 597., 297., 253., 542., 490., 486., 253., 253., 313.,
        676., 253., 404., 578.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([4.6348, 4.8419, 5.0817, 5.0800, 3.9349, 0.0000, 5.0895, 4.8640, 4.2844,
        0.0000, 0.0000, 3.8568, 4.0539, 0.0000, 5.1376, 5.4635],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([5.0844, 5.5054, 5.5085, 5.6798, 4.6041, 0.6193, 5.7299, 5.4050, 4.8214,
        0.6261, 0.6245, 4.3516, 4.6927, 0.6480, 5.8232, 6.0139],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(36.1859, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(38.1329, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([70., 64., 90., 50., 13.,  1., 51., 28., 43.,  1.,  1., 20., 69.,  1.,
        66., 50.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([52., 27., 62., 39.,  7.,  1., 48.,  9., 35.,  1.,  1., 19., 71.,  1.,
        43., 38.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([13.5360, 14.3814, 15.1805, 17.6857, 13.1992,  0.0000, 18.9423, 14.3034,
        12.3885,  0.0000,  0.0000, 14.5599, 15.5285,  0.0000, 14.6884, 17.4413],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([23.8187, 21.9440, 25.8459, 29.4839, 24.9004,  0.0000, 35.6793, 23.3733,
        21.7499,  0.0000,  0.0000, 24.7668, 26.9820,  0.0000, 25.9593, 31.6594],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(43.3736, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(51.2004, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([70., 93., 97., 49., 25.,  1., 58., 37., 58.,  1.,  1., 52., 94.,  1.,
        62., 72.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([22., 25., 42., 14., 12.,  1., 15., 23., 34.,  1.,  1., 16., 48.,  1.,
        29., 40.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([17.3804, 12.8743, 18.6769, 19.8274, 14.3958,  0.0000, 21.2078, 14.9238,
        14.8389,  0.0000,  0.0000, 14.0810, 14.4350,  0.0000, 17.2249, 20.6846],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([34.0630, 26.1547, 35.4513, 34.1565, 26.0017,  0.0000, 44.8918, 25.4741,
        28.6111,  0.0000,  0.0000, 25.3542, 25.3474,  0.0000, 32.5774, 39.2204],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(32.6678, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(34.1889, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([21., 31., 12.,  8., 19.,  1., 14., 15., 12.,  1.,  1., 35., 24.,  1.,
        24., 18.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([14.,  6., 15., 12., 13.,  2., 15., 28., 23.,  2.,  2., 14., 32.,  2.,
        24., 24.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([13.0512, 13.1519, 15.3192, 17.8640, 15.1500,  0.0000, 17.8082, 13.7749,
        11.5363,  0.0000,  0.0000, 15.3896, 12.9991,  0.0000, 13.8341, 18.1925],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([25.3273, 26.2591, 29.9738, 31.3837, 29.1392,  0.4016, 31.0157, 25.3218,
        23.0666,  0.2553,  0.6765, 30.7462, 23.5876,  1.5727, 25.2173, 33.8995],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(10.0848, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(12.5261, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([ 9.,  2., 23., 13.,  8.,  1., 10.,  8.,  1.,  1.,  1., 19.,  5.,  1.,
         6., 15.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 3.,  1., 12.,  7.,  3.,  1.,  2.,  8.,  5.,  1.,  1.,  3.,  2.,  1.,
         1., 12.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([3.7399, 2.1703, 4.2600, 4.1143, 4.6819, 0.0000, 3.5592, 5.2740, 0.0000,
        0.0000, 0.0000, 4.3993, 4.7296, 0.0000, 3.7621, 4.6770],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([ 7.7699,  2.1703,  9.0477,  5.7066,  8.8920,  0.0000,  3.7557, 10.0798,
         4.6610,  0.0000,  0.0000,  7.6305,  8.4595,  0.0000,  3.7621,  9.3754],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
tensor(0.2853, device='cuda:0') tensor(0.9988, device='cuda:0') min max before 1
torch.Size([16]) sum mask size 1
torch.Size([16]) losssss
torch.Size([16]) losssss
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(7.6400, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(7.7864, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([357., 316., 566., 263., 312., 347., 343., 456., 321., 255., 376., 250.,
        318., 420., 344., 350.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([432., 431., 542., 329., 425., 425., 440., 456., 429., 330., 492., 349.,
        428., 466., 401., 413.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([1.6019, 1.3785, 1.8195, 0.8487, 1.8700, 1.2239, 1.3561, 2.2577, 1.6744,
        2.4815, 1.3639, 0.9222, 1.4849, 1.2520, 1.5619, 1.4525],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([2.2726, 1.8899, 2.5403, 1.3968, 2.6738, 1.6170, 1.9179, 3.4478, 2.3242,
        3.6136, 1.8116, 1.3805, 2.1763, 1.5954, 2.1187, 1.9928],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(15.7793, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(14.8385, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([272., 157., 400., 125., 227., 229., 233., 400., 193., 178., 255., 189.,
        210., 261., 363., 254.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([405., 209., 595., 157., 296., 309., 329., 538., 266., 215., 339., 216.,
        222., 338., 470., 406.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([3.3275, 4.1767, 3.6531, 3.0176, 3.8278, 3.9274, 2.8794, 4.3817, 3.7744,
        3.3688, 3.3123, 3.5002, 2.9733, 3.1085, 3.4806, 3.9483],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([4.7976, 5.6966, 5.0622, 5.0024, 5.5004, 5.5698, 3.8402, 6.1720, 5.6469,
        4.4903, 4.3051, 5.4816, 4.0958, 4.3411, 4.7334, 6.2921],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(27.1164, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(28.0482, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([117.,  75., 191.,  87., 144., 131., 153., 217., 108., 112., 143.,  74.,
         97., 146., 181., 121.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 94.,  66., 167.,  90., 121., 122., 137., 193.,  76.,  86., 137.,  63.,
         75., 146., 154., 111.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([4.4710, 4.4156, 5.5543, 4.3320, 5.1017, 4.0948, 4.6946, 6.3456, 5.2761,
        5.9920, 4.0146, 4.7206, 4.2548, 4.9624, 5.0578, 5.5995],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([ 8.0297,  8.3546, 10.6149,  7.7884,  9.3491,  7.7214,  8.9626, 11.6552,
         9.1629, 11.7035,  7.0901,  9.1371,  7.6252,  9.2837,  9.1479,  9.8277],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(18.7040, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(23.3161, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([70., 35., 48., 54., 27., 42., 67., 58., 36., 50., 60., 59., 45., 31.,
        74., 97.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([46., 21., 18., 26., 27., 32., 38., 22., 14., 26., 28., 29., 17., 18.,
        43., 20.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([3.7038, 2.8204, 3.1646, 3.6227, 4.8228, 2.2626, 3.0090, 4.3414, 3.2715,
        3.0588, 3.5560, 2.9983, 2.6654, 3.2591, 4.4535, 5.9350],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([ 6.6095,  5.2953,  6.2151,  7.3787,  8.3526,  4.1586,  6.0097,  8.8445,
         6.4667,  5.1422,  6.3954,  5.2925,  5.3888,  8.2768,  9.0706, 11.4330],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(6.5264, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(6.4068, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([ 7.,  7.,  6., 13.,  9., 10., 23.,  7.,  5.,  5., 17.,  5.,  9.,  9.,
         7., 23.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([18.,  9., 10., 18.,  9., 16., 31.,  8.,  7.,  5., 19.,  5., 10.,  5.,
        10., 25.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([2.2991, 0.7935, 2.1386, 0.6554, 0.7868, 0.6615, 1.1939, 1.6621, 0.7503,
        1.6174, 1.0268, 0.1312, 1.2730, 1.1090, 1.3035, 2.0867],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([3.3640, 1.8349, 3.3232, 1.4239, 1.8446, 1.8878, 2.3855, 3.2378, 1.3990,
        2.8393, 1.7012, 0.4460, 2.5616, 1.7102, 2.5571, 4.1746],

  7%|██████████████████▋                                                                                                                                                                                                                                                            | 26/378 [00:13<02:55,  2.01it/s]
------------ 0.28600478172302246 backwards -------------------------------
1 recon_decay
tensor(0., device='cuda:0') tensor(1., device='cuda:0') min max before 1
torch.Size([16]) sum mask size 1
torch.Size([16]) losssss
torch.Size([16]) losssss
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(11.5921, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(11.7306, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([337., 390., 384.,   1.,   1.,   1., 467., 621., 242., 327.,   1., 380.,
        258., 441.,   1.,   1.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([540., 638., 594., 254., 254., 254., 697., 811., 448., 577., 254., 605.,
        501., 644., 254., 254.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([5.4563, 4.2167, 3.9686, 0.0000, 0.0000, 0.0000, 4.7363, 5.3338, 5.6594,
        5.4514, 0.0000, 4.2616, 5.5282, 5.1704, 0.0000, 0.0000],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([6.0212, 4.8532, 4.6424, 0.4428, 0.4839, 0.4165, 5.2341, 5.9717, 6.0462,
        5.9435, 0.4785, 4.6232, 6.0717, 5.5369, 0.4952, 0.4543],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(37.2865, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(34.6543, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([27., 52., 40.,  1.,  1.,  1., 75., 73., 30., 56.,  1., 34., 47., 43.,
         1.,  1.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 48.,  75.,  60.,   1.,   1.,   1., 105., 106.,  63.,  69.,   1.,  42.,
         68.,  59.,   1.,   1.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([16.2471, 14.8595, 16.6131,  0.0000,  0.0000,  0.0000, 15.4426, 15.9791,
        16.9985, 18.0316,  0.0000, 13.9797, 18.7038, 17.0778,  0.0000,  0.0000],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([27.7988, 24.8753, 28.7948,  0.0000,  0.0000,  0.0000, 25.9759, 27.4898,
        27.1084, 29.6642,  0.0000, 18.9083, 32.5232, 25.4009,  0.0000,  0.0000],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(48.7713, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(44.9393, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([25., 37., 47.,  1.,  1.,  1., 63., 50., 23., 58.,  1., 16., 49., 23.,
         1.,  1.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([41., 62., 70.,  1.,  1.,  1., 87., 73., 48., 72.,  1., 39., 65., 42.,
         1.,  1.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([21.4066, 18.8925, 16.9317,  0.0000,  0.0000,  0.0000, 20.1836, 18.2217,
        16.4862, 22.6546,  0.0000, 18.8407, 22.0231, 20.7896,  0.0000,  0.0000],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([37.7998, 31.1635, 29.7968,  0.0000,  0.0000,  0.0000, 37.2942, 32.2093,
        30.3864, 40.4125,  0.0000, 32.3436, 37.8875, 36.6937,  0.0000,  0.0000],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(33.6112, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(31.9944, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([ 7., 24.,  7.,  1.,  1.,  1., 16.,  8., 20., 20.,  1.,  3., 15., 15.,
         1.,  1.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([12., 55., 34.,  2.,  2.,  2., 30., 26., 19., 26.,  2., 10., 19., 23.,
         2.,  2.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([12.7248, 15.1572,  7.7729,  0.0000,  0.0000,  0.0000, 15.7030, 12.4774,
        11.1740, 15.2622,  0.0000,  9.0959, 16.9586, 12.7579,  0.0000,  0.0000],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([26.1900, 26.9332, 16.3038,  1.6025,  0.4196,  0.3122, 26.7646, 20.4838,
        22.0810, 26.2261,  1.6181, 21.4135, 28.9970, 24.5752,  0.9079,  1.3870],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(12.9505, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(11.1230, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([ 6.,  1.,  1.,  1.,  1.,  1.,  5.,  1.,  1., 23.,  1.,  1.,  7.,  7.,
         1.,  1.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 5.,  1.,  3.,  1.,  1.,  1., 12.,  6.,  2., 25.,  1.,  7.,  5., 18.,
         1.,  1.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([2.1614, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 5.1718, 0.0000, 0.0000,
        4.4794, 0.0000, 0.0000, 4.4827, 5.3911, 0.0000, 0.0000],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([4.8015, 0.0000, 2.3045, 0.0000, 0.0000, 0.0000, 9.8192, 1.4132, 2.7481,
        8.9012, 0.0000, 4.2489, 9.3432, 8.8149, 0.0000, 0.0000],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
tensor(0.2887, device='cuda:0') tensor(0.9988, device='cuda:0') min max before 1
torch.Size([16]) sum mask size 1
torch.Size([16]) losssss
torch.Size([16]) losssss
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(7.7591, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(8.1431, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([349., 308., 302., 360., 267., 386., 310., 381., 313., 403., 307., 261.,
        311., 242., 223., 302.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([384., 348., 363., 401., 315., 372., 331., 347., 359., 395., 284., 350.,
        325., 346., 333., 308.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([1.6067, 1.3261, 1.2443, 1.4288, 1.9008, 2.2794, 1.2234, 1.4885, 1.4061,
        1.7602, 2.4124, 0.9791, 1.8224, 1.7467, 1.6665, 1.0666],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([2.4529, 1.6470, 1.5966, 1.7541, 2.5965, 3.3498, 1.5425, 1.9968, 1.8223,
        2.4417, 3.7931, 1.3111, 2.8932, 2.3545, 2.2305, 1.4752],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(14.3079, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(15.3180, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([453., 522., 338., 461., 407., 817., 580., 567., 519., 713., 428., 400.,
        414., 406., 314., 328.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([258., 290., 172., 230., 236., 371., 291., 341., 275., 347., 237., 205.,
        215., 248., 169., 166.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([2.6165, 2.7615, 2.9264, 2.7277, 3.1591, 2.8729, 3.2360, 3.0084, 3.3119,
        2.9312, 2.5233, 2.9996, 3.5140, 3.0716, 2.7675, 3.0646],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([3.7746, 4.0203, 4.0287, 3.6002, 4.1824, 4.1993, 4.4704, 4.2039, 4.5253,
        4.0017, 4.1642, 4.0449, 5.4355, 4.5743, 3.5275, 4.8269],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(31.2183, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(31.2202, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([101.,  94.,  90.,  81.,  58., 126.,  77.,  95.,  47.,  98.,  70.,  48.,
         81.,  46.,  41.,  87.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 94.,  98.,  90.,  82.,  57., 119.,  89., 102.,  58., 113.,  77.,  50.,
         85.,  53.,  55.,  88.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([3.8395, 4.2741, 4.6043, 3.6487, 4.8924, 4.9132, 3.9306, 3.4791, 5.0802,
        4.7910, 5.5180, 3.4845, 5.1308, 3.3704, 3.3715, 4.1950],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([ 7.5660,  7.8108,  8.7363,  6.8385,  9.7857, 10.0803,  7.6328,  6.9125,
         9.2301,  8.4675, 10.3968,  6.7919,  9.5981,  6.4821,  6.8011,  8.0446],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(22.6202, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(23.3704, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([14., 13., 28.,  6., 11., 26., 19., 12., 19., 23., 22., 13., 11., 13.,
        15., 11.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([32., 38., 29., 26.,  7., 28., 24., 17., 42., 36., 27., 24., 30., 11.,
        28., 29.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([2.6173, 3.8612, 4.4171, 1.6520, 2.2626, 3.1660, 6.3895, 2.6664, 2.0779,
        4.8175, 3.3195, 4.0698, 5.0476, 2.6115, 2.3736, 3.0359],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([ 6.7208,  7.3578,  6.9589,  3.4641,  4.9435,  6.3122, 10.4242,  6.2836,
         5.0763,  8.8613,  7.1900,  5.9460, 11.7231,  5.2650,  4.9393,  4.7033],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(6.3039, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(7.3561, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([11.,  5., 24.,  5.,  6., 20., 11.,  5.,  9.,  6., 11.,  8., 10.,  9.,
        14.,  5.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([13.,  4., 19.,  6.,  4., 22., 13.,  4.,  8.,  9.,  6.,  6., 14.,  3.,
         3., 14.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([1.7654, 1.3020, 1.0558, 1.0987, 1.0368, 1.2324, 1.3801, 1.3533, 1.6667,
        1.4709, 1.3076, 0.6438, 1.7855, 1.4618, 0.9654, 1.1329],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([5.1699, 2.4821, 2.4048, 2.4523, 1.2514, 3.0284, 2.8494, 2.3177, 2.3818,
        3.1801, 2.0912, 1.2049, 4.3001, 1.9978, 1.3366, 2.1329],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
------------ 0.2781257629394531 backwards -------------------------------
1 recon_decay
tensor(0., device='cuda:0') tensor(1., device='cuda:0') min max before 1
torch.Size([16]) sum mask size 1
torch.Size([16]) losssss
torch.Size([16]) losssss
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(13.0496, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(15.5375, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([100.,   1., 194., 196., 253.,   1., 445.,   1., 262., 563.,   1., 234.,
        310., 342.,   1., 592.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([160., 126., 187., 165., 198., 126., 330., 126., 210., 288., 126., 225.,
        203., 197., 126., 302.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([3.3678, 0.0000, 4.4052, 6.0090, 4.5429, 0.0000, 5.2912, 0.0000, 5.1698,
        5.5254, 0.0000, 5.0238, 3.7033, 4.8955, 0.0000, 5.1287],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([3.6391, 0.1030, 4.7126, 6.1783, 4.8639, 0.0312, 5.7639, 0.1481, 5.5445,
        5.8373, 0.0220, 5.4429, 3.9571, 5.1534, 0.0440, 5.5610],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(34.5445, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(37.8878, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([ 29.,   1.,  65.,  57.,  85.,   1.,  66.,   1., 112., 106.,   1.,  29.,
         79.,  95.,   1., 133.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([21.,  1., 30., 31., 37.,  1., 32.,  1., 70., 52.,  1., 18., 53., 53.,
         1., 75.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([11.2031,  0.0000, 15.8413, 16.4531, 13.8093,  0.0000, 14.1314,  0.0000,
        15.8179, 14.5739,  0.0000, 14.7054, 11.1712, 12.9976,  0.0000, 15.1727],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([20.1680,  0.0000, 26.0732, 30.3216, 23.6032,  0.0000, 25.6005,  0.0000,
        29.1845, 26.0694,  0.0000, 27.6900, 18.5228, 23.2909,  0.0000, 25.7406],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(47.7416, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(48.0084, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([23.,  1., 27., 52., 44.,  1., 63.,  1., 58., 52.,  1., 35., 38., 39.,
         1., 57.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([26.,  1., 35., 39., 46.,  1., 49.,  1., 75., 47.,  1., 26., 36., 36.,
         1., 70.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([16.9973,  0.0000, 21.7695, 21.1191, 18.7119,  0.0000, 16.8263,  0.0000,
        20.8895, 18.4578,  0.0000, 17.6685, 15.0957, 19.0965,  0.0000, 18.9848],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([30.8240,  0.0000, 37.4304, 39.3851, 32.8078,  0.0000, 31.2853,  0.0000,
        36.2923, 34.8135,  0.0000, 31.9638, 27.2086, 34.6946,  0.0000, 33.5515],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(33.1095, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(32.2392, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([23.,  1., 25.,  9., 10.,  1.,  7.,  1., 18., 11.,  1.,  6., 22., 18.,
         1., 13.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([28.,  2., 47., 11., 34.,  2., 21.,  2., 21., 26.,  2., 10., 38., 23.,
         2., 28.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([14.4179,  0.0000, 18.7951, 12.6287, 12.7648,  0.0000, 14.2913,  0.0000,
        14.5102, 13.5353,  0.0000, 15.6422, 11.8323, 13.5201,  0.0000, 17.7831],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([25.6237,  0.4637, 33.4983, 22.9557, 20.7366,  1.0080, 24.0323,  0.7714,
        27.0539, 26.5443,  0.8276, 28.2682, 21.9761, 25.4689,  1.1227, 31.1333],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(9.2840, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(9.0701, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([14.,  1., 14., 25., 10.,  1.,  2.,  1.,  9., 27.,  1., 19., 21., 11.,
         1., 10.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([17.,  1., 31., 22., 14.,  1.,  6.,  1., 19., 34.,  1., 48., 44., 12.,
         1., 17.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([3.8537, 0.0000, 3.1753, 2.7185, 1.1788, 0.0000, 1.8087, 0.0000, 1.7377,
        4.2410, 0.0000, 3.6656, 3.4035, 3.5474, 0.0000, 3.6956],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([6.3456, 0.0000, 6.2109, 5.4116, 2.7944, 0.0000, 2.9263, 0.0000, 3.5363,
        7.6110, 0.0000, 6.0140, 5.1349, 7.8431, 0.0000, 6.8896],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
tensor(0.3007, device='cuda:0') tensor(0.9993, device='cuda:0') min max before 1
torch.Size([16]) sum mask size 1
torch.Size([16]) losssss
torch.Size([16]) losssss
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(8.5500, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(8.3411, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([162., 107.,  69.,  68.,  97.,  95.,  95., 132., 168.,  76., 225.,  66.,
        100., 182., 127., 134.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([362., 326., 247., 331., 278., 342., 329., 330., 294., 274., 375., 323.,
        301., 360., 283., 303.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([2.5360, 2.0758, 2.4743, 2.0322, 3.2774, 1.6066, 2.6766, 2.0033, 2.2107,
        2.5055, 2.5583, 1.9993, 2.2634, 1.9909, 2.6829, 2.6622],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([3.0176, 2.3450, 3.2267, 2.2535, 4.1278, 1.8681, 3.0471, 2.4102, 2.9603,
        3.0159, 3.2161, 2.2128, 2.4630, 2.5301, 3.4236, 3.2315],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(16.0795, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(16.2759, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([232., 293., 155., 225.,  86., 267., 179., 216., 436., 135., 416., 263.,
        309., 317., 188., 184.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([165., 222., 136., 113.,  66., 216., 131., 135., 311.,  87., 297., 177.,
        242., 223., 117., 115.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([3.2375, 3.0662, 3.6615, 3.0405, 3.0647, 3.2892, 3.2523, 2.4151, 2.9724,
        3.9223, 3.5412, 2.9101, 3.4848, 2.7521, 2.8623, 2.9449],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([4.5098, 4.3258, 5.0105, 5.0487, 4.2398, 4.3655, 5.0134, 3.4848, 4.3685,
        5.0941, 4.7079, 4.1370, 4.8181, 3.7892, 4.0542, 3.9673],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(30.5222, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(30.6751, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([106., 105.,  70.,  88.,  35.,  94.,  48.,  81., 156.,  53., 137., 103.,
         91., 130.,  60.,  88.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([106., 108.,  55.,  95.,  31., 114.,  45.,  96., 149.,  43., 140.,  94.,
        103., 117.,  54.,  85.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([3.7772, 3.5960, 4.7125, 3.6842, 5.3768, 4.0748, 3.1131, 3.3491, 4.2979,
        6.1040, 5.2594, 3.6301, 4.5674, 3.8880, 4.3785, 3.8968],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([ 7.1640,  6.4498,  9.3630,  6.7716, 10.5511,  7.5534,  5.4194,  6.5127,
         8.4304, 11.0734,  9.8554,  7.0778,  8.4156,  7.4716,  8.5712,  7.2882],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(19.7448, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(18.5229, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([38., 39., 33., 37., 19., 41., 32., 28., 64., 17., 34., 56., 46., 30.,
        37., 27.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 61., 105.,  64., 115.,  32., 107.,  48.,  65.,  96.,  72.,  74., 122.,
         72.,  79.,  80.,  57.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([2.8869, 4.0768, 5.7909, 2.0705, 4.1002, 3.3705, 4.8270, 4.9303, 5.1899,
        2.8756, 4.9280, 3.1885, 3.4235, 3.2881, 3.6015, 4.1612],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([5.9882, 6.9049, 8.7030, 4.1509, 7.9656, 6.5291, 8.0156, 8.0227, 8.9672,
        4.7545, 8.1720, 5.7109, 6.4000, 6.4649, 5.7666, 8.3146],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(6.7580, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(6.0607, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([ 7.,  4.,  5.,  8.,  4.,  3.,  7.,  4., 20.,  4.,  7., 14.,  3.,  6.,
        13.,  5.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([29., 22., 23., 17.,  7., 11., 21.,  8., 20., 15., 14., 12.,  3., 23.,
         5., 32.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([1.2205, 1.1065, 0.3388, 0.8607, 0.4932, 0.3090, 1.6269, 0.3957, 1.5414,
        0.5702, 1.3293, 0.7456, 2.1184, 1.1415, 1.0796, 1.1329],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([2.7238, 1.9779, 1.6666, 1.7266, 1.7151, 0.9819, 2.9105, 2.6095, 2.9852,
        1.5072, 2.3169, 1.1950, 3.2787, 3.0734, 1.9459, 3.6634],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
------------ 0.2764863967895508 backwards -------------------------------
1 recon_decay
tensor(0., device='cuda:0') tensor(1., device='cuda:0') min max before 1
torch.Size([16]) sum mask size 1
torch.Size([16]) losssss
torch.Size([16]) losssss
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(14.2666, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(15.5768, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([137.,   1.,  95., 214., 103.,  35.,   1., 230.,  90., 157.,  99., 261.,
          1., 104., 110., 255.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([227., 126., 182., 102., 192., 116., 126., 275., 161., 243., 193., 314.,
        126., 188., 157., 281.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([5.4725, 0.0000, 4.3977, 5.9184, 5.6588, 5.0556, 0.0000, 6.3502, 5.3116,
        4.8189, 7.1023, 5.6890, 0.0000, 5.4697, 4.1361, 5.6634],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([5.6838, 0.0144, 4.6373, 6.4592, 5.8118, 5.0681, 0.0645, 6.7735, 5.4739,
        5.1199, 7.4211, 6.4454, 0.1482, 5.6859, 4.3253, 5.9335],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(37.4335, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(37.2085, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([41.,  1., 65., 35., 29., 14.,  1., 71., 64., 50., 23., 49.,  1., 51.,
        56., 70.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([53.,  1., 69., 47., 22., 14.,  1., 77., 60., 51., 26., 45.,  1., 49.,
        59., 71.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([17.1424,  0.0000, 14.2568, 18.9500, 16.6141, 10.1176,  0.0000, 16.2156,
        14.6364, 14.9951, 17.0674, 16.6583,  0.0000, 15.8211, 11.0629, 16.2260],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([30.0650,  0.0000, 25.0341, 33.9287, 27.6167, 18.7514,  0.0000, 29.1236,
        26.3386, 26.9684, 29.3657, 29.6422,  0.0000, 27.9873, 20.3739, 26.2260],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(51.9028, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(48.9200, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([26.,  1., 25., 18., 23., 17.,  1., 39., 41., 32., 22., 35.,  1., 23.,
        44., 40.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([36.,  1., 46., 24., 29., 14.,  1., 49., 37., 39., 31., 72.,  1., 44.,
        43., 57.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([23.0912,  0.0000, 18.5411, 21.4493, 22.6260, 11.0094,  0.0000, 18.5945,
        17.9334, 16.7435, 19.6651, 16.3662,  0.0000, 22.4750, 14.6385, 19.9934],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([40.9119,  0.0000, 30.1752, 36.7637, 39.7128, 23.8601,  0.0000, 33.1886,
        31.5651, 31.3258, 34.2627, 28.0489,  0.0000, 40.4249, 24.2523, 35.2861],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(32.3591, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(33.3666, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([18.,  1., 19., 20., 11., 21.,  1., 10., 19., 12.,  7., 14.,  1., 21.,
        29., 26.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([24.,  2., 21., 16., 14., 11.,  2., 22., 13., 13.,  5., 37.,  2., 25.,
        25., 30.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([16.3499,  0.0000,  9.1819, 13.4772, 16.7819,  9.3099,  0.0000, 11.8206,
        13.8389, 14.0688, 11.6173, 13.9551,  0.0000, 13.9615,  7.6350, 15.7533],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([28.7651,  0.0909, 18.2963, 25.9219, 30.5376, 19.1508,  2.1004, 19.3886,
        24.0667, 25.0452, 17.8127, 25.2116,  3.0919, 27.0837, 15.4698, 28.0013],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(11.1175, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(8.9878, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([ 2.,  1.,  2.,  1., 10.,  1.,  1.,  1.,  5., 12.,  4.,  3.,  1.,  9.,
         1., 17.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 7.,  1., 13., 15., 16.,  2.,  1., 22.,  9.,  8., 27., 22.,  1., 16.,
         5., 25.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([1.1094, 0.0000, 2.4690, 0.0000, 1.7050, 0.0000, 0.0000, 0.0000, 2.2447,
        2.4768, 2.6383, 2.4456, 0.0000, 1.4513, 0.0000, 3.5580],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([2.6984, 0.0000, 5.4035, 2.7357, 2.7176, 1.9386, 0.0000, 2.1690, 6.6748,
        4.8815, 4.9257, 4.8614, 0.0000, 2.7383, 1.6353, 5.8650],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
tensor(0.2829, device='cuda:0') tensor(0.9990, device='cuda:0') min max before 1
torch.Size([16]) sum mask size 1
torch.Size([16]) losssss
torch.Size([16]) losssss
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(7.8539, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(7.9048, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([241., 224., 322., 274., 334., 288., 167., 224., 345., 354., 297., 336.,
        239., 235., 337., 272.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([387., 387., 452., 420., 418., 393., 319., 322., 418., 480., 414., 380.,
        365., 359., 418., 318.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([1.3632, 1.2231, 1.4195, 1.7325, 1.5591, 1.0426, 1.1561, 1.2806, 1.3218,
        1.7525, 1.0413, 1.0097, 0.8601, 1.4038, 2.3538, 1.6295],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([1.6911, 1.4558, 1.7488, 2.4019, 2.0388, 1.3630, 1.4402, 1.8946, 1.6429,
        2.0674, 1.1787, 1.4991, 1.0217, 1.7155, 3.0143, 2.5824],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(15.5043, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(14.3714, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([345., 343., 347., 354., 400., 241., 205., 222., 439., 612., 301., 319.,
        275., 191., 419., 284.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([491., 437., 484., 572., 634., 325., 299., 306., 638., 697., 395., 479.,
        356., 250., 595., 369.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([3.0504, 3.5919, 3.2679, 3.0486, 3.0686, 3.1259, 3.1370, 3.5916, 3.5730,
        3.0613, 3.1083, 2.9121, 3.0308, 2.7306, 3.9910, 3.1586],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([4.1713, 5.0167, 4.3879, 4.3429, 4.1320, 4.0256, 4.2488, 5.0313, 4.8748,
        4.2641, 4.0706, 4.0864, 3.9045, 3.8793, 5.8187, 4.4751],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(28.9346, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(28.7853, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([ 98.,  79., 146., 122., 135.,  97.,  54.,  88., 126., 131.,  64., 137.,
         70.,  61.,  98., 117.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([112.,  88., 140., 142., 161.,  95.,  69.,  84., 158., 153.,  71., 124.,
         75.,  68., 133., 131.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([3.4727, 4.0444, 3.5272, 3.7755, 3.9677, 3.5082, 4.7320, 4.6244, 4.1636,
        5.2069, 3.7896, 4.0889, 4.7726, 4.7785, 5.5178, 5.1006],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([6.1801, 7.6627, 6.8474, 6.5479, 7.3270, 6.7283, 8.9003, 8.4103, 7.7118,
        9.7141, 7.2542, 8.0419, 8.7438, 8.7127, 9.5147, 9.9172],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(22.1082, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(20.5020, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([13., 18., 23., 12., 18.,  7.,  4., 20., 20., 21., 18., 37., 14., 13.,
        22., 27.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([54., 40., 62., 31., 37., 38., 51., 43., 72., 51., 60., 66., 53., 36.,
        68., 55.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([2.7803, 2.6321, 3.6220, 1.5697, 2.6523, 2.2571, 0.6998, 3.3946, 3.5302,
        3.1915, 2.8463, 4.5000, 1.7630, 1.8954, 3.0357, 3.6193],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([5.4575, 5.1153, 5.5429, 4.6315, 5.8024, 4.6107, 2.7848, 5.7667, 8.0141,
        6.2644, 5.0608, 8.7592, 4.3350, 4.6207, 6.4251, 6.8098],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(6.1036, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(6.6640, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([11.,  6.,  7.,  6.,  6.,  5., 11.,  5.,  6., 21., 17., 24.,  5.,  6.,
        12., 19.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([11., 13.,  9.,  7., 13.,  7., 13.,  5., 12., 16.,  9., 37.,  5.,  4.,
         4., 29.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([0.9381, 0.8029, 0.7798, 0.9781, 0.8987, 0.6310, 1.0611, 1.3514, 0.9376,
        2.0088, 1.5034, 1.5723, 0.4730, 1.0758, 1.4107, 1.4236],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([1.3854, 1.6061, 1.6158, 1.8051, 2.3238, 1.8690, 2.1377, 2.2668, 1.6160,
        3.1088, 3.2291, 3.4967, 1.2366, 1.5321, 3.8296, 2.9925],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
------------ 0.2745964527130127 backwards -------------------------------
1 recon_decay
tensor(0., device='cuda:0') tensor(1., device='cuda:0') min max before 1
torch.Size([16]) sum mask size 1
torch.Size([16]) losssss
torch.Size([16]) losssss
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(14.4665, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(16.2594, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([  1.,  41.,   1.,  24.,  64.,   1., 112.,   1.,  45., 191.,  28., 159.,
        233.,  23.,   1.,  98.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 1., 13.,  1.,  7., 22.,  1., 31.,  1.,  7., 64., 16., 42., 43., 13.,
         1., 64.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([0.0000, 6.6772, 0.0000, 6.1525, 5.4387, 0.0000, 5.8840, 0.0000, 5.3854,
        5.3290, 4.8947, 5.3252, 5.7507, 4.0087, 0.0000, 4.6202],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([0.0000, 7.4893, 0.0000, 6.6502, 6.1835, 0.0000, 6.3709, 0.0000, 6.1741,
        5.6934, 5.2891, 5.7028, 6.3693, 4.4547, 0.0000, 5.0260],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(37.2417, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(37.2205, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([ 1., 15.,  1., 18., 32.,  1., 54.,  1., 24., 89., 30., 51., 36., 18.,
         1., 75.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 1., 12.,  1., 12., 28.,  1., 58.,  1., 27., 75., 25., 55., 40., 19.,
         1., 64.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 0.0000, 14.4514,  0.0000, 17.8609, 15.1905,  0.0000, 14.8228,  0.0000,
        14.9469, 15.5186, 18.7234, 15.1088, 16.7642, 13.3048,  0.0000, 12.9243],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([ 0.0000, 23.3666,  0.0000, 31.8367, 25.4360,  0.0000, 25.9626,  0.0000,
        25.9480, 28.5110, 33.4141, 27.1072, 30.2901, 24.0270,  0.0000, 22.8265],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(59.9828, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(59.3215, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([ 1.,  6.,  1., 13.,  7.,  1., 12.,  1.,  5.,  9., 15., 11., 11., 10.,
         1., 15.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 1.,  4.,  1.,  9.,  9.,  1., 14.,  1.,  6., 11., 10., 13., 16.,  9.,
         1., 24.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 0.0000,  6.4520,  0.0000, 16.8559, 18.2036,  0.0000, 24.2360,  0.0000,
        19.5963, 22.1204, 16.0892, 17.5073, 12.8992, 11.5483,  0.0000, 11.1009],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([ 0.0000, 14.0395,  0.0000, 33.4031, 36.4991,  0.0000, 43.3903,  0.0000,
        32.6863, 42.9941, 29.9240, 31.2888, 26.5897, 21.1673,  0.0000, 21.3648],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(33.8744, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(33.5911, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([ 1., 13.,  1., 11., 17.,  1., 27.,  1., 12., 12., 18., 11.,  2., 15.,
         1., 20.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 2., 17.,  2.,  8., 30.,  2., 36.,  2., 15., 30., 30., 20., 12.,  6.,
         2., 23.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 0.0000, 15.4981,  0.0000, 16.9074, 16.6846,  0.0000, 15.0605,  0.0000,
        12.3620, 15.5513, 15.8544, 14.1406,  5.4426, 13.3916,  0.0000,  5.3449],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([ 1.0981, 29.3337,  1.0818, 33.0653, 30.0784,  0.3692, 28.3902,  0.9097,
        22.9930, 28.8039, 29.6940, 22.5103, 13.7003, 21.1230,  0.7505,  9.9686],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(8.5176, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(8.7518, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([ 1.,  6.,  1.,  8., 31.,  1., 22.,  1.,  7., 13., 29., 22.,  4., 13.,
         1.,  7.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 1.,  3.,  1.,  6., 48.,  1., 13.,  1., 18., 20., 25., 18., 20.,  7.,
         1.,  5.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([0.0000, 2.7182, 0.0000, 3.1676, 3.7427, 0.0000, 3.4265, 0.0000, 3.1430,
        4.8240, 4.6143, 2.5969, 3.8267, 2.9539, 0.0000, 2.7740],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([0.0000, 4.7187, 0.0000, 5.5378, 6.3822, 0.0000, 5.6397, 0.0000, 5.4474,
        8.2996, 8.8552, 5.0490, 4.7682, 5.9424, 0.0000, 6.1229],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
tensor(0.2882, device='cuda:0') tensor(0.9992, device='cuda:0') min max before 1
torch.Size([16]) sum mask size 1
torch.Size([16]) losssss
torch.Size([16]) losssss
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(7.5089, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(8.0626, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([391., 481., 541., 247., 457., 358., 335., 633., 300., 406., 324., 272.,
        423., 384., 559., 406.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([332., 450., 410., 314., 372., 357., 368., 433., 289., 332., 376., 299.,
        352., 359., 511., 359.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([1.3659, 1.6238, 1.7551, 1.4094, 1.6507, 1.7910, 0.9486, 2.0514, 1.4321,
        1.1675, 1.2969, 1.0921, 1.3070, 1.2710, 1.5477, 1.8856],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([1.8395, 2.1297, 2.2265, 1.8318, 2.1404, 2.3093, 1.0549, 2.7738, 1.9222,
        1.4156, 1.6196, 1.2510, 1.8463, 1.3648, 1.8990, 2.3949],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(15.4873, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(17.3499, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([359., 354., 547., 172., 523., 309., 242., 610., 231., 423., 226., 325.,
        391., 363., 531., 389.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([123., 105., 178.,  70., 186., 110.,  90., 216.,  65., 137.,  68., 105.,
        119., 114., 185., 122.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([3.1254, 3.3063, 3.0217, 2.6438, 2.9743, 2.7646, 2.9851, 3.3313, 3.2847,
        2.9677, 2.5400, 3.2690, 2.9794, 3.2446, 3.3651, 3.0356],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([4.0319, 4.1505, 3.7356, 4.0733, 3.9463, 3.6657, 3.9152, 4.7221, 3.7681,
        4.2995, 3.8331, 4.0270, 4.2651, 4.1047, 4.9870, 4.0326],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(29.1633, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(30.8050, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([127.,  79., 165.,  51., 130., 107.,  49., 117.,  92., 107.,  89., 100.,
        129.,  99., 144., 104.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([122.,  66., 127.,  33., 114.,  95.,  50.,  88.,  77., 107.,  45.,  92.,
        105.,  92., 119.,  86.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([4.1232, 3.6712, 4.6349, 2.9926, 3.5191, 3.5552, 3.0515, 4.5218, 5.0257,
        3.6783, 5.1493, 4.3637, 3.9358, 4.1982, 4.9323, 4.0433],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([ 7.7463,  6.8984,  9.1487,  5.8430,  6.8719,  6.6468,  5.9589,  7.6269,
         9.8835,  6.6855, 10.1450,  8.5820,  7.3720,  8.1025,  8.9521,  7.7269],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(19.4913, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(21.1057, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([33., 19., 88., 34., 56., 33., 36., 51., 17., 23., 27., 40., 42., 26.,
        69., 39.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([33., 30., 89., 20., 50., 58., 26., 49., 34., 56., 39., 67., 51., 36.,
        41., 47.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([2.8725, 2.1482, 4.2473, 4.4735, 3.2216, 2.8963, 3.3388, 5.0544, 2.9155,
        4.2019, 2.7578, 3.3233, 2.7672, 2.5068, 3.4705, 4.0511],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([7.0625, 5.4447, 8.2291, 8.7365, 6.1699, 5.5681, 6.8684, 9.0649, 5.6020,
        6.3832, 4.4227, 5.5502, 5.6507, 4.8315, 5.5776, 7.2130],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(6.1966, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(7.8974, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([ 3.,  4., 43., 12., 17., 11.,  6.,  8.,  3.,  4.,  8.,  6.,  7.,  3.,
        10.,  8.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 6.,  4., 30.,  1.,  4.,  5.,  2.,  2.,  8.,  5.,  6.,  6.,  5.,  2.,
         4.,  7.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([0.4907, 0.7409, 1.5557, 1.3044, 0.5951, 0.6948, 1.3295, 1.1049, 0.5710,
        0.3769, 0.5796, 1.2641, 1.2869, 0.5246, 0.6791, 1.3074],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([2.0602, 1.2575, 3.2782, 1.3044, 1.0324, 1.4976, 2.0620, 1.6228, 1.7880,
        0.8575, 1.2573, 2.2546, 2.7143, 0.5246, 1.2365, 2.8084],

  8%|█████████████████████▌                                                                                                                                                                                                                                                         | 30/378 [00:15<02:53,  2.01it/s]
------------ 0.2761213779449463 backwards -------------------------------
1 recon_decay
tensor(0., device='cuda:0') tensor(1., device='cuda:0') min max before 1
torch.Size([16]) sum mask size 1
torch.Size([16]) losssss
torch.Size([16]) losssss
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(11.2402, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(14.1952, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([441., 472., 240.,   1., 414., 837.,   1.,   1.,   1., 750., 412.,   1.,
        314.,   1.,  16., 661.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([261., 289., 191., 127., 269., 390., 127., 127., 127., 385., 254., 127.,
        235., 127., 133., 339.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([3.8245, 4.9761, 4.4766, 0.0000, 4.8143, 3.7587, 0.0000, 0.0000, 0.0000,
        4.9127, 5.1218, 0.0000, 4.9309, 0.0000, 3.9518, 4.2361],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([4.1984, 5.1231, 4.5821, 0.0773, 5.0771, 4.0966, 0.0252, 0.0287, 0.0292,
        5.3503, 5.4910, 0.0490, 5.2829, 0.0272, 4.1955, 4.6656],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(34.4432, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(34.8135, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([ 71.,  50.,  50.,   1., 103., 209.,   1.,   1.,   1.,  88.,  58.,   1.,
         54.,   1.,   2., 117.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 68.,  50.,  37.,   1., 103., 205.,   1.,   1.,   1.,  80.,  48.,   1.,
         52.,   1.,   2., 123.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([12.5600, 15.1418, 14.6761,  0.0000, 15.5541, 12.7865,  0.0000,  0.0000,
         0.0000, 15.8964, 14.8115,  0.0000, 15.4397,  0.0000,  9.2197, 13.1823],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([19.3571, 26.0141, 26.0365,  0.0000, 26.0589, 22.7870,  0.0000,  0.0000,
         0.0000, 27.5496, 26.2444,  0.0000, 27.1354,  0.0000, 10.0277, 21.8355],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(44.2314, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(45.6102, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([ 53.,  57.,  26.,   1.,  79., 158.,   1.,   1.,   1.,  87.,  56.,   1.,
         57.,   1.,   2.,  66.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 50.,  48.,  38.,   1.,  67., 151.,   1.,   1.,   1.,  72.,  48.,   1.,
         44.,   1.,   2.,  69.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([16.3167, 16.3379, 15.9034,  0.0000, 17.9387, 16.4961,  0.0000,  0.0000,
         0.0000, 17.8312, 16.7892,  0.0000, 18.1782,  0.0000, 11.0276, 15.8986],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([29.9888, 31.1747, 27.6198,  0.0000, 33.5677, 28.1063,  0.0000,  0.0000,
         0.0000, 32.5735, 28.8637,  0.0000, 34.6013,  0.0000, 11.6521, 27.9214],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(31.3289, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(32.5525, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([15., 12.,  9.,  1., 26., 50.,  1.,  1.,  1., 17., 12.,  1., 29.,  1.,
         1., 39.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([14., 18.,  7.,  2., 40., 48.,  2.,  2.,  2., 30., 17.,  2., 33.,  2.,
         2., 35.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([13.9823, 11.6571,  5.5694,  0.0000, 16.0909, 10.6586,  0.0000,  0.0000,
         0.0000, 13.6777, 13.9897,  0.0000, 15.2400,  0.0000,  0.0000, 14.3586],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([28.3083, 20.4828, 13.7198,  2.5044, 29.3663, 19.3943,  0.9625,  0.4239,
         0.7150, 25.6336, 25.0610,  2.1793, 28.1409,  0.2944,  2.5304, 25.2961],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(10.1772, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(9.4899, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([12.,  5.,  4.,  1.,  2.,  5.,  1.,  1.,  1., 16.,  8.,  1., 14.,  1.,
         1., 28.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([13.,  5.,  3.,  1.,  4., 13.,  1.,  1.,  1., 31., 11.,  1., 23.,  1.,
         1., 24.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([2.8689, 4.4565, 2.0552, 0.0000, 2.6262, 1.6440, 0.0000, 0.0000, 0.0000,
        2.1283, 2.8763, 0.0000, 2.5429, 0.0000, 0.0000, 4.1568],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([5.9605, 8.4213, 3.9749, 0.0000, 3.2684, 3.5953, 0.0000, 0.0000, 0.0000,
        4.0816, 4.6903, 0.0000, 4.4153, 0.0000, 0.0000, 7.2628],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
tensor(0.2843, device='cuda:0') tensor(0.9991, device='cuda:0') min max before 1
torch.Size([16]) sum mask size 1
torch.Size([16]) losssss
torch.Size([16]) losssss
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(7.6887, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(8.0234, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([475., 274., 404., 399., 220., 245., 282., 305., 357., 240., 273., 237.,
        249., 314., 311., 563.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([454., 317., 425., 391., 267., 343., 385., 263., 361., 328., 355., 313.,
        292., 322., 384., 518.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([1.5330, 1.5939, 1.4552, 1.3957, 0.9397, 0.9999, 1.5985, 2.1347, 1.6735,
        1.4577, 1.0232, 0.8327, 2.2215, 1.7813, 1.2929, 1.5566],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([1.9702, 1.9055, 1.7322, 1.7036, 1.2066, 1.1297, 2.1830, 3.1778, 2.1241,
        1.6876, 1.1783, 0.9228, 2.8172, 2.6728, 1.6060, 2.0698],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(15.7967, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(16.4480, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([366., 271., 411., 431., 203., 282., 333., 178., 334., 282., 303., 181.,
        183., 171., 280., 620.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([238., 133., 261., 264., 136., 188., 186., 119., 231., 168., 206., 113.,
        105., 103., 178., 367.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([3.3209, 3.3239, 3.2689, 3.3207, 2.9442, 3.8306, 3.9820, 3.0333, 4.2081,
        3.3231, 3.2257, 2.9783, 4.0855, 2.9769, 3.1034, 3.0976],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([4.5799, 5.4473, 4.2116, 4.3585, 3.7084, 4.8336, 5.0921, 4.4392, 5.7290,
        4.2407, 4.8697, 3.8585, 5.6201, 4.4257, 3.7719, 4.3617],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(34.7681, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(35.1309, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([50., 28., 36., 91., 49., 10., 60., 47., 41., 38., 20., 32., 24., 48.,
        59., 95.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([64., 23., 38., 92., 47., 17., 60., 42., 36., 43., 36., 32., 24., 43.,
        59., 91.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([3.7271, 3.0739, 5.2412, 3.7492, 4.1936, 4.3589, 3.4502, 4.0931, 5.7913,
        2.5571, 3.1558, 4.6034, 7.4195, 4.0805, 3.9552, 4.9785],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([ 7.1377,  5.3194,  9.4376,  7.5873,  8.6682,  7.4752,  6.7960,  7.9795,
         9.1678,  5.0808,  5.5434,  8.5036, 12.7730,  8.2291,  7.7522,  9.3503],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(22.5229, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(20.8536, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([ 4., 27., 16., 24., 23., 13., 17., 27., 30., 17., 36., 32., 23., 19.,
        12., 54.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([32., 35., 19., 45., 51., 33., 31., 55., 52., 41., 79., 58., 68., 56.,
        37., 71.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([1.9480, 4.3437, 2.7027, 5.6725, 4.0600, 5.1480, 4.1273, 5.6034, 5.9969,
        4.0641, 4.1316, 3.5163, 5.1790, 3.7169, 1.9205, 4.3768],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([ 4.8198,  8.5216,  5.1296,  9.4494,  7.3529,  6.7476,  6.9380, 10.3423,
        11.6755,  6.9387,  7.0742,  6.5397,  7.4313,  6.2518,  5.0464,  7.9995],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(8.8343, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(8.9734, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([ 1.,  6.,  1.,  1.,  3.,  1.,  1.,  3.,  2.,  2.,  2.,  4.,  1.,  1.,
         1., 24.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 3.,  1.,  1.,  3.,  1.,  2.,  3.,  8.,  2.,  6.,  2.,  4.,  3.,  2.,
         7., 17.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([0.0000, 1.9887, 0.0000, 0.0000, 0.8251, 0.0000, 0.0000, 0.3783, 1.1924,
        0.3909, 0.2316, 2.2207, 0.0000, 0.0000, 0.0000, 2.3642],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([1.2828, 1.9887, 0.0000, 0.2618, 0.8251, 0.4333, 0.5444, 2.5627, 2.3848,
        0.7825, 1.6230, 3.4273, 1.1861, 0.4454, 0.8112, 4.5501],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
------------ 0.27516746520996094 backwards -------------------------------
1 recon_decay
tensor(0., device='cuda:0') tensor(1., device='cuda:0') min max before 1
torch.Size([16]) sum mask size 1
torch.Size([16]) losssss
torch.Size([16]) losssss
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(14.1275, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(11.7824, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([181., 119.,  31., 243.,   1.,  83., 157.,  26., 116., 302., 143., 206.,
        156.,  43.,   8.,   1.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([730., 490., 305., 808., 253., 367., 666., 344., 544., 904., 562., 726.,
        614., 272., 258., 253.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([5.0196, 6.0059, 5.1566, 4.4960, 0.0000, 6.7195, 5.5531, 4.7937, 3.7775,
        4.8270, 5.7252, 5.0149, 5.4037, 5.5033, 5.1314, 0.0000],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([5.2857, 6.2672, 5.4326, 4.8195, 0.0526, 6.8755, 5.8992, 5.0020, 4.1428,
        5.4024, 6.0160, 5.4857, 5.9048, 5.8691, 5.2371, 0.3169],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(37.5663, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(36.4430, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([54., 46., 32., 88.,  1., 26., 67., 28., 75., 88., 57., 67., 60., 14.,
         6.,  1.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 59.,  56.,  33., 113.,   1.,  29.,  88.,  28.,  77.,  93.,  73.,  69.,
         76.,  19.,   8.,   1.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([14.7212, 20.7069, 17.5981, 13.6545,  0.0000, 18.6373, 16.7948, 15.8145,
        11.6968, 16.6666, 17.8963, 12.9143, 17.5810, 14.2633, 15.9592,  0.0000],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([23.9126, 36.3084, 32.2149, 23.8762,  0.0000, 32.6579, 29.0474, 28.3922,
        20.2633, 29.4427, 31.1228, 21.9524, 31.2803, 26.3441, 24.9581,  0.0000],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(52.0932, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(50.6360, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([20., 32., 32., 18.,  1., 17., 40., 18., 30., 50., 26., 27., 33., 19.,
         8.,  1.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([24., 41., 30., 41.,  1., 21., 52., 21., 55., 65., 25., 29., 47.,  9.,
         9.,  1.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([17.7698, 23.5685, 17.0291, 19.8379,  0.0000, 21.0845, 22.2144, 16.3299,
        11.5151, 20.0772, 23.2390, 19.7553, 21.4938, 14.3233, 18.5813,  0.0000],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([30.4645, 40.4464, 31.7929, 34.9256,  0.0000, 37.3795, 37.7618, 28.6752,
        20.2434, 33.2612, 42.7923, 35.1716, 38.0614, 26.0674, 33.6525,  0.0000],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(32.6898, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(37.6614, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([12., 12., 34., 18.,  1., 12., 18., 32., 17., 16.,  9., 17., 21., 16.,
         6.,  1.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([13.,  6., 25., 24.,  2.,  7., 13., 18.,  8., 19.,  9.,  8., 20.,  4.,
         9.,  2.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([16.2344, 17.0406, 16.7708, 15.6310,  0.0000, 10.4753, 14.3885, 17.1422,
         7.6606, 15.5499, 15.6212, 12.5059, 15.5413,  9.9739, 13.7192,  0.0000],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([30.6219, 26.9639, 33.4773, 28.3550,  0.3482, 19.1931, 26.4685, 33.0830,
        12.7200, 28.7233, 28.5430, 24.4781, 28.7225, 21.3681, 25.3026,  0.9756],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(9.7207, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(10.8344, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([15., 13., 20., 12.,  1.,  1.,  7., 27.,  8.,  3.,  5., 12.,  6.,  3.,
         1.,  1.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([10., 16., 15., 13.,  1.,  1., 13., 15.,  5.,  3.,  6.,  8.,  7.,  1.,
         1.,  1.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([3.8528, 4.7704, 4.8477, 4.5919, 0.0000, 0.0000, 1.8772, 5.6037, 2.8135,
        1.4160, 1.9974, 3.7986, 1.8133, 2.6190, 0.0000, 0.0000],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([ 7.5462,  8.3628,  9.4110,  7.0116,  0.0000,  0.0000,  3.6490, 11.0317,
         5.4894,  3.7533,  3.6819,  9.4219,  4.5752,  2.6190,  0.0000,  0.0000],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
tensor(0.2824, device='cuda:0') tensor(0.9993, device='cuda:0') min max before 1
torch.Size([16]) sum mask size 1
torch.Size([16]) losssss
torch.Size([16]) losssss
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(7.5934, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(7.6570, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([433., 307., 571., 316., 374., 285., 212., 461., 603., 478., 447., 439.,
        282., 509., 522., 278.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([463., 358., 587., 430., 492., 399., 351., 460., 636., 489., 476., 402.,
        358., 533., 556., 366.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([1.9051, 2.0358, 1.8352, 1.1136, 1.1085, 1.0515, 1.0593, 1.2885, 1.3533,
        1.2290, 1.6975, 1.6676, 1.5949, 1.8261, 1.2607, 1.5382],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([2.5517, 2.7990, 2.5889, 1.4688, 1.2959, 1.1174, 1.2295, 1.5891, 1.6428,
        1.5140, 2.4367, 2.4023, 2.0699, 2.4919, 1.5822, 1.9298],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(17.0742, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(14.9625, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([194., 148., 338., 160., 192., 181., 127., 184., 460., 232., 236., 156.,
        108., 271., 263.,  97.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([333., 252., 694., 320., 372., 383., 259., 482., 801., 487., 418., 279.,
        214., 589., 534., 251.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([3.4916, 2.8401, 4.0406, 3.2685, 3.0314, 3.5350, 3.7835, 3.4582, 3.3437,
        3.2683, 2.6929, 3.0646, 2.9920, 4.2996, 3.5919, 3.0760],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([4.8207, 4.0503, 5.2717, 4.1018, 3.7827, 4.4512, 4.5516, 4.5095, 4.6855,
        4.4674, 3.8285, 4.1854, 4.2980, 5.3605, 4.7879, 4.0120],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(30.6907, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(31.2463, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([ 80.,  94., 139.,  94.,  92.,  75.,  55., 107., 162., 117., 101.,  97.,
         31.,  90., 114.,  87.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 72.,  75., 144.,  87.,  93.,  86.,  72., 115., 169., 113.,  91.,  99.,
         33.,  99., 112.,  85.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([4.6556, 3.9058, 4.9114, 4.1927, 3.9484, 4.0607, 6.3187, 3.9011, 5.2397,
        3.5678, 4.6201, 4.0040, 2.5700, 5.4036, 4.3362, 3.5475],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([ 8.9691,  7.6169,  9.2167,  7.5802,  7.4621,  7.1783, 11.8818,  7.8548,
         9.6622,  6.4783,  8.6512,  8.0648,  4.5251, 10.2337,  7.9237,  6.5583],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(24.6873, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(25.2532, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([20., 23., 19.,  9.,  5.,  4.,  5., 17., 31.,  8., 10.,  5., 11.,  9.,
        10.,  6.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([17., 19., 19., 12., 15., 28.,  9., 48., 31., 21., 19., 14.,  9., 11.,
        17., 20.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([4.9956, 6.7043, 6.0525, 4.5027, 3.1563, 1.4690, 2.1986, 3.1845, 4.1925,
        2.4723, 4.1435, 2.5538, 4.4157, 3.0551, 2.6419, 6.1657],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([ 9.3022, 14.0532, 10.3781,  7.2585,  5.5910,  4.1032,  4.7393,  7.0385,
         7.0106,  4.3818,  9.4319,  5.2070,  7.8138,  5.2214,  5.3811, 10.2288],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(5.8389, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(7.2944, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([13., 34., 12., 11., 11., 12.,  7., 15., 76.,  8., 17., 30., 37., 27.,
        21., 12.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 3., 10.,  7.,  8.,  5.,  7.,  9.,  2., 46.,  6.,  9., 20.,  8.,  5.,
        14.,  3.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([1.6336, 1.3856, 2.1640, 0.5366, 1.4359, 0.6307, 1.4344, 1.0828, 1.7912,
        1.3596, 1.2851, 1.1772, 2.0602, 1.5693, 2.1291, 0.9626],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([2.5481, 2.6210, 3.1978, 1.0600, 2.6178, 1.0470, 2.6876, 1.3074, 3.4434,
        3.2045, 2.0429, 1.9953, 3.5598, 3.0543, 4.4800, 1.4820],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
------------ 0.27438807487487793 backwards -------------------------------
1 recon_decay
tensor(0., device='cuda:0') tensor(1., device='cuda:0') min max before 1
torch.Size([16]) sum mask size 1
torch.Size([16]) losssss
torch.Size([16]) losssss
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(12.6467, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(15.7383, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([  1., 321.,   1., 333., 393., 341.,   1., 145., 268.,   1., 145.,  14.,
          1.,  58., 416.,   1.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([126.,  88., 126., 192., 188., 262., 126., 154., 152., 126., 180., 130.,
        126., 142., 260., 126.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([0.0000, 4.5964, 0.0000, 4.3734, 4.5996, 4.3008, 0.0000, 5.6006, 3.8595,
        0.0000, 5.8651, 2.9785, 0.0000, 4.8177, 4.5912, 0.0000],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([0.0078, 5.7306, 0.1139, 4.9776, 5.1472, 4.6550, 0.0167, 6.2793, 4.0079,
        0.4768, 6.2061, 3.0093, 0.8185, 4.9456, 4.8741, 0.5049],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(37.2625, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(34.5923, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([  1.,  27.,   1.,  51.,  58.,  53.,   1.,   8.,  76.,   1.,  44.,   7.,
          1.,  33., 149.,   1.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([  1.,  49.,   1.,  94.,  97.,  92.,   1.,  20., 108.,   1.,  64.,  11.,
          1.,  34., 190.,   1.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 0.0000, 17.4061,  0.0000, 13.8641, 15.3717, 14.2645,  0.0000, 14.1088,
        13.1333,  0.0000, 19.3480,  8.7628,  0.0000, 15.5145, 14.4567,  0.0000],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([ 0.0000, 30.7338,  0.0000, 23.5013, 25.7324, 23.3156,  0.0000, 22.0044,
        23.2307,  0.0000, 32.2003, 14.1122,  0.0000, 26.6059, 24.9187,  0.0000],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(50.9191, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(49.5773, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([ 1., 25.,  1., 29., 34., 33.,  1., 18., 53.,  1., 28.,  4.,  1., 22.,
        67.,  1.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 1., 22.,  1., 36., 47., 58.,  1., 14., 47.,  1., 29.,  8.,  1., 23.,
        69.,  1.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 0.0000, 19.4249,  0.0000, 18.1538, 18.9573, 13.7299,  0.0000, 13.6166,
        15.4833,  0.0000, 25.0749, 15.3073,  0.0000, 16.2054, 19.7267,  0.0000],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([ 0.0000, 33.2776,  0.0000, 32.8103, 35.1847, 22.9386,  0.0000, 25.2911,
        26.9481,  0.0000, 43.5958, 26.0568,  0.0000, 26.9565, 35.3069,  0.0000],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(37.9076, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(35.7938, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([ 1., 10.,  1.,  4.,  2., 14.,  1., 11., 17.,  1.,  4.,  2.,  1., 14.,
         4.,  1.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 2., 15.,  2.,  8., 10., 22.,  2.,  9., 27.,  2.,  6.,  5.,  2., 14.,
        19.,  2.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 0.0000, 13.9383,  0.0000,  8.9602,  5.9096, 14.2605,  0.0000, 18.0804,
         4.8334,  0.0000, 13.7346,  7.7274,  0.0000, 18.1302,  9.5671,  0.0000],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([ 0.5032, 27.9060,  0.2489, 16.6066, 19.7357, 28.6834,  0.2305, 36.9333,
         9.5000,  0.6120, 25.9149, 13.8006,  1.5747, 34.8542, 19.2977,  1.1477],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(12.1700, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(12.4730, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([ 1.,  1.,  1.,  6.,  7., 16.,  1.,  6.,  6.,  1.,  6.,  1.,  1., 14.,
         3.,  1.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 1.,  1.,  1.,  5., 10., 22.,  1.,  2.,  5.,  1.,  6.,  1.,  1.,  7.,
         2.,  1.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([0.0000, 0.0000, 0.0000, 1.8500, 5.5733, 5.7686, 0.0000, 5.2826, 2.3103,
        0.0000, 4.6880, 0.0000, 0.0000, 6.1216, 3.4013, 0.0000],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([ 0.0000,  0.0000,  0.0000,  4.2109, 11.2091, 12.4416,  0.0000,  7.9340,
         4.8649,  0.0000,  8.5908,  0.0000,  0.0000, 12.2423,  4.7588,  0.0000],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
tensor(0.2749, device='cuda:0') tensor(0.9993, device='cuda:0') min max before 1
torch.Size([16]) sum mask size 1
torch.Size([16]) losssss
torch.Size([16]) losssss
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(7.9482, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(8.5426, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([242., 328., 380., 253., 290., 324., 265., 259., 277., 248., 252., 192.,
        477., 210., 306., 384.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([215., 333., 252., 282., 353., 276., 260., 241., 244., 301., 288., 286.,
        283., 235., 345., 342.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([1.3293, 1.7247, 1.5996, 1.8188, 1.5785, 1.6324, 2.0275, 2.4985, 1.3733,
        1.5421, 1.0477, 1.2634, 2.1526, 0.8982, 1.5238, 1.9549],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([1.8470, 2.2822, 2.1958, 2.4733, 1.9332, 1.9403, 2.6407, 3.4919, 1.9933,
        1.8706, 1.1174, 1.6099, 2.8148, 1.0559, 1.7708, 2.9222],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(15.0135, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(16.1666, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([459., 696., 824., 350., 474., 467., 306., 286., 592., 447., 528., 173.,
        683., 367., 692., 707.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([231., 379., 381., 185., 256., 241., 151., 122., 297., 230., 267., 105.,
        403., 199., 355., 369.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([3.1954, 3.1627, 2.8298, 2.8747, 3.4814, 3.7176, 2.9764, 2.9458, 3.7471,
        3.3382, 4.0705, 2.6974, 4.2170, 3.4289, 3.3917, 3.4309],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([4.6207, 4.1298, 3.9220, 4.1947, 4.7647, 4.8721, 3.8907, 4.1123, 4.9441,
        5.3752, 5.0265, 3.9275, 5.5671, 4.5074, 4.8916, 4.7110],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(30.5454, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(31.0299, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([108., 110., 157.,  71.,  77.,  99.,  79.,  65., 112.,  54.,  69.,  26.,
        148., 111.,  76., 131.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([103.,  98., 137.,  59.,  79., 102.,  92.,  55., 125.,  48.,  64.,  29.,
        145., 108.,  83., 133.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([4.6485, 3.8823, 4.1292, 4.9262, 4.3673, 4.6235, 3.1298, 3.6804, 3.6308,
        4.3959, 5.1203, 2.9687, 5.0116, 4.2689, 4.4905, 4.2029],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([8.4139, 7.0909, 7.9044, 8.8976, 8.5613, 8.5598, 5.9484, 7.2691, 7.0444,
        8.7004, 8.6480, 5.5885, 9.0720, 7.8320, 8.4271, 7.8930],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(19.3943, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(21.1233, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([31., 56., 60., 84., 40., 33., 78., 24., 42., 48., 39., 23., 64., 23.,
        59., 58.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([65., 46., 37., 78., 28., 42., 61., 32., 40., 35., 43., 12., 53., 50.,
        35., 45.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([4.0520, 5.0792, 3.7493, 3.2317, 3.0596, 2.9417, 3.2180, 3.2152, 2.6019,
        4.9154, 3.9769, 2.3328, 4.7765, 3.5348, 3.5359, 4.0791],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([6.9950, 9.0789, 7.0318, 5.8988, 5.3824, 6.2378, 6.5565, 5.2868, 4.7668,
        8.4530, 6.2830, 4.5623, 8.6738, 5.9921, 6.7836, 7.1651],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(7.7103, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(6.3884, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([ 2.,  3.,  2.,  9.,  2.,  4.,  7.,  4.,  4., 10.,  3.,  2.,  4.,  2.,
         8.,  4.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([12., 23., 11., 12.,  9., 10., 13.,  6., 12., 18.,  8.,  5., 12., 10.,
        26., 14.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([1.2333, 2.4960, 0.1103, 1.2718, 0.3515, 0.9108, 0.9109, 1.0614, 0.3603,
        3.5544, 1.4802, 0.4037, 0.5051, 1.0161, 1.1813, 1.7601],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([2.4660, 3.7839, 1.3697, 2.1357, 1.7333, 1.7417, 2.4513, 2.2433, 0.6758,
        4.5524, 2.9673, 1.7850, 1.9599, 1.8035, 2.3569, 3.6992],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
------------ 0.27467918395996094 backwards -------------------------------
1 recon_decay
tensor(0., device='cuda:0') tensor(1., device='cuda:0') min max before 1
torch.Size([16]) sum mask size 1
torch.Size([16]) losssss
torch.Size([16]) losssss
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(11.8289, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(12.0263, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([106., 501., 662., 430., 760.,   1., 365.,   1., 110.,  76.,   1., 389.,
        175.,   1.,   1., 199.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 300.,  732.,  895.,  642., 1006.,  253.,  607.,  253.,  316.,  327.,
         253.,  613.,  304.,  253.,  253.,  378.], device='cuda:0',
       grad_fn=<AddBackward0>) sum_m_f size
tensor([3.8204, 3.5392, 4.6756, 4.4201, 4.5637, 0.0000, 4.7992, 0.0000, 4.3506,
        4.2169, 0.0000, 4.6682, 5.9387, 0.0000, 0.0000, 4.0367],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([4.2449, 3.9873, 5.0729, 4.8705, 4.8683, 0.1325, 5.1125, 0.2545, 4.6610,
        4.4234, 0.0774, 5.2239, 6.4737, 0.2340, 0.5620, 4.4476],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(37.3704, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(38.7343, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([ 35., 135.,  51.,  46.,  66.,   1.,  60.,   1.,  22.,  29.,   1.,  61.,
         14.,   1.,   1.,  37.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([26., 93., 54., 43., 56.,  1., 57.,  1., 12., 21.,  1., 52., 14.,  1.,
         1., 24.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([13.2633, 12.6252, 17.0368, 15.7230, 15.4557,  0.0000, 18.0127,  0.0000,
        14.7628, 16.6041,  0.0000, 16.9525, 18.0909,  0.0000,  0.0000, 13.5021],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([25.1780, 23.7666, 27.1817, 27.7351, 26.5936,  0.0000, 33.3740,  0.0000,
        26.6125, 32.0712,  0.0000, 31.1626, 34.6198,  0.0000,  0.0000, 25.3048],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(59.1926, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(56.4769, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([14., 16., 14.,  6., 18.,  1., 27.,  1., 12.,  7.,  1., 15.,  9.,  1.,
         1., 12.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([11., 37., 25., 12., 24.,  1., 28.,  1., 11., 13.,  1., 20.,  8.,  1.,
         1., 12.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([18.7188, 18.0807, 26.0841, 19.6827, 21.7857,  0.0000, 21.7174,  0.0000,
        12.4849, 12.2213,  0.0000, 22.5610, 24.0964,  0.0000,  0.0000, 15.3803],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([33.8037, 29.3084, 42.0450, 32.7616, 39.7598,  0.0000, 37.0093,  0.0000,
        24.6188, 26.0401,  0.0000, 38.2016, 44.5209,  0.0000,  0.0000, 24.8671],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(34.6504, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(40.3263, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([19., 17., 20., 18.,  8.,  1., 18.,  1., 14., 22.,  1., 11.,  4.,  1.,
         1.,  9.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 8.,  7., 20., 15.,  4.,  1., 15.,  1.,  9.,  7.,  1., 12.,  1.,  1.,
         1., 11.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([15.0175, 14.9128, 20.3803, 14.8787, 14.9004,  0.0000, 15.9140,  0.0000,
        15.7104, 16.4415,  0.0000, 14.1710,  9.5559,  0.0000,  0.0000, 11.8319],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([30.8067, 29.8149, 37.7397, 29.7988, 30.9844,  0.0000, 28.9701,  0.0000,
        30.3142, 32.0254,  0.0000, 24.7374,  9.5559,  0.0000,  0.0000, 23.1193],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(13.4566, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(12.7521, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([ 4.,  5., 12.,  1.,  4.,  1.,  3.,  1.,  2.,  8.,  1.,  2.,  1.,  1.,
         1.,  4.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 9.,  2., 31.,  2., 14.,  1.,  6.,  1.,  3., 10.,  1.,  3.,  1.,  1.,
         1.,  6.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([4.6436, 1.4747, 4.3669, 0.0000, 5.7531, 0.0000, 3.0284, 0.0000, 2.7745,
        5.1837, 0.0000, 2.5499, 0.0000, 0.0000, 0.0000, 3.3134],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([ 8.4827,  2.9818,  7.9909,  2.0077, 10.7606,  0.0000,  6.7105,  0.0000,
         6.1041, 10.3736,  0.0000,  5.6258,  0.0000,  0.0000,  0.0000,  6.1652],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
tensor(0.2765, device='cuda:0') tensor(0.9992, device='cuda:0') min max before 1
torch.Size([16]) sum mask size 1
torch.Size([16]) losssss
torch.Size([16]) losssss
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(7.5745, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(8.1187, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([482., 380., 341., 297., 264., 462., 404., 429., 241., 408., 514., 638.,
        301., 223., 272., 318.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([417., 356., 344., 304., 289., 427., 404., 341., 301., 393., 435., 432.,
        328., 298., 315., 330.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([1.6589, 0.9755, 1.1176, 1.5463, 1.1481, 1.3966, 1.3051, 1.2904, 0.6937,
        1.0757, 1.3740, 1.5538, 1.1606, 1.2405, 1.0278, 1.6467],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([1.9172, 1.7126, 1.2721, 2.1165, 1.8157, 1.8391, 1.5242, 1.8917, 0.7806,
        1.1864, 1.8658, 2.3721, 1.3259, 1.4670, 1.2052, 2.1597],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(16.1002, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(16.8148, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([477., 296., 385., 214., 131., 374., 274., 321., 200., 366., 494., 550.,
        283., 142., 256., 245.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([261., 181., 196., 135.,  74., 222., 193., 222.,  86., 221., 297., 288.,
        163.,  86., 149., 118.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([3.6441, 2.7315, 3.0759, 3.0917, 3.1093, 2.5605, 3.2118, 3.1981, 3.0311,
        3.2915, 3.2040, 2.6642, 2.8680, 3.0146, 3.2074, 2.7900],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([5.1128, 3.7919, 4.5535, 3.9812, 4.0869, 3.5345, 4.3649, 4.1958, 4.1722,
        4.6093, 4.5712, 3.7646, 3.3358, 4.2215, 4.0158, 3.5817],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(29.3600, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(30.5728, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([140., 122., 109.,  92.,  79., 102.,  90.,  99.,  55.,  81., 155., 161.,
        100.,  51., 101., 118.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([160., 105., 105.,  91.,  60.,  97.,  88., 107.,  45.,  78., 121., 147.,
         87.,  48., 108.,  93.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([5.1056, 4.4488, 3.6670, 4.4246, 5.1583, 3.3413, 4.1533, 3.7325, 4.3162,
        4.4426, 4.4461, 3.9108, 3.7079, 5.0001, 4.6088, 3.5205],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([8.7458, 9.1478, 6.5855, 8.0805, 9.5228, 6.5690, 6.8713, 6.8173, 8.4367,
        8.0997, 8.7258, 7.4735, 6.6825, 8.7367, 9.0820, 6.6754],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(17.7074, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(18.0018, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([ 79.,  93.,  50.,  54.,  76.,  66.,  71.,  49.,  63.,  90., 102., 128.,
         72.,  41.,  65.,  46.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([110., 121.,  86.,  95.,  97.,  81., 111., 132., 107., 148., 114., 124.,
         93.,  69., 156.,  75.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([3.4983, 3.8714, 2.4510, 4.0821, 4.7068, 4.0071, 3.8293, 3.3840, 3.1486,
        3.6732, 3.1817, 3.4516, 2.7815, 2.6081, 2.8370, 3.8087],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([6.4767, 8.0362, 4.6640, 6.6701, 6.8923, 6.9711, 6.4938, 6.3953, 5.0849,
        6.4353, 5.6459, 5.9964, 5.8911, 4.5527, 5.1059, 6.5112],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(5.9511, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(7.2365, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([10., 21., 10.,  5., 12., 15., 11.,  6., 10., 20., 19., 22., 31., 17.,
         8., 13.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 6.,  8.,  6.,  4.,  7., 13., 13., 10.,  5., 10.,  7., 15., 28.,  7.,
         4.,  7.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([0.6061, 1.2447, 1.4010, 1.0135, 1.8217, 1.1070, 1.2324, 1.8635, 0.8398,
        1.3552, 1.6011, 1.0520, 0.8391, 0.9515, 1.1237, 1.5165],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([1.3640, 2.0265, 2.4047, 1.9358, 2.8459, 2.3750, 2.4438, 3.6148, 1.2669,
        3.2068, 3.7299, 2.1978, 1.8967, 2.2824, 2.1489, 2.9136],
  File "lord_exp.py", line 140, in <module>                                                                                                                                                                                                                                         | 33/378 [00:17<02:55,  1.96it/s]
    main()
  File "lord_exp.py", line 133, in main
    args.func(args)
  File "lord_exp.py", line 114, in run_exp
    train_model(model_dict, path_new_exp, model_name, exp_dict['data_l_name'], exp_dict['data_u_name'], exp_dict['data_v_name'], exp_dict['data_t_name'], exp_dict['base_dir'])
  File "lord_exp.py", line 31, in train_model
    take_from_arg = False)
  File "/cs/labs/josko/nirm/embryo_project_version1/embyo_projects_codes/lord-pytorch-unet/lord_unet.py", line 367, in train_ulord
    loaded_model=load_model
  File "/cs/labs/josko/nirm/embryo_project_version1/embyo_projects_codes/lord-pytorch-unet/model/training_unet.py", line 423, in train
    segs_t, classes_t, model_dir, tensorboard_dir, loaded_model, dim)
  File "/cs/labs/josko/nirm/embryo_project_version1/embyo_projects_codes/lord-pytorch-unet/model/training_unet.py", line 518, in train_URLordModel
    self.training_model(model_dir, tensorboard_dir)
  File "/cs/labs/josko/nirm/embryo_project_version1/embyo_projects_codes/lord-pytorch-unet/model/training_unet.py", line 695, in training_model
    reco_loss_epoch, reco_loss_epoch_witha, i)
  File "/cs/labs/josko/nirm/embryo_project_version1/embyo_projects_codes/lord-pytorch-unet/model/training_unet.py", line 364, in do_step_ulord
    batch_u['img'], batch_u['class_id'])
  File "/cs/casmip/nirm/embryo_project_version1/venu-pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/cs/labs/josko/nirm/embryo_project_version1/embyo_projects_codes/lord-pytorch-unet/model/modules_unet.py", line 295, in forward
    generated_img = self.generator(inp_gen, class_adain_params)
  File "/cs/casmip/nirm/embryo_project_version1/venu-pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/cs/labs/josko/nirm/embryo_project_version1/embyo_projects_codes/lord-pytorch-unet/model/modules_unet.py", line 430, in forward
    x = self.last_conv_layers(x)
  File "/cs/casmip/nirm/embryo_project_version1/venu-pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/cs/casmip/nirm/embryo_project_version1/venu-pytorch/lib/python3.7/site-packages/torch/nn/modules/container.py", line 139, in forward
    input = module(input)
  File "/cs/casmip/nirm/embryo_project_version1/venu-pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/cs/casmip/nirm/embryo_project_version1/venu-pytorch/lib/python3.7/site-packages/torch/nn/modules/conv.py", line 443, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/cs/casmip/nirm/embryo_project_version1/venu-pytorch/lib/python3.7/site-packages/torch/nn/modules/conv.py", line 440, in _conv_forward
    self.padding, self.dilation, self.groups)
KeyboardInterrupt
------------ 0.31708598136901855 backwards -------------------------------
1 recon_decay
tensor(0., device='cuda:0') tensor(1., device='cuda:0') min max before 1
torch.Size([16]) sum mask size 1
torch.Size([16]) losssss
torch.Size([16]) losssss
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(11.7547, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(15.5768, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([  1., 418.,   1., 276.,  98., 382., 521., 339.,   1., 495.,   1., 260.,
          1., 449., 334.,   1.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([126., 207., 126., 188., 152., 193., 213., 163., 126., 197., 126., 191.,
        126., 224., 233., 126.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([0.0000, 5.1836, 0.0000, 4.8631, 3.4015, 4.2910, 4.2816, 4.2804, 0.0000,
        4.3469, 0.0000, 5.3906, 0.0000, 4.4317, 5.1509, 0.0000],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([0.3814, 5.5912, 0.1349, 5.4652, 3.6255, 4.7009, 4.6306, 4.7389, 0.5164,
        4.9052, 0.2424, 5.7477, 0.1095, 4.7139, 5.4485, 0.1758],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(37.2417, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(36.9745, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([ 1., 55.,  1., 57., 24., 62., 75., 20.,  1., 63.,  1., 33.,  1., 78.,
        59.,  1.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 1., 66.,  1., 52., 24., 64., 83., 27.,  1., 68.,  1., 37.,  1., 61.,
        58.,  1.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 0.0000, 17.8254,  0.0000, 14.4742, 13.1604, 13.7954, 14.7355, 14.6916,
         0.0000, 12.9495,  0.0000, 17.4854,  0.0000, 15.2422, 17.9935,  0.0000],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([ 0.0000, 28.8882,  0.0000, 25.9743, 23.7619, 23.6293, 25.0701, 25.3557,
         0.0000, 21.8318,  0.0000, 29.8032,  0.0000, 26.5493, 31.9338,  0.0000],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(47.7916, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(49.1622, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([ 1., 52.,  1., 41., 34., 36., 55., 16.,  1., 51.,  1., 31.,  1., 53.,
        52.,  1.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 1., 52.,  1., 34., 31., 42., 56., 15.,  1., 39.,  1., 29.,  1., 55.,
        51.,  1.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 0.0000, 21.4046,  0.0000, 17.7637, 12.4794, 17.0377, 16.5340, 13.6021,
         0.0000, 16.0796,  0.0000, 18.3172,  0.0000, 18.6406, 21.0027,  0.0000],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([ 0.0000, 36.0334,  0.0000, 32.8304, 24.7599, 30.6859, 30.5312, 20.8477,
         0.0000, 28.7674,  0.0000, 33.8277,  0.0000, 33.8325, 39.0449,  0.0000],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(34.9899, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(38.0137, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([ 1., 20.,  1., 19., 15.,  8., 24., 12.,  1., 11.,  1., 15.,  1., 15.,
        13.,  1.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 1., 17.,  1., 15.,  4.,  7.,  7.,  5.,  1.,  9.,  1.,  6.,  1., 11.,
        16.,  1.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 0.0000, 20.2625,  0.0000, 12.3601, 14.1455, 15.2698, 12.8588, 14.2550,
         0.0000, 11.3621,  0.0000, 16.4744,  0.0000, 18.5378, 18.1792,  0.0000],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([ 0.0000, 40.2263,  0.0000, 24.1550, 25.2045, 28.5337, 24.4329, 28.7361,
         0.0000, 22.6716,  0.0000, 32.5041,  0.0000, 37.2146, 31.8455,  0.0000],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(11.6628, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(10.1601, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([ 1.,  3.,  1.,  7., 12.,  1., 17.,  1.,  1.,  3.,  1., 18.,  1.,  1.,
         4.,  1.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 1.,  8.,  1., 12.,  5., 16., 24., 11.,  1.,  8.,  1., 21.,  1.,  9.,
         5.,  1.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([0.0000, 4.8075, 0.0000, 1.3599, 3.2843, 0.0000, 3.9030, 0.0000, 0.0000,
        2.7856, 0.0000, 2.4111, 0.0000, 0.0000, 2.1920, 0.0000],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([0.0000, 8.5188, 0.0000, 3.0157, 6.1946, 2.6385, 7.0988, 1.9818, 0.0000,
        7.0248, 0.0000, 4.8903, 0.0000, 1.4741, 4.3475, 0.0000],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
tensor(0.2771, device='cuda:0') tensor(0.9992, device='cuda:0') min max before 1
torch.Size([16]) sum mask size 1
torch.Size([16]) losssss
torch.Size([16]) losssss
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(7.0717, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(7.9940, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([ 556.,  456.,  559., 1015.,  969., 1038.,  291.,  866.,  501.,  519.,
         476.,  610.,  409.,  438.,  685.,  445.], device='cuda:0',
       grad_fn=<AddBackward0>) sum_m_f size
tensor([366., 354., 337., 443., 433., 465., 266., 427., 326., 349., 328., 386.,
        283., 306., 338., 327.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([1.6558, 1.0193, 1.1455, 1.7026, 1.2124, 1.1481, 1.0818, 0.9919, 1.3935,
        1.3830, 1.3236, 1.3010, 1.7895, 1.1746, 1.3268, 1.0552],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([2.1164, 1.1428, 1.2611, 2.2620, 1.4817, 1.4333, 1.3309, 1.1482, 1.6090,
        1.7978, 1.5199, 1.6409, 2.2917, 1.6669, 1.6970, 1.1859],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(15.4199, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(18.7006, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([366., 362., 464., 674., 765., 739., 145., 677., 250., 454., 254., 466.,
        182., 255., 563., 225.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 55.,  76.,  81., 135., 138., 183.,  31., 126.,  28.,  70.,  33.,  91.,
         30.,  46., 124.,  27.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([3.2377, 3.4466, 2.9740, 3.8531, 3.1051, 3.1578, 3.8966, 2.8567, 3.5394,
        2.5440, 3.7285, 2.6633, 3.2606, 3.0505, 3.1279, 3.0216],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([3.8371, 4.1905, 3.5026, 5.0404, 4.0886, 4.1064, 5.4745, 3.9960, 4.1670,
        3.2360, 4.9413, 3.6753, 4.7393, 4.1127, 3.9486, 3.7436],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(29.2392, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(30.8168, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([ 74.,  74.,  86., 180., 198., 156.,  80., 122., 106.,  86., 110., 136.,
         72., 104., 135.,  94.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 71.,  56.,  78., 145., 173., 137.,  55., 101.,  80.,  76.,  91., 112.,
         49.,  89., 130.,  77.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([4.5241, 4.3287, 3.3195, 4.7788, 4.4206, 4.6675, 6.6587, 4.5336, 4.4532,
        3.7487, 4.9749, 3.4131, 4.1551, 3.8350, 3.7652, 3.2040],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([ 7.6660,  7.8614,  6.1525,  8.4224,  7.6662,  8.7281, 12.2048,  8.4590,
         8.2173,  7.2456,  8.5475,  6.6220,  7.8089,  7.3576,  7.2079,  5.8333],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(23.1264, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(20.6997, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([14., 13.,  9., 16., 21., 31., 22., 36.,  5., 12., 19., 61., 22.,  4.,
        12.,  9.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([41., 65., 42., 33., 47., 69., 43., 74., 50., 23., 43., 88., 52., 65.,
        54., 50.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([3.4633, 3.7300, 3.7807, 4.3508, 3.5181, 3.8802, 5.2355, 4.1399, 3.9897,
        2.1792, 3.5098, 4.3801, 5.3828, 2.3430, 1.8889, 2.0628],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([5.9453, 5.8959, 5.5442, 8.0832, 6.5896, 7.5027, 8.4383, 8.4144, 7.5653,
        4.0785, 6.4056, 7.8939, 9.0102, 5.8948, 4.5380, 4.0024],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
m_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(6.9793, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
mo_f check
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(7.6649, device='cuda:0', grad_fn=<MaxBackward1>) min max before
tensor(0., device='cuda:0', grad_fn=<MinBackward1>) tensor(1., device='cuda:0', grad_fn=<MaxBackward1>) min max after
tensor([ 9.,  6.,  5.,  9.,  2.,  5.,  4., 20.,  6.,  4., 25., 17.,  9.,  5.,
         2.,  3.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([ 7., 13.,  3.,  4.,  4.,  4.,  4., 10., 12.,  6., 14.,  6.,  8.,  8.,
         1.,  5.], device='cuda:0', grad_fn=<AddBackward0>) sum_m_f size
tensor([1.3421, 1.3740, 0.9688, 1.7907, 0.6653, 0.6456, 0.5816, 1.9291, 1.1700,
        1.9332, 0.9172, 1.5883, 1.6080, 1.4596, 1.3627, 0.2184],
       device='cuda:0', grad_fn=<DivBackward0>) layer loss
tensor([3.1103, 2.0887, 1.1831, 2.6120, 4.8243, 1.3571, 0.9500, 4.5460, 2.0903,
        2.9308, 1.7368, 2.9965, 3.1349, 2.5441, 1.3627, 0.8059],
       device='cuda:0', grad_fn=<AddBackward0>) layer loss 2
------------ 0.27634525299072266 backwards -------------------------------
1 recon_decay