True cuda
args: None URLord URLord_2 /cs/casmip/nirm/embryo_project_version1/EXP_FOLDER/exp_fp2/206/exp2d_DF_3_2d True urlord2d_206exp2d_DF_3_2d DF_3_2d_TL DF_3_2d_TU DF_3_2d_VA DF_3_2d_TE False True /cs/labs/josko/nirm/embryo_project_version1/embyo_projects_codes/models_config/config_2d /cs/labs/josko/nirm/embryo_project_version1/embyo_projects_codes/models_config/config_2d
dividing....
(2016, 128, 128, 1) imaggggggeeeeeeeeeeeeeeee shape
[0.] unique claseesssssssssssssssssssssssssssssssssssssssssssssssss
False False load_model
arrive train
2 30 config['n_classes'], config['class_dim']
/cs/casmip/nirm/embryo_project_version1/venu-pytorch/lib/python3.7/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)
  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
/cs/labs/josko/nirm/embryo_project_version1/embyo_projects_codes/lord-pytorch-unet/model/modules_unet.py:356: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  tensor = torch.tensor(x, requires_grad = False)
here seg decay
here recon_loss
  0%|                                                                                                                                                                                                                                                                                        | 0/378 [00:00<?, ?it/s][W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)                                                                                                                                                                                             | 0/378 [00:00<?, ?it/s]
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)                                                                                                                                                                                              | 0/45 [00:00<?, ?it/s]
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)                                                                                                                                                                                             | 0/126 [00:00<?, ?it/s]
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
epoch #0:   1%|██                                                                                                                                                                                                                                                          | 3/378 [00:01<03:25,  1.82it/s, loss=126]
  1%|██▏                                                                                                                                                                                                                                                                             | 3/378 [00:01<03:25,  1.82it/s]
1 recon_decay
------------ 0.10622072219848633 loss -------------------------------
------------ 0.29162120819091797 backwards -------------------------------
1 recon_decay
------------ 0.0873723030090332 loss -------------------------------
------------ 0.2749505043029785 backwards -------------------------------
1 recon_decay
------------ 0.08464670181274414 loss -------------------------------
------------ 0.27406930923461914 backwards -------------------------------

  2%|█████▊                                                                                                                                                                                                                                                                          | 8/378 [00:03<02:37,  2.36it/s]
------------ 0.08451080322265625 loss -------------------------------
------------ 0.2736208438873291 backwards -------------------------------
1 recon_decay
------------ 0.09006857872009277 loss -------------------------------
------------ 0.2737250328063965 backwards -------------------------------
1 recon_decay
------------ 0.08521771430969238 loss -------------------------------
------------ 0.27344655990600586 backwards -------------------------------
1 recon_decay
------------ 0.0857551097869873 loss -------------------------------
------------ 0.2740919589996338 backwards -------------------------------
1 recon_decay

  3%|████████▌                                                                                                                                                                                                                                                                      | 12/378 [00:05<02:30,  2.43it/s]
------------ 0.27451658248901367 backwards -------------------------------
1 recon_decay
------------ 0.08477115631103516 loss -------------------------------
------------ 0.2750544548034668 backwards -------------------------------
1 recon_decay
------------ 0.08790922164916992 loss -------------------------------
------------ 0.27434611320495605 backwards -------------------------------
1 recon_decay
------------ 0.08500266075134277 loss -------------------------------
------------ 0.27356553077697754 backwards -------------------------------
1 recon_decay
------------ 0.08533883094787598 loss -------------------------------
------------ 0.2731618881225586 backwards -------------------------------
1 recon_decay

  4%|████████████▏                                                                                                                                                                                                                                                                  | 17/378 [00:07<02:27,  2.45it/s]
------------ 0.2740023136138916 backwards -------------------------------
1 recon_decay
------------ 0.08473396301269531 loss -------------------------------
------------ 0.27495741844177246 backwards -------------------------------
1 recon_decay
------------ 0.08799028396606445 loss -------------------------------
------------ 0.27448582649230957 backwards -------------------------------
1 recon_decay
------------ 0.0851449966430664 loss -------------------------------
------------ 0.27359676361083984 backwards -------------------------------
1 recon_decay
------------ 0.08569765090942383 loss -------------------------------
------------ 0.27333736419677734 backwards -------------------------------
1 recon_decay

  6%|███████████████▊                                                                                                                                                                                                                                                               | 22/378 [00:09<02:25,  2.44it/s]
------------ 0.27414727210998535 backwards -------------------------------
1 recon_decay
------------ 0.08488178253173828 loss -------------------------------
------------ 0.2758188247680664 backwards -------------------------------
1 recon_decay
------------ 0.08478116989135742 loss -------------------------------
------------ 0.2753157615661621 backwards -------------------------------
1 recon_decay
------------ 0.08678364753723145 loss -------------------------------
------------ 0.27534985542297363 backwards -------------------------------
1 recon_decay
------------ 0.08573627471923828 loss -------------------------------
------------ 0.27375102043151855 backwards -------------------------------
1 recon_decay

  7%|███████████████████▎                                                                                                                                                                                                                                                           | 27/378 [00:11<02:23,  2.44it/s]
------------ 0.2750113010406494 backwards -------------------------------
1 recon_decay
------------ 0.08590555191040039 loss -------------------------------
------------ 0.2764594554901123 backwards -------------------------------
1 recon_decay
------------ 0.08509612083435059 loss -------------------------------
------------ 0.27591705322265625 backwards -------------------------------
1 recon_decay
------------ 0.08875083923339844 loss -------------------------------
------------ 0.27432990074157715 backwards -------------------------------
1 recon_decay
------------ 0.08500003814697266 loss -------------------------------
------------ 0.2744269371032715 backwards -------------------------------
1 recon_decay

  8%|██████████████████████▉                                                                                                                                                                                                                                                        | 32/378 [00:13<02:22,  2.43it/s]
------------ 0.2739682197570801 backwards -------------------------------
1 recon_decay
------------ 0.0868065357208252 loss -------------------------------
------------ 0.27512049674987793 backwards -------------------------------
1 recon_decay
------------ 0.08551573753356934 loss -------------------------------
------------ 0.2754683494567871 backwards -------------------------------
1 recon_decay
------------ 0.08679699897766113 loss -------------------------------
------------ 0.2752344608306885 backwards -------------------------------
1 recon_decay
------------ 0.08566999435424805 loss -------------------------------
------------ 0.27595090866088867 backwards -------------------------------
1 recon_decay

 10%|██████████████████████████▌                                                                                                                                                                                                                                                    | 37/378 [00:15<02:20,  2.43it/s]
------------ 0.2745354175567627 backwards -------------------------------
1 recon_decay
------------ 0.0862267017364502 loss -------------------------------
------------ 0.2743537425994873 backwards -------------------------------
1 recon_decay
------------ 0.08635091781616211 loss -------------------------------
------------ 0.2745018005371094 backwards -------------------------------
1 recon_decay
------------ 0.08570671081542969 loss -------------------------------
------------ 0.27536654472351074 backwards -------------------------------
1 recon_decay
------------ 0.08686113357543945 loss -------------------------------
------------ 0.2751200199127197 backwards -------------------------------

 11%|██████████████████████████████                                                                                                                                                                                                                                                 | 42/378 [00:17<02:18,  2.43it/s]
------------ 0.08580803871154785 loss -------------------------------
------------ 0.27514100074768066 backwards -------------------------------
1 recon_decay
------------ 0.08567190170288086 loss -------------------------------
------------ 0.27436208724975586 backwards -------------------------------
1 recon_decay
------------ 0.08593916893005371 loss -------------------------------
------------ 0.2753920555114746 backwards -------------------------------
1 recon_decay
------------ 0.08556318283081055 loss -------------------------------
------------ 0.2751939296722412 backwards -------------------------------
1 recon_decay
------------ 0.08943605422973633 loss -------------------------------
------------ 0.27471041679382324 backwards -------------------------------
  File "lord_exp.py", line 140, in <module>                                                                                                                                                                                                                                         | 45/378 [00:19<02:16,  2.44it/s]
    main()
  File "lord_exp.py", line 133, in main
    args.func(args)
  File "lord_exp.py", line 114, in run_exp
    train_model(model_dict, path_new_exp, model_name, exp_dict['data_l_name'], exp_dict['data_u_name'], exp_dict['data_v_name'], exp_dict['data_t_name'], exp_dict['base_dir'])
  File "lord_exp.py", line 31, in train_model
    take_from_arg = False)
  File "/cs/labs/josko/nirm/embryo_project_version1/embyo_projects_codes/lord-pytorch-unet/lord_unet.py", line 367, in train_ulord
    loaded_model=load_model
  File "/cs/labs/josko/nirm/embryo_project_version1/embyo_projects_codes/lord-pytorch-unet/model/training_unet.py", line 434, in train
    segs_t, classes_t, model_dir, tensorboard_dir, loaded_model, dim)
  File "/cs/labs/josko/nirm/embryo_project_version1/embyo_projects_codes/lord-pytorch-unet/model/training_unet.py", line 529, in train_URLordModel
    self.training_model(model_dir, tensorboard_dir)
  File "/cs/labs/josko/nirm/embryo_project_version1/embyo_projects_codes/lord-pytorch-unet/model/training_unet.py", line 706, in training_model
    reco_loss_epoch, reco_loss_epoch_witha, i)
  File "/cs/labs/josko/nirm/embryo_project_version1/embyo_projects_codes/lord-pytorch-unet/model/training_unet.py", line 381, in do_step_ulord
    reco_loss_l, reco_loss_u = self.calc_rec_loss(out, batch_t, batch_u, criterion)
  File "/cs/labs/josko/nirm/embryo_project_version1/embyo_projects_codes/lord-pytorch-unet/model/training_unet.py", line 310, in calc_rec_loss_urord
    reco_loss = criterion(out['img'], batch_t['img'] * seg, seg_l)
  File "/cs/casmip/nirm/embryo_project_version1/venu-pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/cs/labs/josko/nirm/embryo_project_version1/embyo_projects_codes/lord-pytorch-unet/model/modules_unet.py", line 602, in forward
    f1 = self.vgg(I1)
  File "/cs/casmip/nirm/embryo_project_version1/venu-pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/cs/labs/josko/nirm/embryo_project_version1/embyo_projects_codes/lord-pytorch-unet/model/modules_unet.py", line 563, in forward
    x = self.vggnet.features[i](x)
  File "/cs/casmip/nirm/embryo_project_version1/venu-pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/cs/casmip/nirm/embryo_project_version1/venu-pytorch/lib/python3.7/site-packages/torch/nn/modules/activation.py", line 102, in forward
    return F.relu(input, inplace=self.inplace)
  File "/cs/casmip/nirm/embryo_project_version1/venu-pytorch/lib/python3.7/site-packages/torch/nn/functional.py", line 1296, in relu
    result = torch.relu_(input)
KeyboardInterrupt
------------ 0.08607149124145508 loss -------------------------------
------------ 0.2756180763244629 backwards -------------------------------
1 recon_decay
------------ 0.08564066886901855 loss -------------------------------
------------ 0.27539825439453125 backwards -------------------------------
1 recon_decay
------------ 0.08559274673461914 loss -------------------------------
------------ 0.2754952907562256 backwards -------------------------------
1 recon_decay