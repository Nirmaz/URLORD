True cuda
nir
here2
here3
exp_dict {'exp_name': 'exp2d_dat1', 'data_l_name': 'D_0_2d_TL', 'data_u_name': 'D_0_2d_TU', 'data_v_name': 'D_0_2d_VA', 'data_t_name': 'D_0_2d_TE', 'path_d': '/mnt/local/nirm/TRUFI', 'path_d_dict': '/mnt/local/nirm/patch2D', 'base_dir': '/mnt/local/nirm/data_storage', 'path_dataset': '/mnt/local/nirm/D_0_2d', 'models_path': '/cs/labs/josko/nirm/embryo_project_version1/embyo_projects_codes/exp_config/exp_2d/data_D_0_2d/', 'models': ['URLord2D_dict.jason', 'ULord2D_dict.jason', 'UNet2D_dict.jason']}
here4
{'model_id': 'URLord', 'dim': 2, 'add_num_exp': True, 'load_model': False, 'train_model': True, 'evaluate_model': True, 'model_name': 'urlord2d_120', 'config_model': '/cs/labs/josko/nirm/embryo_project_version1/embyo_projects_codes/models_config/config_2d', 'config_unet': '/cs/labs/josko/nirm/embryo_project_version1/embyo_projects_codes/models_config/config_2d'} model dict
enterrrr
model_dict['model_name'] urlord2d_120_158
args: None URLord URLord_2 /cs/casmip/nirm/embryo_project_version1/EXP_FOLDER/exp_fp2/158/exp2d_dat1 True urlord2d_120_158 D_0_2d_TL D_0_2d_TU D_0_2d_VA D_0_2d_TE False True /cs/labs/josko/nirm/embryo_project_version1/embyo_projects_codes/models_config/config_2d /cs/labs/josko/nirm/embryo_project_version1/embyo_projects_codes/models_config/config_2d
dividing....
(6048, 128, 128, 1) imaggggggeeeeeeeeeeeeeeee shape
[0.] unique claseesssssssssssssssssssssssssssssssssssssssssssssssss
False False load_model
arrive train
2 30 config['n_classes'], config['class_dim']
/cs/casmip/nirm/embryo_project_version1/venu-pytorch/lib/python3.7/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)
  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
/cs/labs/josko/nirm/embryo_project_version1/embyo_projects_codes/lord-pytorch-unet/model/modules_unet.py:356: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  tensor = torch.tensor(x, requires_grad = False)
  0%|                                                                                                                                                                                                                                                                                         | 0/531 [00:00<?, ?it/s][W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)                                                                                                                                                                                              | 0/531 [00:00<?, ?it/s]
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)                                                                                                                                                                                              | 0/144 [00:00<?, ?it/s]
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)                                                                                                                                                                                              | 0/378 [00:00<?, ?it/s]
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
epoch #0:   1%|█▉                                                                                                                                                                                                                                                          | 4/531 [00:01<01:57,  4.49it/s, loss=4.39]
  1%|██                                                                                                                                                                                                                                                                               | 4/531 [00:01<01:57,  4.49it/s]
here seg decay
here recon_loss
10 recon_decay
------------ 0.10145401954650879 backwards -------------------------------
10 recon_decay
------------ 0.08344769477844238 backwards -------------------------------
10 recon_decay
------------ 0.08372735977172852 backwards -------------------------------
10 recon_decay
------------ 0.08396244049072266 backwards -------------------------------

  4%|█████████▋                                                                                                                                                                                                                                                                      | 19/531 [00:03<01:09,  7.41it/s]
------------ 0.08441925048828125 backwards -------------------------------
10 recon_decay
------------ 0.0850362777709961 backwards -------------------------------
10 recon_decay
------------ 0.0843043327331543 backwards -------------------------------
10 recon_decay
------------ 0.0909264087677002 backwards -------------------------------
10 recon_decay
------------ 0.08416891098022461 backwards -------------------------------
10 recon_decay
------------ 0.08586668968200684 backwards -------------------------------
10 recon_decay
------------ 0.08459711074829102 backwards -------------------------------
10 recon_decay
------------ 0.08443570137023926 backwards -------------------------------
10 recon_decay
------------ 0.0836634635925293 backwards -------------------------------
10 recon_decay
------------ 0.09020137786865234 backwards -------------------------------
10 recon_decay
------------ 0.08470463752746582 backwards -------------------------------
10 recon_decay
------------ 0.08415842056274414 backwards -------------------------------
10 recon_decay
------------ 0.08509993553161621 backwards -------------------------------
10 recon_decay
------------ 0.0844106674194336 backwards -------------------------------
10 recon_decay
------------ 0.08505678176879883 backwards -------------------------------

  6%|█████████████████▍                                                                                                                                                                                                                                                              | 34/531 [00:05<01:07,  7.41it/s]
------------ 0.08430099487304688 backwards -------------------------------
10 recon_decay
------------ 0.08511900901794434 backwards -------------------------------
10 recon_decay
------------ 0.08430838584899902 backwards -------------------------------
10 recon_decay
------------ 0.08919739723205566 backwards -------------------------------
10 recon_decay
------------ 0.08436179161071777 backwards -------------------------------
10 recon_decay
------------ 0.08398604393005371 backwards -------------------------------
10 recon_decay
------------ 0.08406472206115723 backwards -------------------------------
10 recon_decay
------------ 0.08428263664245605 backwards -------------------------------
10 recon_decay
------------ 0.08556723594665527 backwards -------------------------------
10 recon_decay
------------ 0.08416509628295898 backwards -------------------------------
10 recon_decay
------------ 0.08442497253417969 backwards -------------------------------
10 recon_decay
------------ 0.08462357521057129 backwards -------------------------------
10 recon_decay
------------ 0.08547568321228027 backwards -------------------------------
10 recon_decay
------------ 0.08440876007080078 backwards -------------------------------

  9%|█████████████████████████                                                                                                                                                                                                                                                       | 49/531 [00:07<01:05,  7.36it/s]
------------ 0.08607006072998047 backwards -------------------------------
10 recon_decay
------------ 0.08595967292785645 backwards -------------------------------
10 recon_decay
------------ 0.08608222007751465 backwards -------------------------------
10 recon_decay
------------ 0.08450126647949219 backwards -------------------------------
10 recon_decay
------------ 0.08497929573059082 backwards -------------------------------
10 recon_decay
------------ 0.08499383926391602 backwards -------------------------------
10 recon_decay
------------ 0.08480429649353027 backwards -------------------------------
10 recon_decay
------------ 0.08505082130432129 backwards -------------------------------
10 recon_decay
------------ 0.08500313758850098 backwards -------------------------------
10 recon_decay
------------ 0.08585238456726074 backwards -------------------------------
10 recon_decay
------------ 0.08498668670654297 backwards -------------------------------
10 recon_decay
------------ 0.08537650108337402 backwards -------------------------------
10 recon_decay
------------ 0.08488607406616211 backwards -------------------------------
10 recon_decay
------------ 0.08626890182495117 backwards -------------------------------
10 recon_decay
------------ 0.08481907844543457 backwards -------------------------------

 12%|████████████████████████████████▎                                                                                                                                                                                                                                               | 63/531 [00:09<01:04,  7.28it/s]
------------ 0.08572173118591309 backwards -------------------------------
10 recon_decay
------------ 0.08519506454467773 backwards -------------------------------
10 recon_decay
------------ 0.08469080924987793 backwards -------------------------------
10 recon_decay
------------ 0.08794927597045898 backwards -------------------------------
10 recon_decay
------------ 0.0855708122253418 backwards -------------------------------
10 recon_decay
------------ 0.0861518383026123 backwards -------------------------------
10 recon_decay
------------ 0.08505678176879883 backwards -------------------------------
10 recon_decay
------------ 0.08664417266845703 backwards -------------------------------
10 recon_decay
------------ 0.0847923755645752 backwards -------------------------------
10 recon_decay
------------ 0.08614635467529297 backwards -------------------------------
10 recon_decay
------------ 0.08530831336975098 backwards -------------------------------
10 recon_decay
------------ 0.08596515655517578 backwards -------------------------------
10 recon_decay
------------ 0.08542060852050781 backwards -------------------------------
10 recon_decay
------------ 0.08547163009643555 backwards -------------------------------
10 recon_decay
------------ 0.0854043960571289 backwards -------------------------------

 15%|███████████████████████████████████████▉                                                                                                                                                                                                                                        | 78/531 [00:11<01:01,  7.31it/s]
------------ 0.0849456787109375 backwards -------------------------------
10 recon_decay
------------ 0.08614897727966309 backwards -------------------------------
10 recon_decay
------------ 0.08529949188232422 backwards -------------------------------
10 recon_decay
------------ 0.08645749092102051 backwards -------------------------------
10 recon_decay
------------ 0.0852360725402832 backwards -------------------------------
10 recon_decay
------------ 0.08558535575866699 backwards -------------------------------
10 recon_decay
------------ 0.08493375778198242 backwards -------------------------------
10 recon_decay
------------ 0.08551287651062012 backwards -------------------------------
10 recon_decay
------------ 0.08610153198242188 backwards -------------------------------
10 recon_decay
------------ 0.08501839637756348 backwards -------------------------------
10 recon_decay
------------ 0.08600211143493652 backwards -------------------------------
10 recon_decay
------------ 0.08494997024536133 backwards -------------------------------
10 recon_decay
------------ 0.08594346046447754 backwards -------------------------------
10 recon_decay
------------ 0.08505558967590332 backwards -------------------------------

 18%|███████████████████████████████████████████████▋                                                                                                                                                                                                                                | 93/531 [00:13<00:59,  7.30it/s]
------------ 0.08630681037902832 backwards -------------------------------
10 recon_decay
------------ 0.08528852462768555 backwards -------------------------------
10 recon_decay
------------ 0.08518648147583008 backwards -------------------------------
10 recon_decay
------------ 0.08562397956848145 backwards -------------------------------
10 recon_decay
------------ 0.08490824699401855 backwards -------------------------------
10 recon_decay
------------ 0.086517333984375 backwards -------------------------------
10 recon_decay
------------ 0.08496522903442383 backwards -------------------------------
10 recon_decay
------------ 0.08563351631164551 backwards -------------------------------
10 recon_decay
------------ 0.08547115325927734 backwards -------------------------------
10 recon_decay
------------ 0.08668303489685059 backwards -------------------------------
10 recon_decay
------------ 0.08533596992492676 backwards -------------------------------
10 recon_decay
------------ 0.08523178100585938 backwards -------------------------------
10 recon_decay
------------ 0.08478283882141113 backwards -------------------------------
10 recon_decay
------------ 0.08498311042785645 backwards -------------------------------
10 recon_decay
------------ 0.08602237701416016 backwards -------------------------------

 20%|██████████████████████████████████████████████████████▌                                                                                                                                                                                                                        | 107/531 [00:15<00:58,  7.26it/s]
------------ 0.08482193946838379 backwards -------------------------------
10 recon_decay
------------ 0.0862886905670166 backwards -------------------------------
10 recon_decay
------------ 0.08486151695251465 backwards -------------------------------
10 recon_decay
------------ 0.08566498756408691 backwards -------------------------------
10 recon_decay
------------ 0.08558011054992676 backwards -------------------------------
10 recon_decay
------------ 0.08661413192749023 backwards -------------------------------
10 recon_decay
------------ 0.08506989479064941 backwards -------------------------------
10 recon_decay
------------ 0.08618021011352539 backwards -------------------------------
10 recon_decay
------------ 0.08527112007141113 backwards -------------------------------
10 recon_decay
------------ 0.0849294662475586 backwards -------------------------------
10 recon_decay
------------ 0.08649396896362305 backwards -------------------------------
10 recon_decay
------------ 0.08547616004943848 backwards -------------------------------
10 recon_decay
------------ 0.08592033386230469 backwards -------------------------------
10 recon_decay
------------ 0.08553266525268555 backwards -------------------------------

 23%|██████████████████████████████████████████████████████████████▎                                                                                                                                                                                                                | 122/531 [00:17<00:56,  7.21it/s]
------------ 0.08565783500671387 backwards -------------------------------
10 recon_decay
------------ 0.08930516242980957 backwards -------------------------------
10 recon_decay
------------ 0.08559036254882812 backwards -------------------------------
10 recon_decay
------------ 0.0852046012878418 backwards -------------------------------
10 recon_decay
------------ 0.08553147315979004 backwards -------------------------------
10 recon_decay
------------ 0.08696842193603516 backwards -------------------------------
10 recon_decay
------------ 0.08511018753051758 backwards -------------------------------
10 recon_decay
------------ 0.08588886260986328 backwards -------------------------------
10 recon_decay
------------ 0.08547806739807129 backwards -------------------------------
10 recon_decay
------------ 0.0866858959197998 backwards -------------------------------
10 recon_decay
------------ 0.08527684211730957 backwards -------------------------------
10 recon_decay
------------ 0.0853111743927002 backwards -------------------------------
10 recon_decay
------------ 0.08542323112487793 backwards -------------------------------
10 recon_decay
------------ 0.08520007133483887 backwards -------------------------------
10 recon_decay
------------ 0.08620786666870117 backwards -------------------------------

 26%|█████████████████████████████████████████████████████████████████████▉                                                                                                                                                                                                         | 137/531 [00:19<00:54,  7.23it/s]
------------ 0.08522772789001465 backwards -------------------------------
10 recon_decay
------------ 0.08637022972106934 backwards -------------------------------
10 recon_decay
------------ 0.0859687328338623 backwards -------------------------------
10 recon_decay
------------ 0.08691191673278809 backwards -------------------------------
10 recon_decay
------------ 0.08506917953491211 backwards -------------------------------
10 recon_decay
------------ 0.08507585525512695 backwards -------------------------------
10 recon_decay
------------ 0.08520960807800293 backwards -------------------------------
10 recon_decay
------------ 0.08623838424682617 backwards -------------------------------
10 recon_decay
------------ 0.0865931510925293 backwards -------------------------------
10 recon_decay
------------ 0.08575439453125 backwards -------------------------------
10 recon_decay
------------ 0.08554792404174805 backwards -------------------------------
10 recon_decay
------------ 0.08513808250427246 backwards -------------------------------
10 recon_decay
------------ 0.08655881881713867 backwards -------------------------------
10 recon_decay
------------ 0.08582067489624023 backwards -------------------------------

 28%|█████████████████████████████████████████████████████████████████████████████                                                                                                                                                                                                  | 151/531 [00:21<00:52,  7.18it/s]
------------ 0.08554601669311523 backwards -------------------------------
10 recon_decay
------------ 0.08571386337280273 backwards -------------------------------
10 recon_decay
------------ 0.08584284782409668 backwards -------------------------------
10 recon_decay
------------ 0.08618497848510742 backwards -------------------------------
10 recon_decay
------------ 0.08524894714355469 backwards -------------------------------
10 recon_decay
------------ 0.08696508407592773 backwards -------------------------------
10 recon_decay
------------ 0.08530235290527344 backwards -------------------------------
10 recon_decay
------------ 0.08606839179992676 backwards -------------------------------
10 recon_decay
------------ 0.08526754379272461 backwards -------------------------------
10 recon_decay
------------ 0.08566808700561523 backwards -------------------------------
10 recon_decay
------------ 0.0853888988494873 backwards -------------------------------
10 recon_decay
------------ 0.0853111743927002 backwards -------------------------------
10 recon_decay
------------ 0.09152674674987793 backwards -------------------------------
10 recon_decay
------------ 0.08617305755615234 backwards -------------------------------
10 recon_decay
------------ 0.08649563789367676 backwards -------------------------------

 31%|████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                                                                                          | 166/531 [00:23<00:50,  7.18it/s]
------------ 0.08532476425170898 backwards -------------------------------
10 recon_decay
------------ 0.08656430244445801 backwards -------------------------------
10 recon_decay
------------ 0.0858011245727539 backwards -------------------------------
10 recon_decay
------------ 0.08708834648132324 backwards -------------------------------
10 recon_decay
------------ 0.08588719367980957 backwards -------------------------------
10 recon_decay
------------ 0.08551573753356934 backwards -------------------------------
10 recon_decay
------------ 0.0870065689086914 backwards -------------------------------
10 recon_decay
------------ 0.08555984497070312 backwards -------------------------------
10 recon_decay
------------ 0.08679485321044922 backwards -------------------------------
10 recon_decay
------------ 0.0855860710144043 backwards -------------------------------
10 recon_decay
------------ 0.08606529235839844 backwards -------------------------------
10 recon_decay
------------ 0.08582401275634766 backwards -------------------------------
10 recon_decay
------------ 0.08645391464233398 backwards -------------------------------
10 recon_decay
------------ 0.08640432357788086 backwards -------------------------------

 34%|███████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                                                                                                   | 180/531 [00:25<00:49,  7.06it/s]
------------ 0.08534574508666992 backwards -------------------------------
10 recon_decay
------------ 0.08684754371643066 backwards -------------------------------
10 recon_decay
------------ 0.0860605239868164 backwards -------------------------------
10 recon_decay
------------ 0.08662939071655273 backwards -------------------------------
10 recon_decay
------------ 0.08545827865600586 backwards -------------------------------
10 recon_decay
------------ 0.08588624000549316 backwards -------------------------------
10 recon_decay
------------ 0.0861215591430664 backwards -------------------------------
10 recon_decay
------------ 0.08573603630065918 backwards -------------------------------
10 recon_decay
------------ 0.08634138107299805 backwards -------------------------------
10 recon_decay
------------ 0.08507108688354492 backwards -------------------------------
10 recon_decay
------------ 0.08579802513122559 backwards -------------------------------
10 recon_decay
------------ 0.0854196548461914 backwards -------------------------------
10 recon_decay
------------ 0.08716416358947754 backwards -------------------------------
10 recon_decay
------------ 0.08528661727905273 backwards -------------------------------

 37%|███████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                                                                           | 195/531 [00:27<00:46,  7.20it/s]
------------ 0.08585524559020996 backwards -------------------------------
10 recon_decay
------------ 0.08609580993652344 backwards -------------------------------
10 recon_decay
------------ 0.08569931983947754 backwards -------------------------------
10 recon_decay
------------ 0.08624053001403809 backwards -------------------------------
10 recon_decay
------------ 0.08550381660461426 backwards -------------------------------
10 recon_decay
------------ 0.08611154556274414 backwards -------------------------------
10 recon_decay
------------ 0.08544301986694336 backwards -------------------------------
10 recon_decay
------------ 0.08563709259033203 backwards -------------------------------
10 recon_decay
------------ 0.08585500717163086 backwards -------------------------------
10 recon_decay
------------ 0.08503556251525879 backwards -------------------------------
10 recon_decay
------------ 0.08501601219177246 backwards -------------------------------
10 recon_decay
------------ 0.08574557304382324 backwards -------------------------------
10 recon_decay
------------ 0.08620166778564453 backwards -------------------------------
10 recon_decay
------------ 0.08510732650756836 backwards -------------------------------
10 recon_decay
------------ 0.08634686470031738 backwards -------------------------------

 39%|██████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                                                                    | 209/531 [00:29<00:45,  7.12it/s]
------------ 0.08500099182128906 backwards -------------------------------
10 recon_decay
------------ 0.08658385276794434 backwards -------------------------------
10 recon_decay
------------ 0.08510136604309082 backwards -------------------------------
10 recon_decay
------------ 0.08575034141540527 backwards -------------------------------
10 recon_decay
------------ 0.08605432510375977 backwards -------------------------------
10 recon_decay
------------ 0.08465385437011719 backwards -------------------------------
10 recon_decay
------------ 0.08622050285339355 backwards -------------------------------
10 recon_decay
------------ 0.08576774597167969 backwards -------------------------------
10 recon_decay
------------ 0.08661746978759766 backwards -------------------------------
10 recon_decay
------------ 0.08541107177734375 backwards -------------------------------
10 recon_decay
------------ 0.08591127395629883 backwards -------------------------------
10 recon_decay
------------ 0.08559274673461914 backwards -------------------------------
10 recon_decay
------------ 0.08520913124084473 backwards -------------------------------
10 recon_decay
------------ 0.08613133430480957 backwards -------------------------------

 42%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                                                            | 224/531 [00:31<00:43,  7.12it/s]
------------ 0.08522748947143555 backwards -------------------------------
10 recon_decay
------------ 0.0873408317565918 backwards -------------------------------
10 recon_decay
------------ 0.08519792556762695 backwards -------------------------------
10 recon_decay
------------ 0.0861814022064209 backwards -------------------------------
10 recon_decay
------------ 0.08518266677856445 backwards -------------------------------
10 recon_decay
------------ 0.0856618881225586 backwards -------------------------------
10 recon_decay
------------ 0.08513259887695312 backwards -------------------------------
10 recon_decay
------------ 0.0854346752166748 backwards -------------------------------
10 recon_decay
------------ 0.08690047264099121 backwards -------------------------------
10 recon_decay
------------ 0.08525991439819336 backwards -------------------------------
10 recon_decay
------------ 0.08669257164001465 backwards -------------------------------
10 recon_decay
------------ 0.0859231948852539 backwards -------------------------------
10 recon_decay
------------ 0.08739614486694336 backwards -------------------------------
10 recon_decay
------------ 0.0856320858001709 backwards -------------------------------

 45%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                                                                     | 238/531 [00:33<00:41,  7.11it/s]
------------ 0.08624935150146484 backwards -------------------------------
10 recon_decay
------------ 0.08540892601013184 backwards -------------------------------
10 recon_decay
------------ 0.0865030288696289 backwards -------------------------------
10 recon_decay
------------ 0.0873103141784668 backwards -------------------------------
10 recon_decay
------------ 0.08636927604675293 backwards -------------------------------
10 recon_decay
------------ 0.08687400817871094 backwards -------------------------------
10 recon_decay
------------ 0.0862276554107666 backwards -------------------------------
10 recon_decay
------------ 0.08631348609924316 backwards -------------------------------
10 recon_decay
------------ 0.08623218536376953 backwards -------------------------------
10 recon_decay
------------ 0.08604907989501953 backwards -------------------------------
10 recon_decay
------------ 0.08585262298583984 backwards -------------------------------
10 recon_decay
------------ 0.08567094802856445 backwards -------------------------------
10 recon_decay
------------ 0.0872342586517334 backwards -------------------------------
10 recon_decay
------------ 0.08571004867553711 backwards -------------------------------

 47%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                                              | 252/531 [00:35<00:39,  7.11it/s]
------------ 0.08713650703430176 backwards -------------------------------
10 recon_decay
------------ 0.08571267127990723 backwards -------------------------------
10 recon_decay
------------ 0.08637094497680664 backwards -------------------------------
10 recon_decay
------------ 0.08562588691711426 backwards -------------------------------
10 recon_decay
------------ 0.08710741996765137 backwards -------------------------------
10 recon_decay
------------ 0.08694267272949219 backwards -------------------------------
10 recon_decay
------------ 0.08644437789916992 backwards -------------------------------
10 recon_decay
------------ 0.0864415168762207 backwards -------------------------------
10 recon_decay
------------ 0.08589673042297363 backwards -------------------------------
10 recon_decay
------------ 0.08589529991149902 backwards -------------------------------
10 recon_decay
------------ 0.08619523048400879 backwards -------------------------------
10 recon_decay
------------ 0.0864112377166748 backwards -------------------------------
10 recon_decay
------------ 0.08695602416992188 backwards -------------------------------
10 recon_decay
------------ 0.08575248718261719 backwards -------------------------------
10 recon_decay
------------ 0.08598804473876953 backwards -------------------------------

 50%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                                      | 267/531 [00:37<00:37,  7.11it/s]
------------ 0.08563780784606934 backwards -------------------------------
10 recon_decay
------------ 0.08720612525939941 backwards -------------------------------
10 recon_decay
------------ 0.08573246002197266 backwards -------------------------------
10 recon_decay
------------ 0.08605098724365234 backwards -------------------------------
10 recon_decay
------------ 0.08639693260192871 backwards -------------------------------
10 recon_decay
------------ 0.08604717254638672 backwards -------------------------------
10 recon_decay
------------ 0.08687663078308105 backwards -------------------------------
10 recon_decay
------------ 0.08577942848205566 backwards -------------------------------
10 recon_decay
------------ 0.08710765838623047 backwards -------------------------------
10 recon_decay
------------ 0.08586883544921875 backwards -------------------------------
10 recon_decay
------------ 0.08661317825317383 backwards -------------------------------
10 recon_decay
------------ 0.08571457862854004 backwards -------------------------------
10 recon_decay
------------ 0.08661603927612305 backwards -------------------------------
10 recon_decay
------------ 0.08613109588623047 backwards -------------------------------

 53%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                                               | 281/531 [00:39<00:35,  7.04it/s]
------------ 0.08616495132446289 backwards -------------------------------
10 recon_decay
------------ 0.08668756484985352 backwards -------------------------------
10 recon_decay
------------ 0.08611774444580078 backwards -------------------------------
10 recon_decay
------------ 0.08717846870422363 backwards -------------------------------
10 recon_decay
------------ 0.08599328994750977 backwards -------------------------------
10 recon_decay
------------ 0.0865335464477539 backwards -------------------------------
10 recon_decay
------------ 0.08684754371643066 backwards -------------------------------
10 recon_decay
------------ 0.08771562576293945 backwards -------------------------------
10 recon_decay
------------ 0.08725094795227051 backwards -------------------------------
10 recon_decay
------------ 0.08578824996948242 backwards -------------------------------
10 recon_decay
------------ 0.08628058433532715 backwards -------------------------------
10 recon_decay
------------ 0.08595442771911621 backwards -------------------------------
10 recon_decay
------------ 0.08644247055053711 backwards -------------------------------
10 recon_decay
------------ 0.08650803565979004 backwards -------------------------------

 55%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                                                          | 292/531 [00:41<00:33,  7.07it/s]
------------ 0.0854642391204834 backwards -------------------------------
10 recon_decay
------------ 0.08731651306152344 backwards -------------------------------
10 recon_decay
------------ 0.08562183380126953 backwards -------------------------------
10 recon_decay
------------ 0.08667969703674316 backwards -------------------------------
10 recon_decay
------------ 0.08580374717712402 backwards -------------------------------
10 recon_decay
------------ 0.08665704727172852 backwards -------------------------------
10 recon_decay
------------ 0.08658361434936523 backwards -------------------------------
10 recon_decay
------------ 0.0862879753112793 backwards -------------------------------
10 recon_decay
------------ 0.08730697631835938 backwards -------------------------------
10 recon_decay
------------ 0.08615756034851074 backwards -------------------------------
10 recon_decay
------------ 0.0862882137298584 backwards -------------------------------
10 recon_decay
------------ 0.08616447448730469 backwards -------------------------------
10 recon_decay
------------ 0.08623790740966797 backwards -------------------------------
10 recon_decay
------------ 0.08665919303894043 backwards -------------------------------

 58%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                                                  | 306/531 [00:43<00:32,  6.94it/s]
------------ 0.08564329147338867 backwards -------------------------------
10 recon_decay
------------ 0.08733057975769043 backwards -------------------------------
10 recon_decay
------------ 0.08567690849304199 backwards -------------------------------
10 recon_decay
------------ 0.08658933639526367 backwards -------------------------------
10 recon_decay
------------ 0.08614087104797363 backwards -------------------------------
10 recon_decay
------------ 0.08609271049499512 backwards -------------------------------
10 recon_decay
------------ 0.08633947372436523 backwards -------------------------------
10 recon_decay
------------ 0.08570098876953125 backwards -------------------------------
10 recon_decay
------------ 0.08713078498840332 backwards -------------------------------
10 recon_decay
------------ 0.08576226234436035 backwards -------------------------------
10 recon_decay
------------ 0.08607196807861328 backwards -------------------------------
10 recon_decay
------------ 0.0856473445892334 backwards -------------------------------
10 recon_decay
------------ 0.08739876747131348 backwards -------------------------------
10 recon_decay
------------ 0.08628702163696289 backwards -------------------------------

 60%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                           | 320/531 [00:45<00:29,  7.04it/s]
------------ 0.08530831336975098 backwards -------------------------------
10 recon_decay
------------ 0.08716583251953125 backwards -------------------------------
10 recon_decay
------------ 0.08569788932800293 backwards -------------------------------
10 recon_decay
------------ 0.08692216873168945 backwards -------------------------------
10 recon_decay
------------ 0.08566713333129883 backwards -------------------------------
10 recon_decay
------------ 0.08659124374389648 backwards -------------------------------
10 recon_decay
------------ 0.08535623550415039 backwards -------------------------------
10 recon_decay
------------ 0.0854654312133789 backwards -------------------------------
10 recon_decay
------------ 0.08726644515991211 backwards -------------------------------
10 recon_decay
------------ 0.08565664291381836 backwards -------------------------------
10 recon_decay
------------ 0.0862724781036377 backwards -------------------------------
10 recon_decay
------------ 0.08579230308532715 backwards -------------------------------
10 recon_decay
------------ 0.08723163604736328 backwards -------------------------------
10 recon_decay
------------ 0.08572864532470703 backwards -------------------------------

 63%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                    | 334/531 [00:47<00:28,  7.01it/s]
------------ 0.08585882186889648 backwards -------------------------------
10 recon_decay
------------ 0.08717560768127441 backwards -------------------------------
10 recon_decay
------------ 0.08588409423828125 backwards -------------------------------
10 recon_decay
------------ 0.08693194389343262 backwards -------------------------------
10 recon_decay
------------ 0.08577084541320801 backwards -------------------------------
10 recon_decay
------------ 0.08588075637817383 backwards -------------------------------
10 recon_decay
------------ 0.08599710464477539 backwards -------------------------------
10 recon_decay
------------ 0.08514809608459473 backwards -------------------------------
10 recon_decay
------------ 0.08658099174499512 backwards -------------------------------
10 recon_decay
------------ 0.08712887763977051 backwards -------------------------------
10 recon_decay
------------ 0.08648896217346191 backwards -------------------------------
10 recon_decay
------------ 0.08540964126586914 backwards -------------------------------
10 recon_decay
------------ 0.0862431526184082 backwards -------------------------------
10 recon_decay
------------ 0.0863037109375 backwards -------------------------------

 66%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                             | 348/531 [00:49<00:26,  7.02it/s]
------------ 0.08596372604370117 backwards -------------------------------
10 recon_decay
------------ 0.08693504333496094 backwards -------------------------------
10 recon_decay
------------ 0.08585119247436523 backwards -------------------------------
10 recon_decay
------------ 0.08601188659667969 backwards -------------------------------
10 recon_decay
------------ 0.08575844764709473 backwards -------------------------------
10 recon_decay
------------ 0.08656525611877441 backwards -------------------------------
10 recon_decay
------------ 0.08583641052246094 backwards -------------------------------
10 recon_decay
------------ 0.08549642562866211 backwards -------------------------------
10 recon_decay
------------ 0.08644580841064453 backwards -------------------------------
10 recon_decay
------------ 0.08587288856506348 backwards -------------------------------
10 recon_decay
------------ 0.08585786819458008 backwards -------------------------------
10 recon_decay
------------ 0.08567333221435547 backwards -------------------------------
10 recon_decay
------------ 0.08642721176147461 backwards -------------------------------
10 recon_decay
------------ 0.08601737022399902 backwards -------------------------------

 68%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                      | 362/531 [00:51<00:24,  6.99it/s]
------------ 0.08575129508972168 backwards -------------------------------
10 recon_decay
------------ 0.0867316722869873 backwards -------------------------------
10 recon_decay
------------ 0.0857839584350586 backwards -------------------------------
10 recon_decay
------------ 0.08608222007751465 backwards -------------------------------
10 recon_decay
------------ 0.0852205753326416 backwards -------------------------------
10 recon_decay
------------ 0.08654499053955078 backwards -------------------------------
10 recon_decay
------------ 0.08593440055847168 backwards -------------------------------
10 recon_decay
------------ 0.08558034896850586 backwards -------------------------------
10 recon_decay
------------ 0.08678531646728516 backwards -------------------------------
10 recon_decay
------------ 0.0856480598449707 backwards -------------------------------
10 recon_decay
------------ 0.0859675407409668 backwards -------------------------------
10 recon_decay
------------ 0.0855417251586914 backwards -------------------------------
10 recon_decay
------------ 0.08638453483581543 backwards -------------------------------
10 recon_decay
------------ 0.08542990684509277 backwards -------------------------------

 71%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                              | 377/531 [00:53<00:21,  7.01it/s]
------------ 0.08600974082946777 backwards -------------------------------
10 recon_decay
------------ 0.08722877502441406 backwards -------------------------------
10 recon_decay
------------ 0.08604145050048828 backwards -------------------------------
10 recon_decay
------------ 0.08631706237792969 backwards -------------------------------
10 recon_decay
------------ 0.08587026596069336 backwards -------------------------------
10 recon_decay
------------ 0.08570599555969238 backwards -------------------------------
10 recon_decay
------------ 0.08553147315979004 backwards -------------------------------
10 recon_decay
------------ 0.09143280982971191 backwards -------------------------------
10 recon_decay
------------ 0.08786606788635254 backwards -------------------------------
10 recon_decay
------------ 0.08555769920349121 backwards -------------------------------
10 recon_decay
------------ 0.08639717102050781 backwards -------------------------------
10 recon_decay
------------ 0.0856313705444336 backwards -------------------------------
10 recon_decay
------------ 0.08608269691467285 backwards -------------------------------
10 recon_decay
------------ 0.08568072319030762 backwards -------------------------------

 73%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                        | 390/531 [00:55<00:22,  6.14it/s]
------------ 0.08600473403930664 backwards -------------------------------
10 recon_decay
------------ 0.08812403678894043 backwards -------------------------------
10 recon_decay
------------ 0.08666586875915527 backwards -------------------------------
10 recon_decay
------------ 0.0878443717956543 backwards -------------------------------
10 recon_decay
------------ 0.08663177490234375 backwards -------------------------------
10 recon_decay
------------ 0.08605480194091797 backwards -------------------------------
10 recon_decay
------------ 0.08618807792663574 backwards -------------------------------
10 recon_decay
------------ 0.08750033378601074 backwards -------------------------------
10 recon_decay
------------ 0.08549785614013672 backwards -------------------------------
10 recon_decay
------------ 0.08756399154663086 backwards -------------------------------
10 recon_decay
------------ 0.08658194541931152 backwards -------------------------------
10 recon_decay
------------ 0.1676340103149414 backwards -------------------------------
10 recon_decay
------------ 0.08770370483398438 backwards -------------------------------
10 recon_decay

 76%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                 | 403/531 [00:57<00:19,  6.48it/s]
10 recon_decay
------------ 0.09273290634155273 backwards -------------------------------
10 recon_decay
------------ 0.08934974670410156 backwards -------------------------------
10 recon_decay
------------ 0.08823609352111816 backwards -------------------------------
10 recon_decay
------------ 0.09028768539428711 backwards -------------------------------
10 recon_decay
------------ 0.09147810935974121 backwards -------------------------------
10 recon_decay
------------ 0.08900904655456543 backwards -------------------------------
10 recon_decay
------------ 0.08648920059204102 backwards -------------------------------
10 recon_decay
------------ 0.15631341934204102 backwards -------------------------------
10 recon_decay
------------ 0.08753299713134766 backwards -------------------------------
10 recon_decay
------------ 0.09070491790771484 backwards -------------------------------
10 recon_decay
------------ 0.08973550796508789 backwards -------------------------------
10 recon_decay
------------ 0.09222269058227539 backwards -------------------------------

 78%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                          | 416/531 [00:59<00:16,  6.77it/s]
------------ 0.08894062042236328 backwards -------------------------------
10 recon_decay
------------ 0.09148335456848145 backwards -------------------------------
10 recon_decay
------------ 0.08810162544250488 backwards -------------------------------
10 recon_decay
------------ 0.08906030654907227 backwards -------------------------------
10 recon_decay
------------ 0.08759260177612305 backwards -------------------------------
10 recon_decay
------------ 0.08661198616027832 backwards -------------------------------
10 recon_decay
------------ 0.09651732444763184 backwards -------------------------------
10 recon_decay
------------ 0.09012293815612793 backwards -------------------------------
10 recon_decay
------------ 0.0885772705078125 backwards -------------------------------
10 recon_decay
------------ 0.08869218826293945 backwards -------------------------------
10 recon_decay
------------ 0.08731889724731445 backwards -------------------------------
10 recon_decay
------------ 0.08645510673522949 backwards -------------------------------
10 recon_decay
------------ 0.08623051643371582 backwards -------------------------------
10 recon_decay
------------ 0.0880119800567627 backwards -------------------------------

 81%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                   | 430/531 [01:01<00:14,  6.87it/s]
------------ 0.0867609977722168 backwards -------------------------------
10 recon_decay
------------ 0.0893406867980957 backwards -------------------------------
10 recon_decay
------------ 0.08727192878723145 backwards -------------------------------
10 recon_decay
------------ 0.08599162101745605 backwards -------------------------------
10 recon_decay
------------ 0.08729243278503418 backwards -------------------------------
10 recon_decay
------------ 0.09127974510192871 backwards -------------------------------
10 recon_decay
------------ 0.09609627723693848 backwards -------------------------------
10 recon_decay
------------ 0.08754110336303711 backwards -------------------------------
10 recon_decay
------------ 0.08714103698730469 backwards -------------------------------
10 recon_decay
------------ 0.08710265159606934 backwards -------------------------------
10 recon_decay
------------ 0.09164810180664062 backwards -------------------------------
10 recon_decay
------------ 0.08858513832092285 backwards -------------------------------
10 recon_decay
------------ 0.08813834190368652 backwards -------------------------------

 84%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                            | 444/531 [01:03<00:12,  6.86it/s]
------------ 0.0869286060333252 backwards -------------------------------
10 recon_decay
------------ 0.09057259559631348 backwards -------------------------------
10 recon_decay
------------ 0.0892324447631836 backwards -------------------------------
10 recon_decay
------------ 0.08818221092224121 backwards -------------------------------
10 recon_decay
------------ 0.09064149856567383 backwards -------------------------------
10 recon_decay
------------ 0.08679533004760742 backwards -------------------------------
10 recon_decay
------------ 0.0879356861114502 backwards -------------------------------
10 recon_decay
------------ 0.08713889122009277 backwards -------------------------------
10 recon_decay
------------ 0.0863637924194336 backwards -------------------------------
10 recon_decay
------------ 0.08797955513000488 backwards -------------------------------
10 recon_decay
------------ 0.08700203895568848 backwards -------------------------------
10 recon_decay
------------ 0.0877225399017334 backwards -------------------------------
10 recon_decay
------------ 0.08636736869812012 backwards -------------------------------
10 recon_decay
------------ 0.08817267417907715 backwards -------------------------------

 86%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                     | 457/531 [01:05<00:10,  6.75it/s]
------------ 0.0879368782043457 backwards -------------------------------
10 recon_decay
------------ 0.0865788459777832 backwards -------------------------------
10 recon_decay
------------ 0.08948945999145508 backwards -------------------------------
10 recon_decay
------------ 0.08677959442138672 backwards -------------------------------
10 recon_decay
------------ 0.08705568313598633 backwards -------------------------------
10 recon_decay
------------ 0.08740878105163574 backwards -------------------------------
10 recon_decay
------------ 0.0871729850769043 backwards -------------------------------
10 recon_decay
------------ 0.0865030288696289 backwards -------------------------------
10 recon_decay
------------ 0.08667373657226562 backwards -------------------------------
10 recon_decay
------------ 0.08820557594299316 backwards -------------------------------
10 recon_decay
------------ 0.08755373954772949 backwards -------------------------------
10 recon_decay
------------ 0.0863499641418457 backwards -------------------------------
10 recon_decay
------------ 0.08695793151855469 backwards -------------------------------

 89%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                              | 471/531 [01:07<00:09,  6.29it/s]
------------ 0.08790874481201172 backwards -------------------------------
10 recon_decay
------------ 0.08678460121154785 backwards -------------------------------
10 recon_decay
------------ 0.08648467063903809 backwards -------------------------------
10 recon_decay
------------ 0.08901739120483398 backwards -------------------------------
10 recon_decay
------------ 0.08852291107177734 backwards -------------------------------
10 recon_decay
------------ 0.0886387825012207 backwards -------------------------------
10 recon_decay
------------ 0.08886027336120605 backwards -------------------------------
10 recon_decay
------------ 0.08780121803283691 backwards -------------------------------
10 recon_decay
------------ 0.08803844451904297 backwards -------------------------------
10 recon_decay
------------ 0.08683061599731445 backwards -------------------------------
10 recon_decay
------------ 0.08759117126464844 backwards -------------------------------
10 recon_decay
------------ 0.08836984634399414 backwards -------------------------------
10 recon_decay
------------ 0.08761978149414062 backwards -------------------------------
10 recon_decay
------------ 0.08926510810852051 backwards -------------------------------

 91%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                        | 484/531 [01:09<00:07,  6.45it/s]
------------ 0.10597944259643555 backwards -------------------------------
10 recon_decay
------------ 0.08688640594482422 backwards -------------------------------
10 recon_decay
------------ 0.08786702156066895 backwards -------------------------------
10 recon_decay
------------ 0.08737707138061523 backwards -------------------------------
10 recon_decay
------------ 0.0869913101196289 backwards -------------------------------
10 recon_decay
------------ 0.0865926742553711 backwards -------------------------------
10 recon_decay
------------ 0.08757162094116211 backwards -------------------------------
10 recon_decay
------------ 0.08648204803466797 backwards -------------------------------
10 recon_decay
------------ 0.08724021911621094 backwards -------------------------------
10 recon_decay
------------ 0.09049725532531738 backwards -------------------------------
10 recon_decay
------------ 0.08748364448547363 backwards -------------------------------
10 recon_decay
------------ 0.08707833290100098 backwards -------------------------------
10 recon_decay
------------ 0.08832669258117676 backwards -------------------------------

 94%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                | 498/531 [01:11<00:05,  6.56it/s]
------------ 0.08853387832641602 backwards -------------------------------
10 recon_decay
------------ 0.08656096458435059 backwards -------------------------------
10 recon_decay
------------ 0.08722639083862305 backwards -------------------------------
10 recon_decay
------------ 0.08666181564331055 backwards -------------------------------
10 recon_decay
------------ 0.08717727661132812 backwards -------------------------------
10 recon_decay
------------ 0.08653044700622559 backwards -------------------------------
10 recon_decay
------------ 0.08790802955627441 backwards -------------------------------
10 recon_decay
------------ 0.0874624252319336 backwards -------------------------------
10 recon_decay
------------ 0.0873568058013916 backwards -------------------------------
10 recon_decay
------------ 0.09796619415283203 backwards -------------------------------
10 recon_decay
------------ 0.08718609809875488 backwards -------------------------------
10 recon_decay
------------ 0.08803272247314453 backwards -------------------------------
10 recon_decay
------------ 0.08834218978881836 backwards -------------------------------

 96%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊          | 511/531 [01:13<00:02,  6.67it/s]
------------ 0.094512939453125 backwards -------------------------------
10 recon_decay
------------ 0.09115052223205566 backwards -------------------------------
10 recon_decay
------------ 0.0882101058959961 backwards -------------------------------
10 recon_decay
------------ 0.087738037109375 backwards -------------------------------
10 recon_decay
------------ 0.0873100757598877 backwards -------------------------------
10 recon_decay
------------ 0.08832931518554688 backwards -------------------------------
10 recon_decay
------------ 0.08823966979980469 backwards -------------------------------
10 recon_decay
------------ 0.08762383460998535 backwards -------------------------------
10 recon_decay
------------ 0.09744763374328613 backwards -------------------------------
10 recon_decay
------------ 0.08986711502075195 backwards -------------------------------
10 recon_decay
------------ 0.08808541297912598 backwards -------------------------------
10 recon_decay
------------ 0.08849430084228516 backwards -------------------------------
10 recon_decay
------------ 0.08690476417541504 backwards -------------------------------
10 recon_decay
------------ 0.08678412437438965 backwards -------------------------------

 99%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉   | 525/531 [01:15<00:00,  6.82it/s]
------------ 0.08748245239257812 backwards -------------------------------
10 recon_decay
------------ 0.08830833435058594 backwards -------------------------------
10 recon_decay
------------ 0.08734989166259766 backwards -------------------------------
10 recon_decay
------------ 0.0857856273651123 backwards -------------------------------
10 recon_decay
------------ 0.08734917640686035 backwards -------------------------------
10 recon_decay
------------ 0.08708357810974121 backwards -------------------------------
10 recon_decay
------------ 0.08646440505981445 backwards -------------------------------
10 recon_decay
------------ 0.08626151084899902 backwards -------------------------------
10 recon_decay
------------ 0.08628511428833008 backwards -------------------------------
10 recon_decay
------------ 0.09832310676574707 backwards -------------------------------
10 recon_decay
------------ 0.08738327026367188 backwards -------------------------------
10 recon_decay
------------ 0.08645939826965332 backwards -------------------------------
10 recon_decay
------------ 0.08660888671875 backwards -------------------------------
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍| 530/531 [01:16<00:00,  6.92it/s]
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
 13%|███████████████████████████████████▉                                                                                                                                                                                                                                            | 19/144 [01:17<02:11,  1.05s/it]
------------ 0.08754801750183105 backwards -------------------------------
10 recon_decay
------------ 0.0864558219909668 backwards -------------------------------
10 recon_decay
------------ 0.08659482002258301 backwards -------------------------------
10 recon_decay
------------ 0.08658170700073242 backwards -------------------------------
10 recon_decay
------------ 0.08750677108764648 backwards -------------------------------
10 recon_decay
------------ 0.08615350723266602 backwards -------------------------------
10 recon_decay
------------ 0.08631587028503418 backwards -------------------------------
10 recon_decay


[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏   | 142/144 [01:22<00:00, 23.64it/s]
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)








 99%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌ | 376/378 [01:39<00:00, 23.80it/s]
saving model......................................................
done
------------ 99.40486168861389 seg time alll epoch -------------------------------
saving model......................................................
/cs/labs/josko/nirm/embryo_project_version1/embyo_projects_codes/lord-pytorch-unet/model/training_unet.py:879: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  plt.figure()
saving model......................................................
here6
2 30 config['n_classes'], config['class_dim']
dict_keys(['ABR', 'AH', 'AP', 'DA', 'FC', 'GG', 'GKY', 'GN', 'HM', 'HOY', 'ILZ', 'KZ', 'Pat1029_Se17_Res0.7421875_0.7421875_Spac3.5', 'Pat1133_Se24_Res1.25_1.25_Spac3.5', 'Pat1274_Se16_Res1.34375_1.34375_Spac3.5', 'Pat1374_Se26_Res0.78125_0.78125_Spac4.0', 'Pat1563_Se13_Res1.25_1.25_Spac3.5', 'Pat1837_Se18_Res0.9375_0.9375_Spac3.5', 'Pat2175_Se23_Res0.5859375_0.5859375_Spac3.0', 'Pat2227_Se19_Res0.7421875_0.7421875_Spac3.5', 'Pat2426_Se22_Res1.25_1.25_Spac3.5', 'Pat2771_Se28_Res1.25_1.25_Spac3.5', 'Pat2957_Se25_Res0.78125_0.78125_Spac4.0', 'Pat3011_Se24_Res0.7421875_0.7421875_Spac3.5', 'Pat3201_Se22_Res0.78125_0.78125_Spac4.0', 'Pat3547_Se18_Res0.7421875_0.7421875_Spac3.5', 'Pat438_Se19_Res0.78125_0.78125_Spac4.0', 'Pat663_Se20_Res1.25_1.25_Spac3.5', 'Pat876_Se17_Res1.25_1.25_Spac3.5', 'Pat911_Se31_Res0.78125_0.78125_Spac4.0', 'Pat928_Se21_Res1.25_1.25_Spac3.5', 'Pat978_Se16_Res1.25_1.25_Spac3.5', 'RA', 'RR', 'SS', 'ZM'])
here loop: AH
AH subject id
133 dif cols diff_row 90
x:83:173 y:89:222 z:14:100
in BB :) :)
hereeeeee
[128, 128, 16] [64, 64, 16]
dim2
(63, 128, 128, 16) patch shape
torch.Size([1008, 1, 128, 128]) patches torch
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([1008, 1, 128, 128]) prediction size
(1008, 128, 128, 1) prediction shape  63 16
[0.02729042 0.02768339 0.02945316 ... 0.9965773  0.9965848  0.9968215 ] prediction unique check if we are really rounding the score
(63, 128, 128, 16) prediction shape
here loop: AP
AP subject id
140 dif cols diff_row 111
x:35:146 y:48:188 z:18:45
in BB :) :)
hereeeeee
[128, 128, 16] [64, 64, 16]
dim2
(63, 128, 128, 16) patch shape
torch.Size([1008, 1, 128, 128]) patches torch
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([1008, 1, 128, 128]) prediction size
(1008, 128, 128, 1) prediction shape  63 16
[0.0236026  0.02731435 0.02935708 ... 0.9965773  0.9965848  0.9968215 ] prediction unique check if we are really rounding the score
(63, 128, 128, 16) prediction shape
here loop: DA
DA subject id
165 dif cols diff_row 137
x:82:219 y:34:199 z:61:95
in BB :) :)
hereeeeee
[128, 128, 16] [64, 64, 16]
dim2
(63, 128, 128, 16) patch shape
torch.Size([1008, 1, 128, 128]) patches torch
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([1008, 1, 128, 128]) prediction size
(1008, 128, 128, 1) prediction shape  63 16
[0.02649505 0.02815148 0.02945964 ... 0.9965773  0.9965848  0.9968215 ] prediction unique check if we are really rounding the score
(63, 128, 128, 16) prediction shape
here loop: FC
FC subject id
125 dif cols diff_row 83
x:93:176 y:81:206 z:46:115
in BB :) :)
hereeeeee
[128, 128, 16] [64, 64, 16]
dim2
(63, 128, 128, 16) patch shape
torch.Size([1008, 1, 128, 128]) patches torch
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([1008, 1, 128, 128]) prediction size
(1008, 128, 128, 1) prediction shape  63 16
[0.02791623 0.02966339 0.03072299 ... 0.9965773  0.9965848  0.9968215 ] prediction unique check if we are really rounding the score
(63, 128, 128, 16) prediction shape
here loop: GKY
GKY subject id
137 dif cols diff_row 137
x:71:208 y:62:199 z:46:78
in BB :) :)
hereeeeee
[128, 128, 16] [64, 64, 16]
dim2
(63, 128, 128, 16) patch shape
torch.Size([1008, 1, 128, 128]) patches torch
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([1008, 1, 128, 128]) prediction size
(1008, 128, 128, 1) prediction shape  63 16
[0.0263089  0.02675764 0.02686358 ... 0.9965773  0.9965848  0.9968215 ] prediction unique check if we are really rounding the score
(63, 128, 128, 16) prediction shape
here loop: GN
GN subject id
117 dif cols diff_row 148
x:44:192 y:106:223 z:49:102
in BB :) :)
hereeeeee
[128, 128, 16] [64, 64, 16]
dim2
(63, 128, 128, 16) patch shape
torch.Size([1008, 1, 128, 128]) patches torch
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([1008, 1, 128, 128]) prediction size
(1008, 128, 128, 1) prediction shape  63 16
[0.02510469 0.02660671 0.02685848 ... 0.9965773  0.9965848  0.9968215 ] prediction unique check if we are really rounding the score
(63, 128, 128, 16) prediction shape
here loop: HM
HM subject id
45 dif cols diff_row 82
x:107:189 y:187:232 z:60:90
in BB :) :)
hereeeeee
[128, 128, 16] [64, 64, 16]
dim2
(63, 128, 128, 16) patch shape
torch.Size([1008, 1, 128, 128]) patches torch
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([1008, 1, 128, 128]) prediction size
(1008, 128, 128, 1) prediction shape  63 16
[0.02891323 0.02929471 0.02960347 ... 0.9965773  0.9965848  0.9968215 ] prediction unique check if we are really rounding the score
(63, 128, 128, 16) prediction shape
here loop: HOY
HOY subject id
137 dif cols diff_row 94
x:57:151 y:85:222 z:28:62
in BB :) :)
hereeeeee
[128, 128, 16] [64, 64, 16]
dim2
(63, 128, 128, 16) patch shape
torch.Size([1008, 1, 128, 128]) patches torch
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([1008, 1, 128, 128]) prediction size
(1008, 128, 128, 1) prediction shape  63 16
[0.02598227 0.02784543 0.02799936 ... 0.9965773  0.9965848  0.9968215 ] prediction unique check if we are really rounding the score
(63, 128, 128, 16) prediction shape
here loop: ILZ
ILZ subject id
104 dif cols diff_row 121
x:58:179 y:112:216 z:66:99
in BB :) :)
hereeeeee
[128, 128, 16] [64, 64, 16]
dim2
(63, 128, 128, 16) patch shape
torch.Size([1008, 1, 128, 128]) patches torch
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([1008, 1, 128, 128]) prediction size
(1008, 128, 128, 1) prediction shape  63 16
[0.02519985 0.02686325 0.02711628 ... 0.9965773  0.9965848  0.9968215 ] prediction unique check if we are really rounding the score
(63, 128, 128, 16) prediction shape
here loop: KZ
KZ subject id
104 dif cols diff_row 61
x:105:166 y:111:215 z:18:82
in BB :) :)
hereeeeee
[128, 128, 16] [64, 64, 16]
dim2
(63, 128, 128, 16) patch shape
torch.Size([1008, 1, 128, 128]) patches torch
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([1008, 1, 128, 128]) prediction size
(1008, 128, 128, 1) prediction shape  63 16
[0.02856996 0.02924444 0.03016325 ... 0.9965773  0.9965848  0.9968215 ] prediction unique check if we are really rounding the score
(63, 128, 128, 16) prediction shape
here loop: RA
RA subject id
108 dif cols diff_row 95
x:78:173 y:111:219 z:26:71
in BB :) :)
hereeeeee
[128, 128, 16] [64, 64, 16]
dim2
(63, 128, 128, 16) patch shape
torch.Size([1008, 1, 128, 128]) patches torch
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([1008, 1, 128, 128]) prediction size
(1008, 128, 128, 1) prediction shape  63 16
[0.027162   0.02729043 0.02755133 ... 0.9965773  0.9965848  0.9968215 ] prediction unique check if we are really rounding the score
(63, 128, 128, 16) prediction shape
here loop: RR
RR subject id
144 dif cols diff_row 94
x:83:177 y:87:231 z:0:118
in BB :) :)
hereeeeee
[128, 128, 16] [64, 64, 16]
dim2
(63, 128, 128, 16) patch shape
torch.Size([1008, 1, 128, 128]) patches torch
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([1008, 1, 128, 128]) prediction size
(1008, 128, 128, 1) prediction shape  63 16
[0.02637196 0.02849108 0.02944511 ... 0.9965773  0.9965848  0.9968215 ] prediction unique check if we are really rounding the score
(63, 128, 128, 16) prediction shape
here loop: SS
SS subject id
117 dif cols diff_row 47
x:101:148 y:66:183 z:32:108
in BB :) :)
hereeeeee
[128, 128, 16] [64, 64, 16]
dim2
(63, 128, 128, 16) patch shape
torch.Size([1008, 1, 128, 128]) patches torch
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([1008, 1, 128, 128]) prediction size
(1008, 128, 128, 1) prediction shape  63 16
[0.03174507 0.03258424 0.03287361 ... 0.9965773  0.9965848  0.9968215 ] prediction unique check if we are really rounding the score
(63, 128, 128, 16) prediction shape
here loop: ZM
ZM subject id
127 dif cols diff_row 111
x:86:197 y:88:215 z:4:62
in BB :) :)
hereeeeee
[128, 128, 16] [64, 64, 16]
dim2
(54, 128, 128, 16) patch shape
torch.Size([864, 1, 128, 128]) patches torch
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([864, 1, 128, 128]) prediction size
(864, 128, 128, 1) prediction shape  54 16
[0.0247605  0.02689951 0.02895057 ... 0.9965773  0.9965848  0.9968215 ] prediction unique check if we are really rounding the score
(54, 128, 128, 16) prediction shape
here loop: AH
AH subject id
133 dif cols diff_row 90
x:83:173 y:89:222 z:14:100
in BB :) :)
hereeeeee
[128, 128, 16] [64, 64, 16]
dim2
(63, 128, 128, 16) patch shape
torch.Size([1008, 1, 128, 128]) patches torch
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([1008, 1, 128, 128]) prediction size
(1008, 128, 128, 1) prediction shape  63 16
[0.02729042 0.02768339 0.02945316 ... 0.9965773  0.9965848  0.9968215 ] prediction unique check if we are really rounding the score
(63, 128, 128, 16) prediction shape
here loop: AP
AP subject id
140 dif cols diff_row 111
x:35:146 y:48:188 z:18:45
in BB :) :)
hereeeeee
[128, 128, 16] [64, 64, 16]
dim2
(63, 128, 128, 16) patch shape
torch.Size([1008, 1, 128, 128]) patches torch
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([1008, 1, 128, 128]) prediction size
(1008, 128, 128, 1) prediction shape  63 16
[0.0236026  0.02731435 0.02935708 ... 0.9965773  0.9965848  0.9968215 ] prediction unique check if we are really rounding the score
(63, 128, 128, 16) prediction shape
here loop: DA
DA subject id
165 dif cols diff_row 137
x:82:219 y:34:199 z:61:95
in BB :) :)
hereeeeee
[128, 128, 16] [64, 64, 16]
dim2
(63, 128, 128, 16) patch shape
torch.Size([1008, 1, 128, 128]) patches torch
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([1008, 1, 128, 128]) prediction size
(1008, 128, 128, 1) prediction shape  63 16
[0.02649505 0.02815148 0.02945964 ... 0.9965773  0.9965848  0.9968215 ] prediction unique check if we are really rounding the score
(63, 128, 128, 16) prediction shape
here loop: FC
FC subject id
125 dif cols diff_row 83
x:93:176 y:81:206 z:46:115
in BB :) :)
hereeeeee
[128, 128, 16] [64, 64, 16]
dim2
(63, 128, 128, 16) patch shape
torch.Size([1008, 1, 128, 128]) patches torch
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([1008, 1, 128, 128]) prediction size
(1008, 128, 128, 1) prediction shape  63 16
[0.02791623 0.02966339 0.03072299 ... 0.9965773  0.9965848  0.9968215 ] prediction unique check if we are really rounding the score
(63, 128, 128, 16) prediction shape
here loop: GKY
GKY subject id
137 dif cols diff_row 137
x:71:208 y:62:199 z:46:78
in BB :) :)
hereeeeee
[128, 128, 16] [64, 64, 16]
dim2
(63, 128, 128, 16) patch shape
torch.Size([1008, 1, 128, 128]) patches torch
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([1008, 1, 128, 128]) prediction size
(1008, 128, 128, 1) prediction shape  63 16
[0.0263089  0.02675764 0.02686358 ... 0.9965773  0.9965848  0.9968215 ] prediction unique check if we are really rounding the score
(63, 128, 128, 16) prediction shape
here loop: GN
GN subject id
117 dif cols diff_row 148
x:44:192 y:106:223 z:49:102
in BB :) :)
hereeeeee
[128, 128, 16] [64, 64, 16]
dim2
(63, 128, 128, 16) patch shape
torch.Size([1008, 1, 128, 128]) patches torch
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([1008, 1, 128, 128]) prediction size
(1008, 128, 128, 1) prediction shape  63 16
[0.02510469 0.02660671 0.02685848 ... 0.9965773  0.9965848  0.9968215 ] prediction unique check if we are really rounding the score
(63, 128, 128, 16) prediction shape
here loop: HM
HM subject id
45 dif cols diff_row 82
x:107:189 y:187:232 z:60:90
in BB :) :)
hereeeeee
[128, 128, 16] [64, 64, 16]
dim2
(63, 128, 128, 16) patch shape
torch.Size([1008, 1, 128, 128]) patches torch
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([1008, 1, 128, 128]) prediction size
(1008, 128, 128, 1) prediction shape  63 16
[0.02891323 0.02929471 0.02960347 ... 0.9965773  0.9965848  0.9968215 ] prediction unique check if we are really rounding the score
(63, 128, 128, 16) prediction shape
here loop: HOY
HOY subject id
137 dif cols diff_row 94
x:57:151 y:85:222 z:28:62
in BB :) :)
hereeeeee
[128, 128, 16] [64, 64, 16]
dim2
(63, 128, 128, 16) patch shape
torch.Size([1008, 1, 128, 128]) patches torch
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([1008, 1, 128, 128]) prediction size
(1008, 128, 128, 1) prediction shape  63 16
[0.02598227 0.02784543 0.02799936 ... 0.9965773  0.9965848  0.9968215 ] prediction unique check if we are really rounding the score
(63, 128, 128, 16) prediction shape
here loop: ILZ
ILZ subject id
104 dif cols diff_row 121
x:58:179 y:112:216 z:66:99
in BB :) :)
hereeeeee
[128, 128, 16] [64, 64, 16]
dim2
(63, 128, 128, 16) patch shape
torch.Size([1008, 1, 128, 128]) patches torch
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([1008, 1, 128, 128]) prediction size
(1008, 128, 128, 1) prediction shape  63 16
[0.02519985 0.02686325 0.02711628 ... 0.9965773  0.9965848  0.9968215 ] prediction unique check if we are really rounding the score
(63, 128, 128, 16) prediction shape
here loop: KZ
KZ subject id
104 dif cols diff_row 61
x:105:166 y:111:215 z:18:82
in BB :) :)
hereeeeee
[128, 128, 16] [64, 64, 16]
dim2
(63, 128, 128, 16) patch shape
torch.Size([1008, 1, 128, 128]) patches torch
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([1008, 1, 128, 128]) prediction size
(1008, 128, 128, 1) prediction shape  63 16
[0.02856996 0.02924444 0.03016325 ... 0.9965773  0.9965848  0.9968215 ] prediction unique check if we are really rounding the score
(63, 128, 128, 16) prediction shape
here loop: RA
RA subject id
108 dif cols diff_row 95
x:78:173 y:111:219 z:26:71
in BB :) :)
hereeeeee
[128, 128, 16] [64, 64, 16]
dim2
(63, 128, 128, 16) patch shape
torch.Size([1008, 1, 128, 128]) patches torch
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([1008, 1, 128, 128]) prediction size
(1008, 128, 128, 1) prediction shape  63 16
[0.027162   0.02729043 0.02755133 ... 0.9965773  0.9965848  0.9968215 ] prediction unique check if we are really rounding the score
(63, 128, 128, 16) prediction shape
here loop: RR
RR subject id
144 dif cols diff_row 94
x:83:177 y:87:231 z:0:118
in BB :) :)
hereeeeee
[128, 128, 16] [64, 64, 16]
dim2
(63, 128, 128, 16) patch shape
torch.Size([1008, 1, 128, 128]) patches torch
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([1008, 1, 128, 128]) prediction size
(1008, 128, 128, 1) prediction shape  63 16
[0.02637196 0.02849108 0.02944511 ... 0.9965773  0.9965848  0.9968215 ] prediction unique check if we are really rounding the score
(63, 128, 128, 16) prediction shape
here loop: SS
SS subject id
117 dif cols diff_row 47
x:101:148 y:66:183 z:32:108
in BB :) :)
hereeeeee
[128, 128, 16] [64, 64, 16]
dim2
(63, 128, 128, 16) patch shape
torch.Size([1008, 1, 128, 128]) patches torch
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([1008, 1, 128, 128]) prediction size
(1008, 128, 128, 1) prediction shape  63 16
[0.03174507 0.03258424 0.03287361 ... 0.9965773  0.9965848  0.9968215 ] prediction unique check if we are really rounding the score
(63, 128, 128, 16) prediction shape
here loop: ZM
ZM subject id
127 dif cols diff_row 111
x:86:197 y:88:215 z:4:62
in BB :) :)
hereeeeee
[128, 128, 16] [64, 64, 16]
dim2
(54, 128, 128, 16) patch shape
torch.Size([864, 1, 128, 128]) patches torch
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([864, 1, 128, 128]) prediction size
(864, 128, 128, 1) prediction shape  54 16
[0.0247605  0.02689951 0.02895057 ... 0.9965773  0.9965848  0.9968215 ] prediction unique check if we are really rounding the score
(54, 128, 128, 16) prediction shape
4.0 post_processing.max_over_lap
[0. 1. 2. 3. 4.] unique pred
[0. 1. 2. 3. 4.] unique pred
