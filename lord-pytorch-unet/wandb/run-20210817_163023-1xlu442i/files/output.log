True cuda
args: None UNet UNet_2 /cs/casmip/nirm/embryo_project_version1/EXP_FOLDER/exp_fp2/220/exp2d_DF_3_2d False unet2d_185 DF_3_2d_TL DF_3_2d_TU DF_3_2d_VA DF_3_2d_TE True True /cs/labs/josko/nirm/embryo_project_version1/embyo_projects_codes/models_config/config_2d /cs/labs/josko/nirm/embryo_project_version1/embyo_projects_codes/models_config/config_2d
dividing....
(2016, 128, 128, 1) imaggggggeeeeeeeeeeeeeeee shape
[0.] unique claseesssssssssssssssssssssssssssssssssssssssssssssssss
/cs/casmip/nirm/embryo_project_version1/venu-pytorch/lib/python3.7/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)
  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
False True load_model
184 subject id
139 dif cols diff_row 76
x:48:124 y:71:210 z:26:92
hereeeeee
[128, 128, 16] [64, 64, 16]
dim2
(54, 128, 128, 16) patch shape
torch.Size([864, 1, 128, 128]) patches torch
864 patches size
16 batch size
0 iiiiiii
16 iiiiiii
32 iiiiiii
48 iiiiiii
64 iiiiiii
80 iiiiiii
96 iiiiiii
112 iiiiiii
128 iiiiiii
144 iiiiiii
160 iiiiiii
176 iiiiiii
192 iiiiiii
208 iiiiiii
224 iiiiiii
240 iiiiiii
256 iiiiiii
272 iiiiiii
288 iiiiiii
304 iiiiiii
320 iiiiiii
336 iiiiiii
352 iiiiiii
368 iiiiiii
384 iiiiiii
400 iiiiiii
416 iiiiiii
432 iiiiiii
448 iiiiiii
464 iiiiiii
480 iiiiiii
496 iiiiiii
512 iiiiiii
528 iiiiiii
544 iiiiiii
560 iiiiiii
576 iiiiiii
592 iiiiiii
608 iiiiiii
624 iiiiiii
640 iiiiiii
656 iiiiiii
672 iiiiiii
688 iiiiiii
704 iiiiiii
720 iiiiiii
736 iiiiiii
752 iiiiiii
768 iiiiiii
784 iiiiiii
800 iiiiiii
816 iiiiiii
832 iiiiiii
848 iiiiiii
torch.Size([864, 1, 128, 128]) prediction size
(864, 128, 128, 1) prediction shape  54 16
[3.0249865e-08 3.6732278e-08 3.9672091e-08 ... 9.9999976e-01 9.9999988e-01
 1.0000000e+00] prediction unique check if we are really rounding the score
(54, 128, 128, 16) prediction shape
200 subject id
119 dif cols diff_row 163
x:63:226 y:80:199 z:21:78
hereeeeee
[128, 128, 16] [64, 64, 16]
dim2
(45, 128, 128, 16) patch shape
torch.Size([720, 1, 128, 128]) patches torch
720 patches size
16 batch size
0 iiiiiii
16 iiiiiii
32 iiiiiii
48 iiiiiii
64 iiiiiii
80 iiiiiii
96 iiiiiii
112 iiiiiii
128 iiiiiii
144 iiiiiii
160 iiiiiii
176 iiiiiii
192 iiiiiii
208 iiiiiii
224 iiiiiii
240 iiiiiii
256 iiiiiii
272 iiiiiii
288 iiiiiii
304 iiiiiii
320 iiiiiii
336 iiiiiii
352 iiiiiii
368 iiiiiii
384 iiiiiii
400 iiiiiii
416 iiiiiii
432 iiiiiii
448 iiiiiii
464 iiiiiii
480 iiiiiii
496 iiiiiii
512 iiiiiii
528 iiiiiii
544 iiiiiii
560 iiiiiii
576 iiiiiii
592 iiiiiii
608 iiiiiii
624 iiiiiii
640 iiiiiii
656 iiiiiii
672 iiiiiii
688 iiiiiii
704 iiiiiii
torch.Size([720, 1, 128, 128]) prediction size
(720, 128, 128, 1) prediction shape  45 16
[4.3332747e-08 5.1751240e-08 5.4294041e-08 ... 9.9999976e-01 9.9999988e-01
 1.0000000e+00] prediction unique check if we are really rounding the score
(45, 128, 128, 16) prediction shape
203 subject id
135 dif cols diff_row 136
x:43:179 y:34:169 z:12:36
hereeeeee
[128, 128, 16] [64, 64, 16]
dim2
(36, 128, 128, 16) patch shape
torch.Size([576, 1, 128, 128]) patches torch
576 patches size
16 batch size
0 iiiiiii
16 iiiiiii
32 iiiiiii
48 iiiiiii
64 iiiiiii
80 iiiiiii
96 iiiiiii
112 iiiiiii
128 iiiiiii
144 iiiiiii
160 iiiiiii
176 iiiiiii
192 iiiiiii
208 iiiiiii
224 iiiiiii
240 iiiiiii
256 iiiiiii
272 iiiiiii
288 iiiiiii
304 iiiiiii
320 iiiiiii
336 iiiiiii
352 iiiiiii
368 iiiiiii
384 iiiiiii
400 iiiiiii
416 iiiiiii
432 iiiiiii
448 iiiiiii
464 iiiiiii
480 iiiiiii
496 iiiiiii
512 iiiiiii
528 iiiiiii
544 iiiiiii
560 iiiiiii
torch.Size([576, 1, 128, 128]) prediction size
(576, 128, 128, 1) prediction shape  36 16
[3.2152759e-08 3.2249002e-08 3.4872741e-08 ... 9.9999976e-01 9.9999988e-01
 1.0000000e+00] prediction unique check if we are really rounding the score
(36, 128, 128, 16) prediction shape
209 subject id
145 dif cols diff_row 76
x:103:179 y:106:251 z:22:81
hereeeeee
[128, 128, 16] [64, 64, 16]
dim2
(54, 128, 128, 16) patch shape
torch.Size([864, 1, 128, 128]) patches torch
864 patches size
16 batch size
0 iiiiiii
16 iiiiiii
32 iiiiiii
48 iiiiiii
64 iiiiiii
80 iiiiiii
96 iiiiiii
112 iiiiiii
128 iiiiiii
144 iiiiiii
160 iiiiiii
176 iiiiiii
192 iiiiiii
208 iiiiiii
224 iiiiiii
240 iiiiiii
256 iiiiiii
272 iiiiiii
288 iiiiiii
304 iiiiiii
320 iiiiiii
336 iiiiiii
352 iiiiiii
368 iiiiiii
384 iiiiiii
400 iiiiiii
416 iiiiiii
432 iiiiiii
448 iiiiiii
464 iiiiiii
480 iiiiiii
496 iiiiiii
512 iiiiiii
528 iiiiiii
544 iiiiiii
560 iiiiiii
576 iiiiiii
592 iiiiiii
608 iiiiiii
624 iiiiiii
640 iiiiiii
656 iiiiiii
672 iiiiiii
688 iiiiiii
704 iiiiiii
720 iiiiiii
736 iiiiiii
752 iiiiiii
768 iiiiiii
784 iiiiiii
800 iiiiiii
816 iiiiiii
832 iiiiiii
848 iiiiiii
torch.Size([864, 1, 128, 128]) prediction size
(864, 128, 128, 1) prediction shape  54 16
[3.6503895e-08 3.7961740e-08 3.8418669e-08 ... 9.9999976e-01 9.9999988e-01
 1.0000000e+00] prediction unique check if we are really rounding the score
(54, 128, 128, 16) prediction shape
211 subject id
166 dif cols diff_row 90
x:102:192 y:61:227 z:3:58
hereeeeee
[128, 128, 16] [64, 64, 16]
dim2
(27, 128, 128, 16) patch shape
torch.Size([432, 1, 128, 128]) patches torch
432 patches size
16 batch size
0 iiiiiii
16 iiiiiii
32 iiiiiii
48 iiiiiii
64 iiiiiii
80 iiiiiii
96 iiiiiii
112 iiiiiii
128 iiiiiii
144 iiiiiii
160 iiiiiii
176 iiiiiii
192 iiiiiii
208 iiiiiii
224 iiiiiii
240 iiiiiii
256 iiiiiii
272 iiiiiii
288 iiiiiii
304 iiiiiii
320 iiiiiii
336 iiiiiii
352 iiiiiii
368 iiiiiii
384 iiiiiii
400 iiiiiii
416 iiiiiii
torch.Size([432, 1, 128, 128]) prediction size
(432, 128, 128, 1) prediction shape  27 16
[4.6326821e-08 4.7972758e-08 4.8162903e-08 ... 9.9999976e-01 9.9999988e-01
 1.0000000e+00] prediction unique check if we are really rounding the score
(27, 128, 128, 16) prediction shape
4.0 post_processing.max_over_lap
[0. 1. 2. 3. 4.] unique pred
[0. 1. 2. 3. 4.] unique pred
[0. 1. 2. 3. 4.] unique pred
[0. 1. 2. 3. 4.] unique pred
[0. 1. 2. 3. 4.] unique pred
[0. 1. 2. 3. 4.] unique pred
Traceback (most recent call last):
  File "lord_exp.py", line 140, in <module>
    main()
  File "lord_exp.py", line 133, in main
    args.func(args)
  File "lord_exp.py", line 117, in run_exp
    evaluate_model(model_dict, path_new_exp, model_name, exp_dict, data_with_gt, data_param, split_dict)
  File "lord_exp.py", line 47, in evaluate_model
    lord3d.evaluate(model_dict, exp_dict, path_to_weights, data_param, data_with_gt, path_results, split_dict)
  File "/cs/labs/josko/nirm/embryo_project_version1/embyo_projects_codes/lord-pytorch-unet/model/training_unet.py", line 282, in evaluate
    rec = recall_score(gt_1d, res_1d)
  File "/cs/casmip/nirm/embryo_project_version1/venu-pytorch/lib/python3.7/site-packages/sklearn/utils/validation.py", line 63, in inner_f
    return f(*args, **kwargs)
  File "/cs/casmip/nirm/embryo_project_version1/venu-pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py", line 1780, in recall_score
    zero_division=zero_division)
  File "/cs/casmip/nirm/embryo_project_version1/venu-pytorch/lib/python3.7/site-packages/sklearn/utils/validation.py", line 63, in inner_f
    return f(*args, **kwargs)
  File "/cs/casmip/nirm/embryo_project_version1/venu-pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py", line 1465, in precision_recall_fscore_support
    pos_label)
  File "/cs/casmip/nirm/embryo_project_version1/venu-pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py", line 1277, in _check_set_wise_labels
    y_type, y_true, y_pred = _check_targets(y_true, y_pred)
  File "/cs/casmip/nirm/embryo_project_version1/venu-pytorch/lib/python3.7/site-packages/sklearn/metrics/_classification.py", line 85, in _check_targets
    type_pred = type_of_target(y_pred)
  File "/cs/casmip/nirm/embryo_project_version1/venu-pytorch/lib/python3.7/site-packages/sklearn/utils/multiclass.py", line 306, in type_of_target
    if (len(np.unique(y)) > 2) or (y.ndim >= 2 and len(y[0]) > 1):
  File "<__array_function__ internals>", line 6, in unique
  File "/cs/casmip/nirm/embryo_project_version1/venu-pytorch/lib/python3.7/site-packages/numpy/lib/arraysetops.py", line 262, in unique
    ret = _unique1d(ar, return_index, return_inverse, return_counts)
  File "/cs/casmip/nirm/embryo_project_version1/venu-pytorch/lib/python3.7/site-packages/numpy/lib/arraysetops.py", line 323, in _unique1d
    ar.sort()
KeyboardInterrupt