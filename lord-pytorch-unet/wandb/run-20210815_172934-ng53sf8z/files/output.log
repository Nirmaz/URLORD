True cuda
args: None UNetC UNetC_2 /cs/casmip/nirm/embryo_project_version1/EXP_FOLDER/exp_fp2/173/exp2d_DF_3_2d True unet2dC_173 DF_3_2d_TL DF_3_2d_TU DF_3_2d_VA DF_3_2d_TE False True /cs/labs/josko/nirm/embryo_project_version1/embyo_projects_codes/models_config/config_2d /cs/labs/josko/nirm/embryo_project_version1/embyo_projects_codes/models_config/config_2d
dividing....
(2016, 128, 128, 1) imaggggggeeeeeeeeeeeeeeee shape
[0.] unique claseesssssssssssssssssssssssssssssssssssssssssssssssss
False False load_model
arrive train
here opt
here seg decay
here recon_loss
/cs/casmip/nirm/embryo_project_version1/venu-pytorch/lib/python3.7/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)
  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
  0%|                                                                                                                                                                                                                                                                                         | 0/378 [00:00<?, ?it/s]
  0%|                                                                                                                                                                                                                                                                                         | 0/378 [00:00<?, ?it/s]
  0%|                                                                                                                                                                                                                                                                                          | 0/45 [00:00<?, ?it/s]
  0%|                                                                                                                                                                                                                                                                                         | 0/126 [00:00<?, ?it/s]
10 recon_decay
------------ 0.07303619384765625 backwards -------------------------------
10 recon_decay
------------ 0.06507253646850586 backwards -------------------------------
10 recon_decay
------------ 0.06438374519348145 backwards -------------------------------
10 recon_decay
------------ 0.06153440475463867 backwards -------------------------------
10 recon_decay
------------ 0.0615692138671875 backwards -------------------------------
10 recon_decay
------------ 0.06165122985839844 backwards -------------------------------
10 recon_decay
------------ 0.06148099899291992 backwards -------------------------------
10 recon_decay
------------ 0.06128406524658203 backwards -------------------------------
10 recon_decay
------------ 0.061595916748046875 backwards -------------------------------
10 recon_decay
------------ 0.06265544891357422 backwards -------------------------------
10 recon_decay
------------ 0.06143975257873535 backwards -------------------------------
10 recon_decay
------------ 0.06122326850891113 backwards -------------------------------
10 recon_decay
------------ 0.06166648864746094 backwards -------------------------------
10 recon_decay
------------ 0.06214618682861328 backwards -------------------------------
10 recon_decay
------------ 0.06236839294433594 backwards -------------------------------
10 recon_decay
------------ 0.06082439422607422 backwards -------------------------------
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)                                                                                                                                                                                              | 0/126 [00:00<?, ?it/s]
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
epoch #0:   4%|██████████▌                                                                                                                                                                                                                                                | 16/378 [00:02<00:35, 10.19it/s, loss=1.23]
  4%|███████████▌                                                                                                                                                                                                                                                                    | 16/378 [00:02<00:35, 10.19it/s]
------------ 0.061690568923950195 backwards -------------------------------
10 recon_decay
------------ 0.06175065040588379 backwards -------------------------------
10 recon_decay
------------ 0.062024593353271484 backwards -------------------------------
10 recon_decay
------------ 0.06109476089477539 backwards -------------------------------
10 recon_decay
------------ 0.06144285202026367 backwards -------------------------------
10 recon_decay
------------ 0.06102871894836426 backwards -------------------------------
10 recon_decay
------------ 0.06053495407104492 backwards -------------------------------
10 recon_decay
------------ 0.06061506271362305 backwards -------------------------------
10 recon_decay
------------ 0.06055188179016113 backwards -------------------------------
10 recon_decay
------------ 0.061855316162109375 backwards -------------------------------
10 recon_decay
------------ 0.06085538864135742 backwards -------------------------------
10 recon_decay
------------ 0.06077241897583008 backwards -------------------------------
10 recon_decay
------------ 0.060851097106933594 backwards -------------------------------
10 recon_decay
------------ 0.06119966506958008 backwards -------------------------------
10 recon_decay
------------ 0.0608675479888916 backwards -------------------------------
10 recon_decay
------------ 0.06127762794494629 backwards -------------------------------
10 recon_decay
------------ 0.06248641014099121 backwards -------------------------------
10 recon_decay
------------ 0.06060338020324707 backwards -------------------------------
10 recon_decay
------------ 0.0612034797668457 backwards -------------------------------
10 recon_decay
------------ 0.06051206588745117 backwards -------------------------------
10 recon_decay
------------ 0.06132340431213379 backwards -------------------------------
10 recon_decay
------------ 0.06059527397155762 backwards -------------------------------


 16%|███████████████████████████████████████████▏                                                                                                                                                                                                                                    | 60/378 [00:06<00:29, 10.88it/s]
------------ 0.06747961044311523 backwards -------------------------------
10 recon_decay
------------ 0.06173133850097656 backwards -------------------------------
10 recon_decay
------------ 0.06067800521850586 backwards -------------------------------
10 recon_decay
------------ 0.06127119064331055 backwards -------------------------------
10 recon_decay
------------ 0.061000823974609375 backwards -------------------------------
10 recon_decay
------------ 0.06156134605407715 backwards -------------------------------
10 recon_decay
------------ 0.0604710578918457 backwards -------------------------------
10 recon_decay
------------ 0.06139492988586426 backwards -------------------------------
10 recon_decay
------------ 0.060976505279541016 backwards -------------------------------
10 recon_decay
------------ 0.06182861328125 backwards -------------------------------
10 recon_decay
------------ 0.06193685531616211 backwards -------------------------------
10 recon_decay
------------ 0.061708927154541016 backwards -------------------------------
10 recon_decay
------------ 0.06231856346130371 backwards -------------------------------
10 recon_decay
------------ 0.06141090393066406 backwards -------------------------------
10 recon_decay
------------ 0.06154751777648926 backwards -------------------------------
10 recon_decay
------------ 0.06187009811401367 backwards -------------------------------
10 recon_decay
------------ 0.06162619590759277 backwards -------------------------------
10 recon_decay
------------ 0.06188774108886719 backwards -------------------------------
10 recon_decay
------------ 0.06152796745300293 backwards -------------------------------
10 recon_decay
------------ 0.061930179595947266 backwards -------------------------------
10 recon_decay
------------ 0.06207418441772461 backwards -------------------------------
10 recon_decay
------------ 0.0617673397064209 backwards -------------------------------

 22%|███████████████████████████████████████████████████████████                                                                                                                                                                                                                     | 82/378 [00:08<00:26, 11.03it/s]
------------ 0.06167411804199219 backwards -------------------------------
10 recon_decay
------------ 0.061385393142700195 backwards -------------------------------
10 recon_decay
------------ 0.061434268951416016 backwards -------------------------------
10 recon_decay
------------ 0.061844587326049805 backwards -------------------------------
10 recon_decay
------------ 0.061714887619018555 backwards -------------------------------
10 recon_decay
------------ 0.06045675277709961 backwards -------------------------------
10 recon_decay
------------ 0.060671329498291016 backwards -------------------------------
10 recon_decay
------------ 0.06056356430053711 backwards -------------------------------
10 recon_decay
------------ 0.06129598617553711 backwards -------------------------------
10 recon_decay
------------ 0.06116890907287598 backwards -------------------------------
10 recon_decay
------------ 0.06044197082519531 backwards -------------------------------
10 recon_decay
------------ 0.06117963790893555 backwards -------------------------------
10 recon_decay
------------ 0.06037735939025879 backwards -------------------------------
10 recon_decay
------------ 0.0610508918762207 backwards -------------------------------
10 recon_decay
------------ 0.06134033203125 backwards -------------------------------
10 recon_decay
------------ 0.06077837944030762 backwards -------------------------------
10 recon_decay
------------ 0.06092047691345215 backwards -------------------------------
10 recon_decay
------------ 0.06062746047973633 backwards -------------------------------
10 recon_decay
------------ 0.060518503189086914 backwards -------------------------------
10 recon_decay
------------ 0.06072211265563965 backwards -------------------------------
10 recon_decay
------------ 0.06116485595703125 backwards -------------------------------
10 recon_decay
------------ 0.060771942138671875 backwards -------------------------------
10 recon_decay
------------ 0.06106901168823242 backwards -------------------------------
10 recon_decay
------------ 0.06083226203918457 backwards -------------------------------
10 recon_decay
------------ 0.060828447341918945 backwards -------------------------------
10 recon_decay
------------ 0.061037540435791016 backwards -------------------------------
10 recon_decay
------------ 0.06053757667541504 backwards -------------------------------
10 recon_decay
------------ 0.06046152114868164 backwards -------------------------------
10 recon_decay
------------ 0.06041526794433594 backwards -------------------------------
10 recon_decay
------------ 0.06090426445007324 backwards -------------------------------
10 recon_decay
------------ 0.06119942665100098 backwards -------------------------------
10 recon_decay
------------ 0.06117701530456543 backwards -------------------------------
10 recon_decay
------------ 0.06257843971252441 backwards -------------------------------
10 recon_decay
------------ 0.06302547454833984 backwards -------------------------------
10 recon_decay
------------ 0.06481575965881348 backwards -------------------------------
10 recon_decay
------------ 0.06242966651916504 backwards -------------------------------
10 recon_decay
------------ 0.0623776912689209 backwards -------------------------------
10 recon_decay
------------ 0.060613393783569336 backwards -------------------------------
10 recon_decay
------------ 0.06062889099121094 backwards -------------------------------
10 recon_decay
------------ 0.060707807540893555 backwards -------------------------------
10 recon_decay
------------ 0.06094980239868164 backwards -------------------------------
10 recon_decay
------------ 0.06079745292663574 backwards -------------------------------
10 recon_decay
------------ 0.06105828285217285 backwards -------------------------------
10 recon_decay
------------ 0.06127786636352539 backwards -------------------------------

 28%|██████████████████████████████████████████████████████████████████████████▌                                                                                                                                                                                                    | 104/378 [00:10<00:25, 10.91it/s]
------------ 0.06058669090270996 backwards -------------------------------
10 recon_decay
------------ 0.060402631759643555 backwards -------------------------------
10 recon_decay
------------ 0.06092357635498047 backwards -------------------------------
10 recon_decay
------------ 0.061255693435668945 backwards -------------------------------
10 recon_decay
------------ 0.06125497817993164 backwards -------------------------------
10 recon_decay
------------ 0.06141805648803711 backwards -------------------------------
10 recon_decay
------------ 0.061630964279174805 backwards -------------------------------
10 recon_decay
------------ 0.06148266792297363 backwards -------------------------------
10 recon_decay
------------ 0.06138277053833008 backwards -------------------------------
10 recon_decay
------------ 0.061556100845336914 backwards -------------------------------
10 recon_decay
------------ 0.06193876266479492 backwards -------------------------------
10 recon_decay
------------ 0.06170225143432617 backwards -------------------------------
10 recon_decay
------------ 0.06187844276428223 backwards -------------------------------
10 recon_decay
------------ 0.06220841407775879 backwards -------------------------------
10 recon_decay
------------ 0.062041521072387695 backwards -------------------------------
10 recon_decay
------------ 0.062195777893066406 backwards -------------------------------
10 recon_decay
------------ 0.06173110008239746 backwards -------------------------------
10 recon_decay
------------ 0.061444997787475586 backwards -------------------------------
10 recon_decay
------------ 0.06174111366271973 backwards -------------------------------
10 recon_decay
------------ 0.0619349479675293 backwards -------------------------------
10 recon_decay
------------ 0.062001705169677734 backwards -------------------------------

 33%|██████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                                                                                                    | 126/378 [00:12<00:23, 10.80it/s]
------------ 0.06087160110473633 backwards -------------------------------
10 recon_decay
------------ 0.0604252815246582 backwards -------------------------------
10 recon_decay
------------ 0.0605311393737793 backwards -------------------------------
10 recon_decay
------------ 0.0610957145690918 backwards -------------------------------
10 recon_decay
------------ 0.06128072738647461 backwards -------------------------------
10 recon_decay
------------ 0.061376094818115234 backwards -------------------------------
10 recon_decay
------------ 0.061075448989868164 backwards -------------------------------
10 recon_decay
------------ 0.06032729148864746 backwards -------------------------------
10 recon_decay
------------ 0.06066298484802246 backwards -------------------------------
10 recon_decay
------------ 0.06140494346618652 backwards -------------------------------
10 recon_decay
------------ 0.06129264831542969 backwards -------------------------------
10 recon_decay
------------ 0.06071877479553223 backwards -------------------------------
10 recon_decay
------------ 0.06081986427307129 backwards -------------------------------
10 recon_decay
------------ 0.06085014343261719 backwards -------------------------------
10 recon_decay
------------ 0.06253361701965332 backwards -------------------------------
10 recon_decay
------------ 0.06291556358337402 backwards -------------------------------
10 recon_decay
------------ 0.06173992156982422 backwards -------------------------------
10 recon_decay
------------ 0.060521841049194336 backwards -------------------------------
10 recon_decay
------------ 0.06048440933227539 backwards -------------------------------
10 recon_decay
------------ 0.06032133102416992 backwards -------------------------------
10 recon_decay
------------ 0.06180214881896973 backwards -------------------------------
10 recon_decay
------------ 0.06130814552307129 backwards -------------------------------


 45%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                                                                     | 170/378 [00:16<00:19, 10.91it/s]
------------ 0.06094670295715332 backwards -------------------------------
10 recon_decay
------------ 0.06067299842834473 backwards -------------------------------
10 recon_decay
------------ 0.0605466365814209 backwards -------------------------------
10 recon_decay
------------ 0.061191558837890625 backwards -------------------------------
10 recon_decay
------------ 0.06138801574707031 backwards -------------------------------
10 recon_decay
------------ 0.06044816970825195 backwards -------------------------------
10 recon_decay
------------ 0.06085801124572754 backwards -------------------------------
10 recon_decay
------------ 0.061165571212768555 backwards -------------------------------
10 recon_decay
------------ 0.060762882232666016 backwards -------------------------------
10 recon_decay
------------ 0.06093716621398926 backwards -------------------------------
10 recon_decay
------------ 0.0615229606628418 backwards -------------------------------
10 recon_decay
------------ 0.06101536750793457 backwards -------------------------------
10 recon_decay
------------ 0.06059670448303223 backwards -------------------------------
10 recon_decay
------------ 0.06084704399108887 backwards -------------------------------
10 recon_decay
------------ 0.061867475509643555 backwards -------------------------------
10 recon_decay
------------ 0.06129312515258789 backwards -------------------------------
10 recon_decay
------------ 0.060805559158325195 backwards -------------------------------
10 recon_decay
------------ 0.06041383743286133 backwards -------------------------------
10 recon_decay
------------ 0.06067228317260742 backwards -------------------------------
10 recon_decay
------------ 0.06055045127868652 backwards -------------------------------
10 recon_decay
------------ 0.06208395957946777 backwards -------------------------------
10 recon_decay
------------ 0.06059575080871582 backwards -------------------------------

 51%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                                     | 192/378 [00:18<00:17, 10.76it/s]
------------ 0.0606842041015625 backwards -------------------------------
10 recon_decay
------------ 0.06052064895629883 backwards -------------------------------
10 recon_decay
------------ 0.06099987030029297 backwards -------------------------------
10 recon_decay
------------ 0.06216025352478027 backwards -------------------------------
10 recon_decay
------------ 0.06205391883850098 backwards -------------------------------
10 recon_decay
------------ 0.060759782791137695 backwards -------------------------------
10 recon_decay
------------ 0.06074404716491699 backwards -------------------------------
10 recon_decay
------------ 0.06096696853637695 backwards -------------------------------
10 recon_decay
------------ 0.06157970428466797 backwards -------------------------------
10 recon_decay
------------ 0.06068158149719238 backwards -------------------------------
10 recon_decay
------------ 0.06067347526550293 backwards -------------------------------
10 recon_decay
------------ 0.06095075607299805 backwards -------------------------------
10 recon_decay
------------ 0.06071901321411133 backwards -------------------------------
10 recon_decay
------------ 0.061223506927490234 backwards -------------------------------
10 recon_decay
------------ 0.061862945556640625 backwards -------------------------------
10 recon_decay
------------ 0.06112051010131836 backwards -------------------------------
10 recon_decay
------------ 0.06148195266723633 backwards -------------------------------
10 recon_decay
------------ 0.06121468544006348 backwards -------------------------------
10 recon_decay
------------ 0.061940670013427734 backwards -------------------------------
10 recon_decay
------------ 0.062100887298583984 backwards -------------------------------
10 recon_decay
------------ 0.06196475028991699 backwards -------------------------------
10 recon_decay
------------ 0.06118202209472656 backwards -------------------------------
10 recon_decay
------------ 0.061511993408203125 backwards -------------------------------
10 recon_decay
------------ 0.06122469902038574 backwards -------------------------------
10 recon_decay
------------ 0.061724185943603516 backwards -------------------------------
10 recon_decay
------------ 0.06128740310668945 backwards -------------------------------
10 recon_decay
------------ 0.06181740760803223 backwards -------------------------------
10 recon_decay
------------ 0.060903310775756836 backwards -------------------------------
10 recon_decay
------------ 0.062079668045043945 backwards -------------------------------
10 recon_decay
------------ 0.06386852264404297 backwards -------------------------------
10 recon_decay
------------ 0.06101512908935547 backwards -------------------------------
10 recon_decay
------------ 0.06197619438171387 backwards -------------------------------
10 recon_decay
------------ 0.06183624267578125 backwards -------------------------------
10 recon_decay
------------ 0.061762094497680664 backwards -------------------------------
10 recon_decay
------------ 0.06678652763366699 backwards -------------------------------
10 recon_decay
------------ 0.06642341613769531 backwards -------------------------------
10 recon_decay
------------ 0.06087946891784668 backwards -------------------------------
10 recon_decay
------------ 0.0663142204284668 backwards -------------------------------
10 recon_decay
------------ 0.06645679473876953 backwards -------------------------------
10 recon_decay
------------ 0.062151432037353516 backwards -------------------------------
10 recon_decay
------------ 0.1104283332824707 backwards -------------------------------


 61%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                                        | 232/378 [00:22<00:14, 10.29it/s]
------------ 0.060724735260009766 backwards -------------------------------
10 recon_decay
------------ 0.06132960319519043 backwards -------------------------------
10 recon_decay
------------ 0.062376976013183594 backwards -------------------------------
10 recon_decay
------------ 0.06423258781433105 backwards -------------------------------
10 recon_decay
------------ 0.06355595588684082 backwards -------------------------------
10 recon_decay
------------ 0.0613253116607666 backwards -------------------------------
10 recon_decay
------------ 0.06227564811706543 backwards -------------------------------
10 recon_decay
------------ 0.06297874450683594 backwards -------------------------------
10 recon_decay
------------ 0.06245088577270508 backwards -------------------------------
10 recon_decay
------------ 0.06724143028259277 backwards -------------------------------
10 recon_decay
------------ 0.06274652481079102 backwards -------------------------------
10 recon_decay
------------ 0.0627748966217041 backwards -------------------------------
10 recon_decay
------------ 0.11147308349609375 backwards -------------------------------
10 recon_decay
------------ 0.06196284294128418 backwards -------------------------------
10 recon_decay
------------ 0.06669926643371582 backwards -------------------------------
10 recon_decay
------------ 0.06306147575378418 backwards -------------------------------
10 recon_decay
------------ 0.06313514709472656 backwards -------------------------------
10 recon_decay
------------ 0.07393836975097656 backwards -------------------------------
10 recon_decay
------------ 0.06156134605407715 backwards -------------------------------
10 recon_decay
------------ 0.06068277359008789 backwards -------------------------------

 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                          | 252/378 [00:24<00:11, 10.51it/s]
------------ 0.06146550178527832 backwards -------------------------------
10 recon_decay
------------ 0.0605928897857666 backwards -------------------------------
10 recon_decay
------------ 0.061234235763549805 backwards -------------------------------
10 recon_decay
------------ 0.06590509414672852 backwards -------------------------------
10 recon_decay
------------ 0.08383011817932129 backwards -------------------------------
10 recon_decay
------------ 0.09263324737548828 backwards -------------------------------
10 recon_decay
------------ 0.060952186584472656 backwards -------------------------------
10 recon_decay
------------ 0.06117677688598633 backwards -------------------------------
10 recon_decay
------------ 0.06174969673156738 backwards -------------------------------
10 recon_decay
------------ 0.06170010566711426 backwards -------------------------------
10 recon_decay
------------ 0.06081819534301758 backwards -------------------------------
10 recon_decay
------------ 0.060678958892822266 backwards -------------------------------
10 recon_decay
------------ 0.06074023246765137 backwards -------------------------------
10 recon_decay
------------ 0.07189559936523438 backwards -------------------------------
10 recon_decay
------------ 0.06418490409851074 backwards -------------------------------
10 recon_decay
------------ 0.06517267227172852 backwards -------------------------------
10 recon_decay
------------ 0.06226396560668945 backwards -------------------------------
10 recon_decay
------------ 0.061043500900268555 backwards -------------------------------
10 recon_decay
------------ 0.06119108200073242 backwards -------------------------------
10 recon_decay
------------ 0.061231136322021484 backwards -------------------------------

 72%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                          | 274/378 [00:26<00:09, 10.70it/s]
------------ 0.0619809627532959 backwards -------------------------------
10 recon_decay
------------ 0.062212228775024414 backwards -------------------------------
10 recon_decay
------------ 0.06151556968688965 backwards -------------------------------
10 recon_decay
------------ 0.06482696533203125 backwards -------------------------------
10 recon_decay
------------ 0.06139540672302246 backwards -------------------------------
10 recon_decay
------------ 0.0611269474029541 backwards -------------------------------
10 recon_decay
------------ 0.06103181838989258 backwards -------------------------------
10 recon_decay
------------ 0.06090354919433594 backwards -------------------------------
10 recon_decay
------------ 0.06068587303161621 backwards -------------------------------
10 recon_decay
------------ 0.0626063346862793 backwards -------------------------------
10 recon_decay
------------ 0.06086921691894531 backwards -------------------------------
10 recon_decay
------------ 0.06093192100524902 backwards -------------------------------
10 recon_decay
------------ 0.06123232841491699 backwards -------------------------------
10 recon_decay
------------ 0.06074047088623047 backwards -------------------------------
10 recon_decay
------------ 0.06097292900085449 backwards -------------------------------
10 recon_decay
------------ 0.06195878982543945 backwards -------------------------------
10 recon_decay
------------ 0.06081247329711914 backwards -------------------------------
10 recon_decay
------------ 0.06051969528198242 backwards -------------------------------
10 recon_decay
------------ 0.06063389778137207 backwards -------------------------------
10 recon_decay
------------ 0.06054401397705078 backwards -------------------------------
10 recon_decay
------------ 0.06165361404418945 backwards -------------------------------
10 recon_decay
------------ 0.06086874008178711 backwards -------------------------------

 78%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                          | 296/378 [00:28<00:07, 10.69it/s]
------------ 0.06094098091125488 backwards -------------------------------
10 recon_decay
------------ 0.06058692932128906 backwards -------------------------------
10 recon_decay
------------ 0.06094717979431152 backwards -------------------------------
10 recon_decay
------------ 0.06204962730407715 backwards -------------------------------
10 recon_decay
------------ 0.060744524002075195 backwards -------------------------------
10 recon_decay
------------ 0.060979366302490234 backwards -------------------------------
10 recon_decay
------------ 0.06129884719848633 backwards -------------------------------
10 recon_decay
------------ 0.06260442733764648 backwards -------------------------------
10 recon_decay
------------ 0.0607609748840332 backwards -------------------------------
10 recon_decay
------------ 0.06096696853637695 backwards -------------------------------
10 recon_decay
------------ 0.06088542938232422 backwards -------------------------------
10 recon_decay
------------ 0.06095409393310547 backwards -------------------------------
10 recon_decay
------------ 0.061646223068237305 backwards -------------------------------
10 recon_decay
------------ 0.06168246269226074 backwards -------------------------------
10 recon_decay
------------ 0.06207633018493652 backwards -------------------------------
10 recon_decay
------------ 0.06109166145324707 backwards -------------------------------
10 recon_decay
------------ 0.06075716018676758 backwards -------------------------------
10 recon_decay
------------ 0.061284542083740234 backwards -------------------------------
10 recon_decay
------------ 0.06093001365661621 backwards -------------------------------
10 recon_decay
------------ 0.06554985046386719 backwards -------------------------------
10 recon_decay
------------ 0.06064963340759277 backwards -------------------------------

 84%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                           | 318/378 [00:30<00:05, 10.57it/s]
------------ 0.06065702438354492 backwards -------------------------------
10 recon_decay
------------ 0.06067681312561035 backwards -------------------------------
10 recon_decay
------------ 0.06100654602050781 backwards -------------------------------
10 recon_decay
------------ 0.0606389045715332 backwards -------------------------------
10 recon_decay
------------ 0.060864925384521484 backwards -------------------------------
10 recon_decay
------------ 0.06148219108581543 backwards -------------------------------
10 recon_decay
------------ 0.060657501220703125 backwards -------------------------------
10 recon_decay
------------ 0.06116628646850586 backwards -------------------------------
10 recon_decay
------------ 0.06092548370361328 backwards -------------------------------
10 recon_decay
------------ 0.061437368392944336 backwards -------------------------------
10 recon_decay
------------ 0.06097006797790527 backwards -------------------------------
10 recon_decay
------------ 0.06093764305114746 backwards -------------------------------
10 recon_decay
------------ 0.06077098846435547 backwards -------------------------------
10 recon_decay
------------ 0.06100130081176758 backwards -------------------------------
10 recon_decay
------------ 0.06120753288269043 backwards -------------------------------
10 recon_decay
------------ 0.06069159507751465 backwards -------------------------------
10 recon_decay
------------ 0.060883283615112305 backwards -------------------------------
10 recon_decay
------------ 0.06072831153869629 backwards -------------------------------
10 recon_decay
------------ 0.06108355522155762 backwards -------------------------------
10 recon_decay
------------ 0.060888051986694336 backwards -------------------------------
10 recon_decay
------------ 0.060791969299316406 backwards -------------------------------
10 recon_decay
------------ 0.06065535545349121 backwards -------------------------------

 90%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                           | 340/378 [00:32<00:03, 10.58it/s]
------------ 0.06077766418457031 backwards -------------------------------
10 recon_decay
------------ 0.061528682708740234 backwards -------------------------------
10 recon_decay
------------ 0.061324357986450195 backwards -------------------------------
10 recon_decay
------------ 0.06151008605957031 backwards -------------------------------
10 recon_decay
------------ 0.06098675727844238 backwards -------------------------------
10 recon_decay
------------ 0.06088566780090332 backwards -------------------------------
10 recon_decay
------------ 0.06100606918334961 backwards -------------------------------
10 recon_decay
------------ 0.06067347526550293 backwards -------------------------------
10 recon_decay
------------ 0.06159210205078125 backwards -------------------------------
10 recon_decay
------------ 0.06075334548950195 backwards -------------------------------
10 recon_decay
------------ 0.0609743595123291 backwards -------------------------------
10 recon_decay
------------ 0.06060290336608887 backwards -------------------------------
10 recon_decay
------------ 0.06111001968383789 backwards -------------------------------
10 recon_decay
------------ 0.06074929237365723 backwards -------------------------------
10 recon_decay
------------ 0.061170339584350586 backwards -------------------------------
10 recon_decay
------------ 0.061582326889038086 backwards -------------------------------
10 recon_decay
------------ 0.06117701530456543 backwards -------------------------------
10 recon_decay
------------ 0.06090211868286133 backwards -------------------------------
10 recon_decay
------------ 0.06069445610046387 backwards -------------------------------
10 recon_decay
------------ 0.06716513633728027 backwards -------------------------------
10 recon_decay
------------ 0.060326576232910156 backwards -------------------------------

 95%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████             | 360/378 [00:34<00:01, 10.34it/s]
------------ 0.061017751693725586 backwards -------------------------------
10 recon_decay
------------ 0.0613551139831543 backwards -------------------------------
10 recon_decay
------------ 0.06033968925476074 backwards -------------------------------
10 recon_decay
------------ 0.061785221099853516 backwards -------------------------------
10 recon_decay
------------ 0.06367611885070801 backwards -------------------------------
10 recon_decay
------------ 0.060610055923461914 backwards -------------------------------
10 recon_decay
------------ 0.061852216720581055 backwards -------------------------------
10 recon_decay
------------ 0.06041884422302246 backwards -------------------------------
10 recon_decay
------------ 0.061411142349243164 backwards -------------------------------
10 recon_decay
------------ 0.06068563461303711 backwards -------------------------------
10 recon_decay
------------ 0.06060481071472168 backwards -------------------------------
10 recon_decay
------------ 0.06064295768737793 backwards -------------------------------
10 recon_decay
------------ 0.0609588623046875 backwards -------------------------------
10 recon_decay
------------ 0.060701608657836914 backwards -------------------------------
10 recon_decay
------------ 0.06111598014831543 backwards -------------------------------
10 recon_decay
------------ 0.06045079231262207 backwards -------------------------------
10 recon_decay
------------ 0.06068587303161621 backwards -------------------------------
10 recon_decay
------------ 0.061106204986572266 backwards -------------------------------
10 recon_decay
------------ 0.06059694290161133 backwards -------------------------------
10 recon_decay
------------ 0.10794377326965332 backwards -------------------------------
10 recon_decay
------------ 0.06070232391357422 backwards -------------------------------
 99%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌ | 376/378 [00:36<00:00, 10.38it/s]
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
 16%|██████████████████████████████████████████▌                                                                                                                                                                                                                                       | 7/45 [00:36<02:25,  3.83s/it]
------------ 0.060384273529052734 backwards -------------------------------
10 recon_decay
------------ 0.06117367744445801 backwards -------------------------------
10 recon_decay
------------ 0.06084918975830078 backwards -------------------------------
10 recon_decay
------------ 0.06147646903991699 backwards -------------------------------
10 recon_decay
------------ 0.06120586395263672 backwards -------------------------------
10 recon_decay
------------ 0.06022214889526367 backwards -------------------------------
10 recon_decay
------------ 0.06064581871032715 backwards -------------------------------
10 recon_decay
------------ 0.06024742126464844 backwards -------------------------------
10 recon_decay
------------ 0.060851335525512695 backwards -------------------------------
10 recon_decay
------------ 0.06429076194763184 backwards -------------------------------
10 recon_decay
------------ 0.06105208396911621 backwards -------------------------------
10 recon_decay
------------ 0.06077170372009277 backwards -------------------------------
10 recon_decay
------------ 0.06120491027832031 backwards -------------------------------
10 recon_decay
------------ 0.06193423271179199 backwards -------------------------------
10 recon_decay
------------ 0.06291842460632324 backwards -------------------------------
10 recon_decay
------------ 0.060817718505859375 backwards -------------------------------
10 recon_decay
------------ 0.06146860122680664 backwards -------------------------------
10 recon_decay
------------ 0.06226944923400879 backwards -------------------------------
10 recon_decay
------------ 0.0607297420501709 backwards -------------------------------
10 recon_decay
------------ 0.06159353256225586 backwards -------------------------------
10 recon_decay
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊            | 43/45 [00:37<00:00,  5.52it/s]
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)

 96%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏          | 121/126 [00:39<00:00, 50.47it/s]
saving model......................................................
done
------------ 40.12831425666809 seg time alll epoch -------------------------------
saving model......................................................
here1
saving model......................................................
dict_keys(['104', '135', '170', '174', '176', '177', '184', '188', '189', '191', '197', '200', '201', '203', '205', '208', '209', '211', '223', '224', '225', '228', '232', '234', '258', '76', '78', '81', '91', '93', '95'])
184 subject id
139 dif cols diff_row 76
x:48:124 y:71:210 z:26:92
hereeeeee
[128, 128, 16] [64, 64, 16]
dim2
(54, 128, 128, 16) patch shape
torch.Size([864, 1, 128, 128]) patches torch
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([864, 1, 128, 128]) prediction size
(864, 128, 128, 1) prediction shape  54 16
[0.08059464 0.08155803 0.08157285 ... 0.991589   0.9915896  0.99158984] prediction unique check if we are really rounding the score
(54, 128, 128, 16) prediction shape
200 subject id
119 dif cols diff_row 163
x:63:226 y:80:199 z:21:78
hereeeeee
[128, 128, 16] [64, 64, 16]
dim2
(45, 128, 128, 16) patch shape
torch.Size([720, 1, 128, 128]) patches torch
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([720, 1, 128, 128]) prediction size
(720, 128, 128, 1) prediction shape  45 16
[0.08795273 0.08836125 0.08839987 ... 0.9915918  0.99159205 0.99159276] prediction unique check if we are really rounding the score
(45, 128, 128, 16) prediction shape
203 subject id
135 dif cols diff_row 136
x:43:179 y:34:169 z:12:36
hereeeeee
[128, 128, 16] [64, 64, 16]
dim2
(36, 128, 128, 16) patch shape
torch.Size([576, 1, 128, 128]) patches torch
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([576, 1, 128, 128]) prediction size
(576, 128, 128, 1) prediction shape  36 16
[0.08370134 0.08498374 0.08586783 ... 0.99147415 0.9914744  0.99147636] prediction unique check if we are really rounding the score
(36, 128, 128, 16) prediction shape
209 subject id
145 dif cols diff_row 76
x:103:179 y:106:251 z:22:81
hereeeeee
[128, 128, 16] [64, 64, 16]
dim2
(54, 128, 128, 16) patch shape
torch.Size([864, 1, 128, 128]) patches torch
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([864, 1, 128, 128]) prediction size
(864, 128, 128, 1) prediction shape  54 16
[0.08788829 0.08789702 0.08800104 ... 0.9915324  0.9915337  0.9915338 ] prediction unique check if we are really rounding the score
(54, 128, 128, 16) prediction shape
211 subject id
166 dif cols diff_row 90
x:102:192 y:61:227 z:3:58
hereeeeee
[128, 128, 16] [64, 64, 16]
dim2
(27, 128, 128, 16) patch shape
torch.Size([432, 1, 128, 128]) patches torch
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([432, 1, 128, 128]) prediction size
(432, 128, 128, 1) prediction shape  27 16
[0.09113231 0.09139864 0.09144382 ... 0.99146956 0.9914807  0.9914835 ] prediction unique check if we are really rounding the score
(27, 128, 128, 16) prediction shape
184 subject id
139 dif cols diff_row 76
x:48:124 y:71:210 z:26:92
hereeeeee
[128, 128, 16] [64, 64, 16]
dim2
(54, 128, 128, 16) patch shape
torch.Size([864, 1, 128, 128]) patches torch
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([864, 1, 128, 128]) prediction size
(864, 128, 128, 1) prediction shape  54 16
[0.08059464 0.08155803 0.08157285 ... 0.991589   0.9915896  0.99158984] prediction unique check if we are really rounding the score
(54, 128, 128, 16) prediction shape
200 subject id
119 dif cols diff_row 163
x:63:226 y:80:199 z:21:78
hereeeeee
[128, 128, 16] [64, 64, 16]
dim2
(45, 128, 128, 16) patch shape
torch.Size([720, 1, 128, 128]) patches torch
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([720, 1, 128, 128]) prediction size
(720, 128, 128, 1) prediction shape  45 16
[0.08795273 0.08836125 0.08839987 ... 0.9915918  0.99159205 0.99159276] prediction unique check if we are really rounding the score
(45, 128, 128, 16) prediction shape
203 subject id
135 dif cols diff_row 136
x:43:179 y:34:169 z:12:36
hereeeeee
[128, 128, 16] [64, 64, 16]
dim2
(36, 128, 128, 16) patch shape
torch.Size([576, 1, 128, 128]) patches torch
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([576, 1, 128, 128]) prediction size
(576, 128, 128, 1) prediction shape  36 16
[0.08370134 0.08498374 0.08586783 ... 0.99147415 0.9914744  0.99147636] prediction unique check if we are really rounding the score
(36, 128, 128, 16) prediction shape
209 subject id
145 dif cols diff_row 76
x:103:179 y:106:251 z:22:81
hereeeeee
[128, 128, 16] [64, 64, 16]
dim2
(54, 128, 128, 16) patch shape
torch.Size([864, 1, 128, 128]) patches torch
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([864, 1, 128, 128]) prediction size
(864, 128, 128, 1) prediction shape  54 16
[0.08788829 0.08789702 0.08800104 ... 0.9915324  0.9915337  0.9915338 ] prediction unique check if we are really rounding the score
(54, 128, 128, 16) prediction shape
211 subject id
166 dif cols diff_row 90
x:102:192 y:61:227 z:3:58
hereeeeee
[128, 128, 16] [64, 64, 16]
dim2
(27, 128, 128, 16) patch shape
torch.Size([432, 1, 128, 128]) patches torch
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([432, 1, 128, 128]) prediction size
(432, 128, 128, 1) prediction shape  27 16
[0.09113231 0.09139864 0.09144382 ... 0.99146956 0.9914807  0.9914835 ] prediction unique check if we are really rounding the score
(27, 128, 128, 16) prediction shape
4.0 post_processing.max_over_lap
[0. 1. 2. 3. 4.] unique pred
[0. 1. 2. 3. 4.] unique pred
[0. 1. 2. 3. 4.] unique pred
[0. 1. 2. 3. 4.] unique pred
args: None URLord URLord_2 /cs/casmip/nirm/embryo_project_version1/EXP_FOLDER/exp_fp2/173/exp2d_DF_3_2d True urlord2d_173 DF_3_2d_TL DF_3_2d_TU DF_3_2d_VA DF_3_2d_TE False True /cs/labs/josko/nirm/embryo_project_version1/embyo_projects_codes/models_config/config_2d /cs/labs/josko/nirm/embryo_project_version1/embyo_projects_codes/models_config/config_2d
/cs/labs/josko/nirm/embryo_project_version1/embyo_projects_codes/lord-pytorch-unet/model/training_unet.py:918: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  plt.figure()
(2016, 128, 128, 1) imaggggggeeeeeeeeeeeeeeee shape
[0.] unique claseesssssssssssssssssssssssssssssssssssssssssssssssss
False False load_model
arrive train
2 30 config['n_classes'], config['class_dim']
here seg decay
here recon_loss
  0%|                                                                                                                                                                                                                                                                                         | 0/378 [00:00<?, ?it/s][W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)                                                                                                                                                                                              | 0/378 [00:00<?, ?it/s]
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)                                                                                                                                                                                               | 0/45 [00:00<?, ?it/s]
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)                                                                                                                                                                                              | 0/126 [00:00<?, ?it/s]
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
epoch #0:   2%|█████▎                                                                                                                                                                                                                                                      | 8/378 [00:01<00:54,  6.77it/s, loss=3.55]
  2%|█████▊                                                                                                                                                                                                                                                                           | 8/378 [00:01<00:54,  6.77it/s]
10 recon_decay
------------ 0.09110045433044434 backwards -------------------------------
10 recon_decay
------------ 0.08540916442871094 backwards -------------------------------
10 recon_decay
------------ 0.08484244346618652 backwards -------------------------------
10 recon_decay
------------ 0.08557271957397461 backwards -------------------------------
10 recon_decay
------------ 0.08543968200683594 backwards -------------------------------
10 recon_decay
------------ 0.08426070213317871 backwards -------------------------------

  5%|█████████████▋                                                                                                                                                                                                                                                                  | 19/378 [00:03<00:48,  7.43it/s]
------------ 0.08462119102478027 backwards -------------------------------
10 recon_decay
------------ 0.08585524559020996 backwards -------------------------------
10 recon_decay
------------ 0.0849459171295166 backwards -------------------------------
10 recon_decay
------------ 0.0843966007232666 backwards -------------------------------
10 recon_decay
------------ 0.08471870422363281 backwards -------------------------------
10 recon_decay
------------ 0.08496809005737305 backwards -------------------------------
10 recon_decay
------------ 0.08562445640563965 backwards -------------------------------
10 recon_decay
------------ 0.08564138412475586 backwards -------------------------------
10 recon_decay
------------ 0.08495616912841797 backwards -------------------------------
10 recon_decay
------------ 0.09035563468933105 backwards -------------------------------
10 recon_decay
------------ 0.08559918403625488 backwards -------------------------------
10 recon_decay
------------ 0.08485865592956543 backwards -------------------------------
10 recon_decay
------------ 0.08600163459777832 backwards -------------------------------
10 recon_decay
------------ 0.08544778823852539 backwards -------------------------------
10 recon_decay
------------ 0.08525943756103516 backwards -------------------------------

  9%|████████████████████████▍                                                                                                                                                                                                                                                       | 34/378 [00:05<00:46,  7.37it/s]
------------ 0.0850534439086914 backwards -------------------------------
10 recon_decay
------------ 0.08585429191589355 backwards -------------------------------
10 recon_decay
------------ 0.08551216125488281 backwards -------------------------------
10 recon_decay
------------ 0.08561205863952637 backwards -------------------------------
10 recon_decay
------------ 0.08554363250732422 backwards -------------------------------
10 recon_decay
------------ 0.08572077751159668 backwards -------------------------------
10 recon_decay
------------ 0.08457016944885254 backwards -------------------------------
10 recon_decay
------------ 0.08582305908203125 backwards -------------------------------
10 recon_decay
------------ 0.08595418930053711 backwards -------------------------------
10 recon_decay
------------ 0.08607912063598633 backwards -------------------------------
10 recon_decay
------------ 0.08562874794006348 backwards -------------------------------
10 recon_decay
------------ 0.08567047119140625 backwards -------------------------------
10 recon_decay
------------ 0.08580398559570312 backwards -------------------------------
10 recon_decay
------------ 0.08560466766357422 backwards -------------------------------
10 recon_decay
------------ 0.08528375625610352 backwards -------------------------------

 12%|███████████████████████████████▋                                                                                                                                                                                                                                                | 44/378 [00:07<01:04,  5.19it/s]
------------ 0.08566546440124512 backwards -------------------------------
10 recon_decay
------------ 0.08545732498168945 backwards -------------------------------
10 recon_decay
------------ 0.08495426177978516 backwards -------------------------------
10 recon_decay
------------ 0.29504823684692383 backwards -------------------------------
10 recon_decay
------------ 0.3756446838378906 backwards -------------------------------
10 recon_decay
------------ 0.08516407012939453 backwards -------------------------------
10 recon_decay
------------ 0.08481907844543457 backwards -------------------------------
10 recon_decay
------------ 0.08659648895263672 backwards -------------------------------
10 recon_decay
------------ 0.09365439414978027 backwards -------------------------------
10 recon_decay
------------ 0.08588504791259766 backwards -------------------------------

 16%|██████████████████████████████████████████▍                                                                                                                                                                                                                                     | 59/378 [00:09<00:44,  7.24it/s]
------------ 0.08544611930847168 backwards -------------------------------
10 recon_decay
------------ 0.08624124526977539 backwards -------------------------------
10 recon_decay
------------ 0.08531951904296875 backwards -------------------------------
10 recon_decay
------------ 0.08526301383972168 backwards -------------------------------
10 recon_decay
------------ 0.08558106422424316 backwards -------------------------------
10 recon_decay
------------ 0.08557581901550293 backwards -------------------------------
10 recon_decay
------------ 0.08518314361572266 backwards -------------------------------
10 recon_decay
------------ 0.08946967124938965 backwards -------------------------------
10 recon_decay
------------ 0.08543944358825684 backwards -------------------------------
10 recon_decay
------------ 0.08620929718017578 backwards -------------------------------
10 recon_decay
------------ 0.0875558853149414 backwards -------------------------------
10 recon_decay
------------ 0.0856790542602539 backwards -------------------------------
10 recon_decay
------------ 0.08655476570129395 backwards -------------------------------
10 recon_decay
------------ 0.08845281600952148 backwards -------------------------------
10 recon_decay
------------ 0.08839130401611328 backwards -------------------------------
10 recon_decay
------------ 0.0865170955657959 backwards -------------------------------
10 recon_decay
------------ 0.08518815040588379 backwards -------------------------------
10 recon_decay
------------ 0.08586955070495605 backwards -------------------------------
10 recon_decay
------------ 0.13873004913330078 backwards -------------------------------
10 recon_decay
------------ 0.08512473106384277 backwards -------------------------------
10 recon_decay
------------ 0.08486628532409668 backwards -------------------------------
10 recon_decay
------------ 0.08549308776855469 backwards -------------------------------
10 recon_decay
------------ 0.08654093742370605 backwards -------------------------------
10 recon_decay
------------ 0.08577752113342285 backwards -------------------------------
10 recon_decay
------------ 0.08580732345581055 backwards -------------------------------
10 recon_decay
------------ 0.08672690391540527 backwards -------------------------------
10 recon_decay
------------ 0.08772444725036621 backwards -------------------------------
10 recon_decay
------------ 0.08594727516174316 backwards -------------------------------

 19%|████████████████████████████████████████████████████▌                                                                                                                                                                                                                           | 73/378 [00:11<00:43,  6.97it/s]
------------ 0.08544206619262695 backwards -------------------------------
10 recon_decay
------------ 0.08545303344726562 backwards -------------------------------
10 recon_decay
------------ 0.08513188362121582 backwards -------------------------------
10 recon_decay
------------ 0.08495259284973145 backwards -------------------------------
10 recon_decay
------------ 0.08448672294616699 backwards -------------------------------
10 recon_decay
------------ 0.08504986763000488 backwards -------------------------------
10 recon_decay
------------ 0.0901491641998291 backwards -------------------------------
10 recon_decay
------------ 0.08507108688354492 backwards -------------------------------
10 recon_decay
------------ 0.08576631546020508 backwards -------------------------------
10 recon_decay
------------ 0.0847628116607666 backwards -------------------------------
10 recon_decay
------------ 0.0861961841583252 backwards -------------------------------
10 recon_decay
------------ 0.08459019660949707 backwards -------------------------------
10 recon_decay
------------ 0.08648943901062012 backwards -------------------------------
10 recon_decay
------------ 0.08629465103149414 backwards -------------------------------
10 recon_decay
------------ 0.08761310577392578 backwards -------------------------------


 27%|█████████████████████████████████████████████████████████████████████████▊                                                                                                                                                                                                     | 103/378 [00:15<00:37,  7.33it/s]
------------ 0.08640861511230469 backwards -------------------------------
10 recon_decay
------------ 0.08660244941711426 backwards -------------------------------
10 recon_decay
------------ 0.08576488494873047 backwards -------------------------------
10 recon_decay
------------ 0.08719611167907715 backwards -------------------------------
10 recon_decay
------------ 0.08683919906616211 backwards -------------------------------
10 recon_decay
------------ 0.08580207824707031 backwards -------------------------------
10 recon_decay
------------ 0.08653879165649414 backwards -------------------------------
10 recon_decay
------------ 0.08689689636230469 backwards -------------------------------
10 recon_decay
------------ 0.08611536026000977 backwards -------------------------------
10 recon_decay
------------ 0.0863041877746582 backwards -------------------------------
10 recon_decay
------------ 0.08633255958557129 backwards -------------------------------
10 recon_decay
------------ 0.08663344383239746 backwards -------------------------------
10 recon_decay
------------ 0.08591318130493164 backwards -------------------------------
10 recon_decay
------------ 0.08573532104492188 backwards -------------------------------
10 recon_decay
------------ 0.0853731632232666 backwards -------------------------------
10 recon_decay
------------ 0.08605599403381348 backwards -------------------------------
10 recon_decay
------------ 0.08608222007751465 backwards -------------------------------
10 recon_decay
------------ 0.08759140968322754 backwards -------------------------------
10 recon_decay
------------ 0.08612585067749023 backwards -------------------------------
10 recon_decay
------------ 0.08628249168395996 backwards -------------------------------
10 recon_decay
------------ 0.08631205558776855 backwards -------------------------------
10 recon_decay
------------ 0.08617615699768066 backwards -------------------------------
10 recon_decay
------------ 0.08592438697814941 backwards -------------------------------
10 recon_decay
------------ 0.08622884750366211 backwards -------------------------------
10 recon_decay
------------ 0.08511495590209961 backwards -------------------------------
10 recon_decay
------------ 0.08496451377868652 backwards -------------------------------
10 recon_decay
------------ 0.08565402030944824 backwards -------------------------------
10 recon_decay
------------ 0.08483242988586426 backwards -------------------------------
10 recon_decay
------------ 0.08455610275268555 backwards -------------------------------

 31%|████████████████████████████████████████████████████████████████████████████████████▌                                                                                                                                                                                          | 118/378 [00:17<00:35,  7.31it/s]
------------ 0.08470511436462402 backwards -------------------------------
10 recon_decay
------------ 0.08525776863098145 backwards -------------------------------
10 recon_decay
------------ 0.08587217330932617 backwards -------------------------------
10 recon_decay
------------ 0.08478593826293945 backwards -------------------------------
10 recon_decay
------------ 0.08579325675964355 backwards -------------------------------
10 recon_decay
------------ 0.08475208282470703 backwards -------------------------------
10 recon_decay
------------ 0.08471012115478516 backwards -------------------------------
10 recon_decay
------------ 0.08548569679260254 backwards -------------------------------
10 recon_decay
------------ 0.08570742607116699 backwards -------------------------------
10 recon_decay
------------ 0.08507084846496582 backwards -------------------------------
10 recon_decay
------------ 0.08509254455566406 backwards -------------------------------
10 recon_decay
------------ 0.08544063568115234 backwards -------------------------------
10 recon_decay
------------ 0.08523726463317871 backwards -------------------------------
10 recon_decay
------------ 0.08511090278625488 backwards -------------------------------
10 recon_decay
------------ 0.08628082275390625 backwards -------------------------------

 35%|██████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                                                                                | 132/378 [00:19<00:33,  7.27it/s]
------------ 0.08722949028015137 backwards -------------------------------
10 recon_decay
------------ 0.08535647392272949 backwards -------------------------------
10 recon_decay
------------ 0.0858922004699707 backwards -------------------------------
10 recon_decay
------------ 0.08893036842346191 backwards -------------------------------
10 recon_decay
------------ 0.0875558853149414 backwards -------------------------------
10 recon_decay
------------ 0.08476996421813965 backwards -------------------------------
10 recon_decay
------------ 0.08460688591003418 backwards -------------------------------
10 recon_decay
------------ 0.08436036109924316 backwards -------------------------------
10 recon_decay
------------ 0.08542990684509277 backwards -------------------------------
10 recon_decay
------------ 0.08515334129333496 backwards -------------------------------
10 recon_decay
------------ 0.08987069129943848 backwards -------------------------------
10 recon_decay
------------ 0.08454394340515137 backwards -------------------------------
10 recon_decay
------------ 0.08443713188171387 backwards -------------------------------
10 recon_decay
------------ 0.08524632453918457 backwards -------------------------------

 39%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                                                                                     | 147/378 [00:21<00:31,  7.32it/s]
------------ 0.08550739288330078 backwards -------------------------------
10 recon_decay
------------ 0.08505702018737793 backwards -------------------------------
10 recon_decay
------------ 0.08492016792297363 backwards -------------------------------
10 recon_decay
------------ 0.08567118644714355 backwards -------------------------------
10 recon_decay
------------ 0.08575677871704102 backwards -------------------------------
10 recon_decay
------------ 0.0852205753326416 backwards -------------------------------
10 recon_decay
------------ 0.08487415313720703 backwards -------------------------------
10 recon_decay
------------ 0.08466076850891113 backwards -------------------------------
10 recon_decay
------------ 0.0851130485534668 backwards -------------------------------
10 recon_decay
------------ 0.08452653884887695 backwards -------------------------------
10 recon_decay
------------ 0.08535599708557129 backwards -------------------------------
10 recon_decay
------------ 0.08434486389160156 backwards -------------------------------
10 recon_decay
------------ 0.08499550819396973 backwards -------------------------------
10 recon_decay
------------ 0.0844271183013916 backwards -------------------------------
10 recon_decay
------------ 0.0847012996673584 backwards -------------------------------


 47%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                                                                | 177/378 [00:25<00:27,  7.36it/s]
------------ 0.08436274528503418 backwards -------------------------------
10 recon_decay
------------ 0.08546018600463867 backwards -------------------------------
10 recon_decay
------------ 0.08521389961242676 backwards -------------------------------
10 recon_decay
------------ 0.08501935005187988 backwards -------------------------------
10 recon_decay
------------ 0.08528923988342285 backwards -------------------------------
10 recon_decay
------------ 0.08473086357116699 backwards -------------------------------
10 recon_decay
------------ 0.08454132080078125 backwards -------------------------------
10 recon_decay
------------ 0.08517670631408691 backwards -------------------------------
10 recon_decay
------------ 0.08529973030090332 backwards -------------------------------
10 recon_decay
------------ 0.08695864677429199 backwards -------------------------------
10 recon_decay
------------ 0.0845797061920166 backwards -------------------------------
10 recon_decay
------------ 0.08531522750854492 backwards -------------------------------
10 recon_decay
------------ 0.08585882186889648 backwards -------------------------------
10 recon_decay
------------ 0.08477163314819336 backwards -------------------------------
10 recon_decay
------------ 0.08548665046691895 backwards -------------------------------

 51%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                                                      | 191/378 [00:27<00:25,  7.23it/s]
------------ 0.08502006530761719 backwards -------------------------------
10 recon_decay
------------ 0.08463025093078613 backwards -------------------------------
10 recon_decay
------------ 0.08453512191772461 backwards -------------------------------
10 recon_decay
------------ 0.10240054130554199 backwards -------------------------------
10 recon_decay
------------ 0.08645343780517578 backwards -------------------------------
10 recon_decay
------------ 0.08644294738769531 backwards -------------------------------
10 recon_decay
------------ 0.08521223068237305 backwards -------------------------------
10 recon_decay
------------ 0.08612298965454102 backwards -------------------------------
10 recon_decay
------------ 0.08558917045593262 backwards -------------------------------
10 recon_decay
------------ 0.08746671676635742 backwards -------------------------------
10 recon_decay
------------ 0.08806276321411133 backwards -------------------------------
10 recon_decay
------------ 0.08690357208251953 backwards -------------------------------
10 recon_decay
------------ 0.0860128402709961 backwards -------------------------------
10 recon_decay
------------ 0.08477139472961426 backwards -------------------------------

 54%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                           | 206/378 [00:29<00:23,  7.24it/s]
------------ 0.08629155158996582 backwards -------------------------------
10 recon_decay
------------ 0.0859687328338623 backwards -------------------------------
10 recon_decay
------------ 0.08474373817443848 backwards -------------------------------
10 recon_decay
------------ 0.08563065528869629 backwards -------------------------------
10 recon_decay
------------ 0.08563828468322754 backwards -------------------------------
10 recon_decay
------------ 0.0875394344329834 backwards -------------------------------
10 recon_decay
------------ 0.08967924118041992 backwards -------------------------------
10 recon_decay
------------ 0.08780074119567871 backwards -------------------------------
10 recon_decay
------------ 0.08614420890808105 backwards -------------------------------
10 recon_decay
------------ 0.08520150184631348 backwards -------------------------------
10 recon_decay
------------ 0.08646154403686523 backwards -------------------------------
10 recon_decay
------------ 0.0879364013671875 backwards -------------------------------
10 recon_decay
------------ 0.08510780334472656 backwards -------------------------------
10 recon_decay
------------ 0.08550548553466797 backwards -------------------------------

 58%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                                 | 220/378 [00:31<00:22,  7.05it/s]
------------ 0.08556199073791504 backwards -------------------------------
10 recon_decay
------------ 0.08582711219787598 backwards -------------------------------
10 recon_decay
------------ 0.08728480339050293 backwards -------------------------------
10 recon_decay
------------ 0.08533215522766113 backwards -------------------------------
10 recon_decay
------------ 0.08744096755981445 backwards -------------------------------
10 recon_decay
------------ 0.08605241775512695 backwards -------------------------------
10 recon_decay
------------ 0.08526611328125 backwards -------------------------------
10 recon_decay
------------ 0.08599305152893066 backwards -------------------------------
10 recon_decay
------------ 0.08525848388671875 backwards -------------------------------
10 recon_decay
------------ 0.08601713180541992 backwards -------------------------------
10 recon_decay
------------ 0.08635497093200684 backwards -------------------------------
10 recon_decay
------------ 0.08547377586364746 backwards -------------------------------
10 recon_decay
------------ 0.10866808891296387 backwards -------------------------------
10 recon_decay
------------ 0.08583807945251465 backwards -------------------------------
10 recon_decay
------------ 0.08569765090942383 backwards -------------------------------

 62%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                      | 235/378 [00:33<00:20,  7.02it/s]
------------ 0.0871737003326416 backwards -------------------------------
10 recon_decay
------------ 0.08768653869628906 backwards -------------------------------
10 recon_decay
------------ 0.08690834045410156 backwards -------------------------------
10 recon_decay
------------ 0.08680582046508789 backwards -------------------------------
10 recon_decay
------------ 0.08637142181396484 backwards -------------------------------
10 recon_decay
------------ 0.08950114250183105 backwards -------------------------------
10 recon_decay
------------ 0.08649039268493652 backwards -------------------------------
10 recon_decay
------------ 0.08616161346435547 backwards -------------------------------
10 recon_decay
------------ 0.08985114097595215 backwards -------------------------------
10 recon_decay
------------ 0.08767104148864746 backwards -------------------------------
10 recon_decay
------------ 0.0893402099609375 backwards -------------------------------
10 recon_decay
------------ 0.08896422386169434 backwards -------------------------------
10 recon_decay
------------ 0.08814692497253418 backwards -------------------------------
10 recon_decay
------------ 0.09246540069580078 backwards -------------------------------

 66%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                            | 249/378 [00:35<00:18,  7.14it/s]
------------ 0.08819389343261719 backwards -------------------------------
10 recon_decay
------------ 0.08814716339111328 backwards -------------------------------
10 recon_decay
------------ 0.0879373550415039 backwards -------------------------------
10 recon_decay
------------ 0.08915877342224121 backwards -------------------------------
10 recon_decay
------------ 0.08802080154418945 backwards -------------------------------
10 recon_decay
------------ 0.08862781524658203 backwards -------------------------------
10 recon_decay
------------ 0.08876895904541016 backwards -------------------------------
10 recon_decay
------------ 0.08787751197814941 backwards -------------------------------
10 recon_decay
------------ 0.08802962303161621 backwards -------------------------------
10 recon_decay
------------ 0.08522224426269531 backwards -------------------------------
10 recon_decay
------------ 0.08657169342041016 backwards -------------------------------
10 recon_decay
------------ 0.08859920501708984 backwards -------------------------------
10 recon_decay
------------ 0.08814120292663574 backwards -------------------------------
10 recon_decay
------------ 0.0862123966217041 backwards -------------------------------

 70%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                  | 263/378 [00:37<00:16,  7.13it/s]
------------ 0.08648824691772461 backwards -------------------------------
10 recon_decay
------------ 0.08580636978149414 backwards -------------------------------
10 recon_decay
------------ 0.08558940887451172 backwards -------------------------------
10 recon_decay
------------ 0.08658862113952637 backwards -------------------------------
10 recon_decay
------------ 0.08597254753112793 backwards -------------------------------
10 recon_decay
------------ 0.08681845664978027 backwards -------------------------------
10 recon_decay
------------ 0.09215164184570312 backwards -------------------------------
10 recon_decay
------------ 0.08514952659606934 backwards -------------------------------
10 recon_decay
------------ 0.0858452320098877 backwards -------------------------------
10 recon_decay
------------ 0.08682489395141602 backwards -------------------------------
10 recon_decay
------------ 0.08508062362670898 backwards -------------------------------
10 recon_decay
------------ 0.08858180046081543 backwards -------------------------------
10 recon_decay
------------ 0.08737516403198242 backwards -------------------------------
10 recon_decay
------------ 0.08603024482727051 backwards -------------------------------

 74%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                       | 278/378 [00:39<00:13,  7.15it/s]
------------ 0.08527541160583496 backwards -------------------------------
10 recon_decay
------------ 0.08942008018493652 backwards -------------------------------
10 recon_decay
------------ 0.08543634414672852 backwards -------------------------------
10 recon_decay
------------ 0.086212158203125 backwards -------------------------------
10 recon_decay
------------ 0.08850240707397461 backwards -------------------------------
10 recon_decay
------------ 0.08871698379516602 backwards -------------------------------
10 recon_decay
------------ 0.08907842636108398 backwards -------------------------------
10 recon_decay
------------ 0.08958935737609863 backwards -------------------------------
10 recon_decay
------------ 0.08971309661865234 backwards -------------------------------
10 recon_decay
------------ 0.08828210830688477 backwards -------------------------------
10 recon_decay
------------ 0.08623123168945312 backwards -------------------------------
10 recon_decay
------------ 0.08896088600158691 backwards -------------------------------
10 recon_decay
------------ 0.0865333080291748 backwards -------------------------------
10 recon_decay
------------ 0.08533644676208496 backwards -------------------------------

 77%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                             | 292/378 [00:41<00:12,  7.16it/s]
------------ 0.08716917037963867 backwards -------------------------------
10 recon_decay
------------ 0.08687639236450195 backwards -------------------------------
10 recon_decay
------------ 0.08501672744750977 backwards -------------------------------
10 recon_decay
------------ 0.0862116813659668 backwards -------------------------------
10 recon_decay
------------ 0.08534955978393555 backwards -------------------------------
10 recon_decay
------------ 0.08630633354187012 backwards -------------------------------
10 recon_decay
------------ 0.0902702808380127 backwards -------------------------------
10 recon_decay
------------ 0.08569860458374023 backwards -------------------------------
10 recon_decay
------------ 0.08903837203979492 backwards -------------------------------
10 recon_decay
------------ 0.08939909934997559 backwards -------------------------------
10 recon_decay
------------ 0.08905911445617676 backwards -------------------------------
10 recon_decay
------------ 0.0887606143951416 backwards -------------------------------
10 recon_decay
------------ 0.08597636222839355 backwards -------------------------------
10 recon_decay
------------ 0.08527088165283203 backwards -------------------------------
10 recon_decay
------------ 0.08528423309326172 backwards -------------------------------

 81%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                   | 307/378 [00:43<00:09,  7.13it/s]
------------ 0.08577966690063477 backwards -------------------------------
10 recon_decay
------------ 0.08516120910644531 backwards -------------------------------
10 recon_decay
------------ 0.08621501922607422 backwards -------------------------------
10 recon_decay
------------ 0.08540725708007812 backwards -------------------------------
10 recon_decay
------------ 0.08700108528137207 backwards -------------------------------
10 recon_decay
------------ 0.08512616157531738 backwards -------------------------------
10 recon_decay
------------ 0.08718347549438477 backwards -------------------------------
10 recon_decay
------------ 0.08576774597167969 backwards -------------------------------
10 recon_decay
------------ 0.08890199661254883 backwards -------------------------------
10 recon_decay
------------ 0.08579015731811523 backwards -------------------------------
10 recon_decay
------------ 0.0858461856842041 backwards -------------------------------
10 recon_decay
------------ 0.08646297454833984 backwards -------------------------------
10 recon_decay
------------ 0.08546876907348633 backwards -------------------------------
10 recon_decay
------------ 0.0872201919555664 backwards -------------------------------

 85%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                        | 321/378 [00:45<00:08,  6.94it/s]
------------ 0.08621096611022949 backwards -------------------------------
10 recon_decay
------------ 0.08613824844360352 backwards -------------------------------
10 recon_decay
------------ 0.08555746078491211 backwards -------------------------------
10 recon_decay
------------ 0.08604621887207031 backwards -------------------------------
10 recon_decay
------------ 0.08693265914916992 backwards -------------------------------
10 recon_decay
------------ 0.08633160591125488 backwards -------------------------------
10 recon_decay
------------ 0.08629417419433594 backwards -------------------------------
10 recon_decay
------------ 0.08875465393066406 backwards -------------------------------
10 recon_decay
------------ 0.08800220489501953 backwards -------------------------------
10 recon_decay
------------ 0.08691525459289551 backwards -------------------------------
10 recon_decay
------------ 0.08595705032348633 backwards -------------------------------
10 recon_decay
------------ 0.08675217628479004 backwards -------------------------------
10 recon_decay
------------ 0.08889484405517578 backwards -------------------------------
10 recon_decay
------------ 0.08556175231933594 backwards -------------------------------

 88%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                 | 332/378 [00:47<00:06,  7.14it/s]
------------ 0.08714485168457031 backwards -------------------------------
10 recon_decay
------------ 0.09636759757995605 backwards -------------------------------
10 recon_decay
------------ 0.09438419342041016 backwards -------------------------------
10 recon_decay
------------ 0.08690476417541504 backwards -------------------------------
10 recon_decay
------------ 0.09198808670043945 backwards -------------------------------
10 recon_decay
------------ 0.09131813049316406 backwards -------------------------------
10 recon_decay
------------ 0.08754324913024902 backwards -------------------------------
10 recon_decay
------------ 0.0867307186126709 backwards -------------------------------
10 recon_decay
------------ 0.08646845817565918 backwards -------------------------------
10 recon_decay
------------ 0.0866246223449707 backwards -------------------------------
10 recon_decay
------------ 0.08632755279541016 backwards -------------------------------
10 recon_decay
------------ 0.08580541610717773 backwards -------------------------------
10 recon_decay
------------ 0.08699440956115723 backwards -------------------------------
10 recon_decay
------------ 0.08615422248840332 backwards -------------------------------

 92%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                       | 346/378 [00:49<00:04,  6.84it/s]
------------ 0.08727645874023438 backwards -------------------------------
10 recon_decay
------------ 0.08624053001403809 backwards -------------------------------
10 recon_decay
------------ 0.08605194091796875 backwards -------------------------------
10 recon_decay
------------ 0.08658695220947266 backwards -------------------------------
10 recon_decay
------------ 0.08689379692077637 backwards -------------------------------
10 recon_decay
------------ 0.08583974838256836 backwards -------------------------------
10 recon_decay
------------ 0.0866084098815918 backwards -------------------------------
10 recon_decay
------------ 0.08587932586669922 backwards -------------------------------
10 recon_decay
------------ 0.0865013599395752 backwards -------------------------------
10 recon_decay
------------ 0.14423894882202148 backwards -------------------------------
10 recon_decay
------------ 0.08617615699768066 backwards -------------------------------
10 recon_decay
------------ 0.08702945709228516 backwards -------------------------------
10 recon_decay
------------ 0.08585548400878906 backwards -------------------------------
10 recon_decay
------------ 0.08802652359008789 backwards -------------------------------

 95%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████             | 360/378 [00:51<00:02,  7.03it/s]
------------ 0.08603429794311523 backwards -------------------------------
10 recon_decay
------------ 0.08710193634033203 backwards -------------------------------
10 recon_decay
------------ 0.08611488342285156 backwards -------------------------------
10 recon_decay
------------ 0.08812522888183594 backwards -------------------------------
10 recon_decay
------------ 0.08561468124389648 backwards -------------------------------
10 recon_decay
------------ 0.08637595176696777 backwards -------------------------------
10 recon_decay
------------ 0.08592081069946289 backwards -------------------------------
10 recon_decay
------------ 0.08628249168395996 backwards -------------------------------
10 recon_decay
------------ 0.0872964859008789 backwards -------------------------------
10 recon_decay
------------ 0.08600091934204102 backwards -------------------------------
10 recon_decay
------------ 0.08889222145080566 backwards -------------------------------
10 recon_decay
------------ 0.08572769165039062 backwards -------------------------------
10 recon_decay
------------ 0.08549976348876953 backwards -------------------------------
10 recon_decay
------------ 0.08519220352172852 backwards -------------------------------

 99%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊  | 375/378 [00:53<00:00,  7.18it/s]
------------ 0.08568477630615234 backwards -------------------------------
10 recon_decay
------------ 0.0858771800994873 backwards -------------------------------
10 recon_decay
------------ 0.08530664443969727 backwards -------------------------------
10 recon_decay
------------ 0.08805346488952637 backwards -------------------------------
10 recon_decay
------------ 0.08565831184387207 backwards -------------------------------
10 recon_decay
------------ 0.08557844161987305 backwards -------------------------------
10 recon_decay
------------ 0.08528280258178711 backwards -------------------------------
10 recon_decay
------------ 0.08609199523925781 backwards -------------------------------
10 recon_decay
------------ 0.08592033386230469 backwards -------------------------------
10 recon_decay
------------ 0.08768868446350098 backwards -------------------------------
10 recon_decay
------------ 0.08561420440673828 backwards -------------------------------
10 recon_decay
------------ 0.08667802810668945 backwards -------------------------------
10 recon_decay
------------ 0.08496832847595215 backwards -------------------------------
10 recon_decay
------------ 0.08537149429321289 backwards -------------------------------
10 recon_decay
------------ 0.08504629135131836 backwards -------------------------------
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎| 377/378 [00:53<00:00,  7.00it/s]
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
 69%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                     | 31/45 [00:55<00:02,  5.08it/s]
------------ 0.08837127685546875 backwards -------------------------------
10 recon_decay
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊            | 43/45 [00:55<00:00, 13.03it/s]
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)

 63%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                     | 79/126 [00:59<00:01, 24.75it/s]
saving model......................................................
done
------------ 61.512779712677 seg time alll epoch -------------------------------
saving model......................................................

 98%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋    | 124/126 [01:01<00:00, 24.91it/s]
saving model......................................................
2 30 config['n_classes'], config['class_dim']
dict_keys(['104', '135', '170', '174', '176', '177', '184', '188', '189', '191', '197', '200', '201', '203', '205', '208', '209', '211', '223', '224', '225', '228', '232', '234', '258', '76', '78', '81', '91', '93', '95'])
184 subject id
139 dif cols diff_row 76
x:48:124 y:71:210 z:26:92
hereeeeee
[128, 128, 16] [64, 64, 16]
dim2
(54, 128, 128, 16) patch shape
torch.Size([864, 1, 128, 128]) patches torch
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([864, 1, 128, 128]) prediction size
(864, 128, 128, 1) prediction shape  54 16
[0.15907584 0.17085129 0.17317487 ... 0.9931844  0.99353325 0.9937226 ] prediction unique check if we are really rounding the score
(54, 128, 128, 16) prediction shape
200 subject id
119 dif cols diff_row 163
x:63:226 y:80:199 z:21:78
hereeeeee
[128, 128, 16] [64, 64, 16]
dim2
(45, 128, 128, 16) patch shape
torch.Size([720, 1, 128, 128]) patches torch
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([720, 1, 128, 128]) prediction size
(720, 128, 128, 1) prediction shape  45 16
[0.16938628 0.17216197 0.17223966 ... 0.99309653 0.99353325 0.9937226 ] prediction unique check if we are really rounding the score
(45, 128, 128, 16) prediction shape
203 subject id
135 dif cols diff_row 136
x:43:179 y:34:169 z:12:36
hereeeeee
[128, 128, 16] [64, 64, 16]
dim2
(36, 128, 128, 16) patch shape
torch.Size([576, 1, 128, 128]) patches torch
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([576, 1, 128, 128]) prediction size
(576, 128, 128, 1) prediction shape  36 16
[0.1540089  0.16325809 0.16606136 ... 0.99353325 0.9937226  0.99389726] prediction unique check if we are really rounding the score
(36, 128, 128, 16) prediction shape
209 subject id
145 dif cols diff_row 76
x:103:179 y:106:251 z:22:81
hereeeeee
[128, 128, 16] [64, 64, 16]
dim2
(54, 128, 128, 16) patch shape
torch.Size([864, 1, 128, 128]) patches torch
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([864, 1, 128, 128]) prediction size
(864, 128, 128, 1) prediction shape  54 16
[0.15454988 0.15728617 0.1587464  ... 0.9931844  0.99353325 0.9937226 ] prediction unique check if we are really rounding the score
(54, 128, 128, 16) prediction shape
211 subject id
166 dif cols diff_row 90
x:102:192 y:61:227 z:3:58
hereeeeee
[128, 128, 16] [64, 64, 16]
dim2
(27, 128, 128, 16) patch shape
torch.Size([432, 1, 128, 128]) patches torch
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([432, 1, 128, 128]) prediction size
(432, 128, 128, 1) prediction shape  27 16
[0.1343046  0.17393379 0.17393382 ... 0.99308276 0.99353325 0.9937226 ] prediction unique check if we are really rounding the score
(27, 128, 128, 16) prediction shape
184 subject id
139 dif cols diff_row 76
x:48:124 y:71:210 z:26:92
hereeeeee
[128, 128, 16] [64, 64, 16]
dim2
(54, 128, 128, 16) patch shape
torch.Size([864, 1, 128, 128]) patches torch
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([864, 1, 128, 128]) prediction size
(864, 128, 128, 1) prediction shape  54 16
[0.15907584 0.17085129 0.17317487 ... 0.9931844  0.99353325 0.9937226 ] prediction unique check if we are really rounding the score
(54, 128, 128, 16) prediction shape
200 subject id
119 dif cols diff_row 163
x:63:226 y:80:199 z:21:78
hereeeeee
[128, 128, 16] [64, 64, 16]
dim2
(45, 128, 128, 16) patch shape
torch.Size([720, 1, 128, 128]) patches torch
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([720, 1, 128, 128]) prediction size
(720, 128, 128, 1) prediction shape  45 16
[0.16938628 0.17216197 0.17223966 ... 0.99309653 0.99353325 0.9937226 ] prediction unique check if we are really rounding the score
(45, 128, 128, 16) prediction shape
203 subject id
135 dif cols diff_row 136
x:43:179 y:34:169 z:12:36
hereeeeee
[128, 128, 16] [64, 64, 16]
dim2
(36, 128, 128, 16) patch shape
torch.Size([576, 1, 128, 128]) patches torch
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([576, 1, 128, 128]) prediction size
(576, 128, 128, 1) prediction shape  36 16
[0.1540089  0.16325809 0.16606136 ... 0.99353325 0.9937226  0.99389726] prediction unique check if we are really rounding the score
(36, 128, 128, 16) prediction shape
209 subject id
145 dif cols diff_row 76
x:103:179 y:106:251 z:22:81
hereeeeee
[128, 128, 16] [64, 64, 16]
dim2
(54, 128, 128, 16) patch shape
torch.Size([864, 1, 128, 128]) patches torch
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([864, 1, 128, 128]) prediction size
(864, 128, 128, 1) prediction shape  54 16
[0.15454988 0.15728617 0.1587464  ... 0.9931844  0.99353325 0.9937226 ] prediction unique check if we are really rounding the score
(54, 128, 128, 16) prediction shape
211 subject id
166 dif cols diff_row 90
x:102:192 y:61:227 z:3:58
hereeeeee
[128, 128, 16] [64, 64, 16]
dim2
(27, 128, 128, 16) patch shape
torch.Size([432, 1, 128, 128]) patches torch
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([16, 1, 128, 128]) patch size
torch.Size([432, 1, 128, 128]) prediction size
(432, 128, 128, 1) prediction shape  27 16
[0.1343046  0.17393379 0.17393382 ... 0.99308276 0.99353325 0.9937226 ] prediction unique check if we are really rounding the score
(27, 128, 128, 16) prediction shape
4.0 post_processing.max_over_lap
[0. 1. 2. 3. 4.] unique pred
[0. 1. 2. 3. 4.] unique pred
